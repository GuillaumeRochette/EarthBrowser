Log file created at: 2017/10/10 15:38:48
Running on machine: athena-0094
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I1010 15:38:48.725550 28708 caffe.cpp:218] Using GPUs 0
I1010 15:38:48.758016 28708 caffe.cpp:223] GPU 0: Quadro M1000M
I1010 15:38:49.053707 28708 solver.cpp:44] Initializing solver from parameters: 
test_iter: 1733
test_interval: 500
base_lr: 0.001
display: 500
max_iter: 50000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0005
snapshot: 500
snapshot_prefix: "snapshots/znet3"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
train_state {
  level: 0
  stage: ""
}
iter_size: 4
momentum2: 0.999
type: "Adam"
I1010 15:38:49.102145 28708 solver.cpp:87] Creating training net from net file: train_val.prototxt
I1010 15:38:49.104890 28708 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1010 15:38:49.107230 28708 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1010 15:38:49.109786 28708 net.cpp:51] Initializing net from parameters: 
name: "ZNet3"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/home/grochette/Documents/SegNet/data/HDF5/Train/hdf5_list.txt"
    batch_size: 16
    shuffle: true
  }
}
layer {
  name: "batchnorm0"
  type: "BatchNorm"
  bottom: "data"
  top: "data"
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchnorm1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "elu1_1"
  type: "ELU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchnorm1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "elu1_2"
  type: "ELU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  top: "pool1_argmax_count"
  pooling_param {
    pool: MAX
    kernel_size: 4
    stride: 4
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchnorm2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "elu2_1"
  type: "ELU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchnorm2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "elu2_2"
  type: "ELU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  top: "pool2_argmax_count"
  pooling_param {
    pool: MAX
    kernel_size: 4
    stride: 4
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchnorm3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "elu3_1"
  type: "ELU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchnorm3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "elu3_2"
  type: "ELU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchnorm3_3"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "elu3_3"
  type: "ELU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  top: "pool3_argmax_count"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchnorm4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "elu4_1"
  type: "ELU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchnorm4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "elu4_2"
  type: "ELU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "deconv4_3"
  type: "Deconvolution"
  bottom: "conv4_2"
  top: "deconv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "debatchnorm4_3"
  type: "BatchNorm"
  bottom: "deconv4_3"
  top: "deconv4_3"
}
layer {
  name: "deelu4_3"
  type: "ELU"
  bottom: "deconv4_3"
  top: "deconv4_3"
}
layer {
  name: "unpool3"
  type: "Unpooling"
  bottom: "deconv4_3"
  bottom: "pool3_mask"
  bottom: "pool3_argmax_count"
  top: "unpool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "deconv3_1"
  type: "Deconvolution"
  bottom: "unpool3"
  top: "deconv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "debatchnorm3_1"
  type: "BatchNorm"
  bottom: "deconv3_1"
  top: "deconv3_1"
}
layer {
  name: "deelu3_1"
  type: "ELU"
  bottom: "deconv3_1"
  top: "deconv3_1"
}
layer {
  name: "deconv3_2"
  type: "Deconvolution"
  bottom: "deconv3_1"
  top: "deconv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "debatchnorm3_2"
  type: "BatchNorm"
  bottom: "deconv3_2"
  top: "deconv3_2"
}
layer {
  name: "deelu3_2"
  type: "ELU"
  bottom: "deconv3_2"
  top: "deconv3_2"
}
layer {
  name: "deconv3_3"
  type: "Deconvolution"
  bottom: "deconv3_2"
  top: "deconv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "debatchnorm3_3"
  type: "BatchNorm"
  bottom: "deconv3_3"
  top: "deconv3_3"
}
layer {
  name: "deelu3_3"
  type: "ELU"
  bottom: "deconv3_3"
  top: "deconv3_3"
}
layer {
  name: "unpool2"
  type: "Unpooling"
  bottom: "deconv3_3"
  bottom: "pool2_mask"
  bottom: "pool2_argmax_count"
  top: "unpool2"
  pooling_param {
    pool: MAX
    kernel_size: 4
    stride: 4
  }
}
layer {
  name: "deconv2_1"
  type: "Deconvolution"
  bottom: "unpool2"
  top: "deconv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "debatchnorm2_1"
  type: "BatchNorm"
  bottom: "deconv2_1"
  top: "deconv2_1"
}
layer {
  name: "deelu2_1"
  type: "ELU"
  bottom: "deconv2_1"
  top: "deconv2_1"
}
layer {
  name: "deconv2_2"
  type: "Deconvolution"
  bottom: "deconv2_1"
  top: "deconv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "debatchnorm2_2"
  type: "BatchNorm"
  bottom: "deconv2_2"
  top: "deconv2_2"
}
layer {
  name: "deelu2_2"
  type: "ELU"
  bottom: "deconv2_2"
  top: "deconv2_2"
}
layer {
  name: "unpool1"
  type: "Unpooling"
  bottom: "deconv2_2"
  bottom: "pool1_mask"
  bottom: "pool1_argmax_count"
  top: "unpool1"
  pooling_param {
    pool: MAX
    kernel_size: 4
    stride: 4
  }
}
layer {
  name: "deconv1_1"
  type: "Deconvolution"
  bottom: "unpool1"
  top: "deconv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "debatchnorm1_1"
  type: "BatchNorm"
  bottom: "deconv1_1"
  top: "deconv1_1"
}
layer {
  name: "deelu1_1"
  type: "ELU"
  bottom: "deconv1_1"
  top: "deconv1_1"
}
layer {
  name: "deconv1_2"
  type: "Deconvolution"
  bottom: "deconv1_1"
  top: "deconv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "debatchnorm1_2"
  type: "BatchNorm"
  bottom: "deconv1_2"
  top: "deconv1_2"
}
layer {
  name: "deelu1_2"
  type: "ELU"
  bottom: "deconv1_2"
  top: "deconv1_2"
}
layer {
  name: "segmentation"
  type: "Convolution"
  bottom: "deconv1_2"
  top: "segmentation"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 3
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "infogainLoss"
  type: "InfogainLoss"
  bottom: "segmentation"
  bottom: "label"
  top: "loss"
  loss_param {
    ignore_label: 3
  }
  infogain_loss_param {
    source: "/home/grochette/Documents/SegNet/data/OnlyVegas/infogainH.binaryproto"
  }
}
I1010 15:38:50.093286 28708 layer_factory.hpp:77] Creating layer data
I1010 15:38:50.094525 28708 net.cpp:84] Creating Layer data
I1010 15:38:50.095783 28708 net.cpp:380] data -> data
I1010 15:38:50.097059 28708 net.cpp:380] data -> label
I1010 15:38:50.098317 28708 hdf5_data_layer.cpp:80] Loading list of HDF5 filenames from: /home/grochette/Documents/SegNet/data/HDF5/Train/hdf5_list.txt
I1010 15:38:50.100626 28708 hdf5_data_layer.cpp:94] Number of HDF5 files: 16
I1010 15:38:50.104727 28708 hdf5.cpp:32] Datatype class: H5T_FLOAT
I1010 15:38:52.743945 28708 hdf5.cpp:35] Datatype class: H5T_INTEGER
I1010 15:38:53.086591 28708 net.cpp:122] Setting up data
I1010 15:38:53.087986 28708 net.cpp:129] Top shape: 16 4 224 224 (3211264)
I1010 15:38:53.089336 28708 net.cpp:129] Top shape: 16 1 224 224 (802816)
I1010 15:38:53.090692 28708 net.cpp:137] Memory required for data: 16056320
I1010 15:38:53.092043 28708 layer_factory.hpp:77] Creating layer batchnorm0
I1010 15:38:53.093426 28708 net.cpp:84] Creating Layer batchnorm0
I1010 15:38:53.094796 28708 net.cpp:406] batchnorm0 <- data
I1010 15:38:53.096197 28708 net.cpp:367] batchnorm0 -> data (in-place)
I1010 15:38:53.098644 28708 net.cpp:122] Setting up batchnorm0
I1010 15:38:53.100033 28708 net.cpp:129] Top shape: 16 4 224 224 (3211264)
I1010 15:38:53.101408 28708 net.cpp:137] Memory required for data: 28901376
I1010 15:38:53.102823 28708 layer_factory.hpp:77] Creating layer conv1_1
I1010 15:38:53.104256 28708 net.cpp:84] Creating Layer conv1_1
I1010 15:38:53.105687 28708 net.cpp:406] conv1_1 <- data
I1010 15:38:53.107121 28708 net.cpp:380] conv1_1 -> conv1_1
I1010 15:38:53.645409 28708 net.cpp:122] Setting up conv1_1
I1010 15:38:53.646879 28708 net.cpp:129] Top shape: 16 32 224 224 (25690112)
I1010 15:38:53.648356 28708 net.cpp:137] Memory required for data: 131661824
I1010 15:38:53.649827 28708 layer_factory.hpp:77] Creating layer batchnorm1_1
I1010 15:38:53.651279 28708 net.cpp:84] Creating Layer batchnorm1_1
I1010 15:38:53.652765 28708 net.cpp:406] batchnorm1_1 <- conv1_1
I1010 15:38:53.654249 28708 net.cpp:367] batchnorm1_1 -> conv1_1 (in-place)
I1010 15:38:53.655977 28708 net.cpp:122] Setting up batchnorm1_1
I1010 15:38:53.657466 28708 net.cpp:129] Top shape: 16 32 224 224 (25690112)
I1010 15:38:53.658967 28708 net.cpp:137] Memory required for data: 234422272
I1010 15:38:53.660481 28708 layer_factory.hpp:77] Creating layer elu1_1
I1010 15:38:53.662011 28708 net.cpp:84] Creating Layer elu1_1
I1010 15:38:53.663527 28708 net.cpp:406] elu1_1 <- conv1_1
I1010 15:38:53.665045 28708 net.cpp:367] elu1_1 -> conv1_1 (in-place)
I1010 15:38:53.666571 28708 net.cpp:122] Setting up elu1_1
I1010 15:38:53.668087 28708 net.cpp:129] Top shape: 16 32 224 224 (25690112)
I1010 15:38:53.669651 28708 net.cpp:137] Memory required for data: 337182720
I1010 15:38:53.671200 28708 layer_factory.hpp:77] Creating layer conv1_2
I1010 15:38:53.672771 28708 net.cpp:84] Creating Layer conv1_2
I1010 15:38:53.674348 28708 net.cpp:406] conv1_2 <- conv1_1
I1010 15:38:53.675920 28708 net.cpp:380] conv1_2 -> conv1_2
I1010 15:38:53.680320 28708 net.cpp:122] Setting up conv1_2
I1010 15:38:53.681921 28708 net.cpp:129] Top shape: 16 32 224 224 (25690112)
I1010 15:38:53.683509 28708 net.cpp:137] Memory required for data: 439943168
I1010 15:38:53.685102 28708 layer_factory.hpp:77] Creating layer batchnorm1_2
I1010 15:38:53.686722 28708 net.cpp:84] Creating Layer batchnorm1_2
I1010 15:38:53.688344 28708 net.cpp:406] batchnorm1_2 <- conv1_2
I1010 15:38:53.689976 28708 net.cpp:367] batchnorm1_2 -> conv1_2 (in-place)
I1010 15:38:53.691787 28708 net.cpp:122] Setting up batchnorm1_2
I1010 15:38:53.693430 28708 net.cpp:129] Top shape: 16 32 224 224 (25690112)
I1010 15:38:53.695082 28708 net.cpp:137] Memory required for data: 542703616
I1010 15:38:53.696749 28708 layer_factory.hpp:77] Creating layer elu1_2
I1010 15:38:53.698421 28708 net.cpp:84] Creating Layer elu1_2
I1010 15:38:53.700084 28708 net.cpp:406] elu1_2 <- conv1_2
I1010 15:38:53.701737 28708 net.cpp:367] elu1_2 -> conv1_2 (in-place)
I1010 15:38:53.703447 28708 net.cpp:122] Setting up elu1_2
I1010 15:38:53.705148 28708 net.cpp:129] Top shape: 16 32 224 224 (25690112)
I1010 15:38:53.706840 28708 net.cpp:137] Memory required for data: 645464064
I1010 15:38:53.708559 28708 layer_factory.hpp:77] Creating layer pool1
I1010 15:38:53.710264 28708 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I1010 15:38:53.712018 28708 net.cpp:84] Creating Layer pool1
I1010 15:38:53.713778 28708 net.cpp:406] pool1 <- conv1_2
I1010 15:38:53.715543 28708 net.cpp:380] pool1 -> pool1
I1010 15:38:53.717300 28708 net.cpp:380] pool1 -> pool1_mask
I1010 15:38:53.719094 28708 net.cpp:380] pool1 -> pool1_argmax_count
I1010 15:38:53.720993 28708 net.cpp:122] Setting up pool1
I1010 15:38:53.722801 28708 net.cpp:129] Top shape: 16 32 56 56 (1605632)
I1010 15:38:53.724620 28708 net.cpp:129] Top shape: 16 32 56 56 (1605632)
I1010 15:38:53.726434 28708 net.cpp:129] Top shape: 16 32 224 224 (25690112)
I1010 15:38:53.728236 28708 net.cpp:137] Memory required for data: 761069568
I1010 15:38:53.730072 28708 layer_factory.hpp:77] Creating layer conv2_1
I1010 15:38:53.731914 28708 net.cpp:84] Creating Layer conv2_1
I1010 15:38:53.733728 28708 net.cpp:406] conv2_1 <- pool1
I1010 15:38:53.735565 28708 net.cpp:380] conv2_1 -> conv2_1
I1010 15:38:53.740265 28708 net.cpp:122] Setting up conv2_1
I1010 15:38:53.742105 28708 net.cpp:129] Top shape: 16 64 56 56 (3211264)
I1010 15:38:53.743959 28708 net.cpp:137] Memory required for data: 773914624
I1010 15:38:53.745816 28708 layer_factory.hpp:77] Creating layer batchnorm2_1
I1010 15:38:53.747683 28708 net.cpp:84] Creating Layer batchnorm2_1
I1010 15:38:53.749547 28708 net.cpp:406] batchnorm2_1 <- conv2_1
I1010 15:38:53.751386 28708 net.cpp:367] batchnorm2_1 -> conv2_1 (in-place)
I1010 15:38:53.753448 28708 net.cpp:122] Setting up batchnorm2_1
I1010 15:38:53.755339 28708 net.cpp:129] Top shape: 16 64 56 56 (3211264)
I1010 15:38:53.757243 28708 net.cpp:137] Memory required for data: 786759680
I1010 15:38:53.759143 28708 layer_factory.hpp:77] Creating layer elu2_1
I1010 15:38:53.761056 28708 net.cpp:84] Creating Layer elu2_1
I1010 15:38:53.762977 28708 net.cpp:406] elu2_1 <- conv2_1
I1010 15:38:53.764904 28708 net.cpp:367] elu2_1 -> conv2_1 (in-place)
I1010 15:38:53.766816 28708 net.cpp:122] Setting up elu2_1
I1010 15:38:53.768741 28708 net.cpp:129] Top shape: 16 64 56 56 (3211264)
I1010 15:38:53.770684 28708 net.cpp:137] Memory required for data: 799604736
I1010 15:38:53.772632 28708 layer_factory.hpp:77] Creating layer conv2_2
I1010 15:38:53.774595 28708 net.cpp:84] Creating Layer conv2_2
I1010 15:38:53.776566 28708 net.cpp:406] conv2_2 <- conv2_1
I1010 15:38:53.778524 28708 net.cpp:380] conv2_2 -> conv2_2
I1010 15:38:53.782611 28708 net.cpp:122] Setting up conv2_2
I1010 15:38:53.784593 28708 net.cpp:129] Top shape: 16 64 56 56 (3211264)
I1010 15:38:53.786594 28708 net.cpp:137] Memory required for data: 812449792
I1010 15:38:53.788638 28708 layer_factory.hpp:77] Creating layer batchnorm2_2
I1010 15:38:53.790634 28708 net.cpp:84] Creating Layer batchnorm2_2
I1010 15:38:53.792666 28708 net.cpp:406] batchnorm2_2 <- conv2_2
I1010 15:38:53.794709 28708 net.cpp:367] batchnorm2_2 -> conv2_2 (in-place)
I1010 15:38:53.796941 28708 net.cpp:122] Setting up batchnorm2_2
I1010 15:38:53.798993 28708 net.cpp:129] Top shape: 16 64 56 56 (3211264)
I1010 15:38:53.801046 28708 net.cpp:137] Memory required for data: 825294848
I1010 15:38:53.803109 28708 layer_factory.hpp:77] Creating layer elu2_2
I1010 15:38:53.805212 28708 net.cpp:84] Creating Layer elu2_2
I1010 15:38:53.807301 28708 net.cpp:406] elu2_2 <- conv2_2
I1010 15:38:53.809392 28708 net.cpp:367] elu2_2 -> conv2_2 (in-place)
I1010 15:38:53.811497 28708 net.cpp:122] Setting up elu2_2
I1010 15:38:53.813597 28708 net.cpp:129] Top shape: 16 64 56 56 (3211264)
I1010 15:38:53.815717 28708 net.cpp:137] Memory required for data: 838139904
I1010 15:38:53.817808 28708 layer_factory.hpp:77] Creating layer pool2
I1010 15:38:53.819924 28708 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I1010 15:38:53.822104 28708 net.cpp:84] Creating Layer pool2
I1010 15:38:53.824287 28708 net.cpp:406] pool2 <- conv2_2
I1010 15:38:53.826472 28708 net.cpp:380] pool2 -> pool2
I1010 15:38:53.828646 28708 net.cpp:380] pool2 -> pool2_mask
I1010 15:38:53.830842 28708 net.cpp:380] pool2 -> pool2_argmax_count
I1010 15:38:53.833082 28708 net.cpp:122] Setting up pool2
I1010 15:38:53.835253 28708 net.cpp:129] Top shape: 16 64 14 14 (200704)
I1010 15:38:53.837482 28708 net.cpp:129] Top shape: 16 64 14 14 (200704)
I1010 15:38:53.839680 28708 net.cpp:129] Top shape: 16 64 56 56 (3211264)
I1010 15:38:53.841894 28708 net.cpp:137] Memory required for data: 852590592
I1010 15:38:53.844121 28708 layer_factory.hpp:77] Creating layer conv3_1
I1010 15:38:53.846343 28708 net.cpp:84] Creating Layer conv3_1
I1010 15:38:53.848597 28708 net.cpp:406] conv3_1 <- pool2
I1010 15:38:53.850795 28708 net.cpp:380] conv3_1 -> conv3_1
I1010 15:38:53.855928 28708 net.cpp:122] Setting up conv3_1
I1010 15:38:53.858191 28708 net.cpp:129] Top shape: 16 128 14 14 (401408)
I1010 15:38:53.860407 28708 net.cpp:137] Memory required for data: 854196224
I1010 15:38:53.862644 28708 layer_factory.hpp:77] Creating layer batchnorm3_1
I1010 15:38:53.864893 28708 net.cpp:84] Creating Layer batchnorm3_1
I1010 15:38:53.867092 28708 net.cpp:406] batchnorm3_1 <- conv3_1
I1010 15:38:53.869320 28708 net.cpp:367] batchnorm3_1 -> conv3_1 (in-place)
I1010 15:38:53.871745 28708 net.cpp:122] Setting up batchnorm3_1
I1010 15:38:53.873957 28708 net.cpp:129] Top shape: 16 128 14 14 (401408)
I1010 15:38:53.876168 28708 net.cpp:137] Memory required for data: 855801856
I1010 15:38:53.878361 28708 layer_factory.hpp:77] Creating layer elu3_1
I1010 15:38:53.880591 28708 net.cpp:84] Creating Layer elu3_1
I1010 15:38:53.882786 28708 net.cpp:406] elu3_1 <- conv3_1
I1010 15:38:53.884963 28708 net.cpp:367] elu3_1 -> conv3_1 (in-place)
I1010 15:38:53.887161 28708 net.cpp:122] Setting up elu3_1
I1010 15:38:53.889353 28708 net.cpp:129] Top shape: 16 128 14 14 (401408)
I1010 15:38:53.891546 28708 net.cpp:137] Memory required for data: 857407488
I1010 15:38:53.893736 28708 layer_factory.hpp:77] Creating layer conv3_2
I1010 15:38:53.895929 28708 net.cpp:84] Creating Layer conv3_2
I1010 15:38:53.898138 28708 net.cpp:406] conv3_2 <- conv3_1
I1010 15:38:53.900321 28708 net.cpp:380] conv3_2 -> conv3_2
I1010 15:38:53.905550 28708 net.cpp:122] Setting up conv3_2
I1010 15:38:53.907749 28708 net.cpp:129] Top shape: 16 128 14 14 (401408)
I1010 15:38:53.909948 28708 net.cpp:137] Memory required for data: 859013120
I1010 15:38:53.912134 28708 layer_factory.hpp:77] Creating layer batchnorm3_2
I1010 15:38:53.914331 28708 net.cpp:84] Creating Layer batchnorm3_2
I1010 15:38:53.916520 28708 net.cpp:406] batchnorm3_2 <- conv3_2
I1010 15:38:53.918671 28708 net.cpp:367] batchnorm3_2 -> conv3_2 (in-place)
I1010 15:38:53.921053 28708 net.cpp:122] Setting up batchnorm3_2
I1010 15:38:53.923234 28708 net.cpp:129] Top shape: 16 128 14 14 (401408)
I1010 15:38:53.925446 28708 net.cpp:137] Memory required for data: 860618752
I1010 15:38:53.927644 28708 layer_factory.hpp:77] Creating layer elu3_2
I1010 15:38:53.929819 28708 net.cpp:84] Creating Layer elu3_2
I1010 15:38:53.932024 28708 net.cpp:406] elu3_2 <- conv3_2
I1010 15:38:53.934183 28708 net.cpp:367] elu3_2 -> conv3_2 (in-place)
I1010 15:38:53.936373 28708 net.cpp:122] Setting up elu3_2
I1010 15:38:53.938539 28708 net.cpp:129] Top shape: 16 128 14 14 (401408)
I1010 15:38:53.940732 28708 net.cpp:137] Memory required for data: 862224384
I1010 15:38:53.942905 28708 layer_factory.hpp:77] Creating layer conv3_3
I1010 15:38:53.945086 28708 net.cpp:84] Creating Layer conv3_3
I1010 15:38:53.947283 28708 net.cpp:406] conv3_3 <- conv3_2
I1010 15:38:53.949461 28708 net.cpp:380] conv3_3 -> conv3_3
I1010 15:38:53.954980 28708 net.cpp:122] Setting up conv3_3
I1010 15:38:53.957195 28708 net.cpp:129] Top shape: 16 128 14 14 (401408)
I1010 15:38:53.959378 28708 net.cpp:137] Memory required for data: 863830016
I1010 15:38:53.961560 28708 layer_factory.hpp:77] Creating layer batchnorm3_3
I1010 15:38:53.963779 28708 net.cpp:84] Creating Layer batchnorm3_3
I1010 15:38:53.965979 28708 net.cpp:406] batchnorm3_3 <- conv3_3
I1010 15:38:53.968147 28708 net.cpp:367] batchnorm3_3 -> conv3_3 (in-place)
I1010 15:38:53.970527 28708 net.cpp:122] Setting up batchnorm3_3
I1010 15:38:53.972721 28708 net.cpp:129] Top shape: 16 128 14 14 (401408)
I1010 15:38:53.974897 28708 net.cpp:137] Memory required for data: 865435648
I1010 15:38:53.977095 28708 layer_factory.hpp:77] Creating layer elu3_3
I1010 15:38:53.979282 28708 net.cpp:84] Creating Layer elu3_3
I1010 15:38:53.981489 28708 net.cpp:406] elu3_3 <- conv3_3
I1010 15:38:53.983669 28708 net.cpp:367] elu3_3 -> conv3_3 (in-place)
I1010 15:38:53.985841 28708 net.cpp:122] Setting up elu3_3
I1010 15:38:53.988029 28708 net.cpp:129] Top shape: 16 128 14 14 (401408)
I1010 15:38:53.990200 28708 net.cpp:137] Memory required for data: 867041280
I1010 15:38:53.992393 28708 layer_factory.hpp:77] Creating layer pool3
I1010 15:38:53.994580 28708 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I1010 15:38:53.996799 28708 net.cpp:84] Creating Layer pool3
I1010 15:38:53.999028 28708 net.cpp:406] pool3 <- conv3_3
I1010 15:38:54.001216 28708 net.cpp:380] pool3 -> pool3
I1010 15:38:54.003434 28708 net.cpp:380] pool3 -> pool3_mask
I1010 15:38:54.005633 28708 net.cpp:380] pool3 -> pool3_argmax_count
I1010 15:38:54.007859 28708 net.cpp:122] Setting up pool3
I1010 15:38:54.010020 28708 net.cpp:129] Top shape: 16 128 7 7 (100352)
I1010 15:38:54.012192 28708 net.cpp:129] Top shape: 16 128 7 7 (100352)
I1010 15:38:54.014359 28708 net.cpp:129] Top shape: 16 128 14 14 (401408)
I1010 15:38:54.016525 28708 net.cpp:137] Memory required for data: 869449728
I1010 15:38:54.018676 28708 layer_factory.hpp:77] Creating layer conv4_1
I1010 15:38:54.020879 28708 net.cpp:84] Creating Layer conv4_1
I1010 15:38:54.023051 28708 net.cpp:406] conv4_1 <- pool3
I1010 15:38:54.025230 28708 net.cpp:380] conv4_1 -> conv4_1
I1010 15:38:54.070819 28708 net.cpp:122] Setting up conv4_1
I1010 15:38:54.073040 28708 net.cpp:129] Top shape: 16 1024 1 1 (16384)
I1010 15:38:54.075225 28708 net.cpp:137] Memory required for data: 869515264
I1010 15:38:54.077414 28708 layer_factory.hpp:77] Creating layer batchnorm4_1
I1010 15:38:54.079612 28708 net.cpp:84] Creating Layer batchnorm4_1
I1010 15:38:54.081779 28708 net.cpp:406] batchnorm4_1 <- conv4_1
I1010 15:38:54.083950 28708 net.cpp:367] batchnorm4_1 -> conv4_1 (in-place)
I1010 15:38:54.086334 28708 net.cpp:122] Setting up batchnorm4_1
I1010 15:38:54.088516 28708 net.cpp:129] Top shape: 16 1024 1 1 (16384)
I1010 15:38:54.090697 28708 net.cpp:137] Memory required for data: 869580800
I1010 15:38:54.092890 28708 layer_factory.hpp:77] Creating layer elu4_1
I1010 15:38:54.095080 28708 net.cpp:84] Creating Layer elu4_1
I1010 15:38:54.097270 28708 net.cpp:406] elu4_1 <- conv4_1
I1010 15:38:54.099448 28708 net.cpp:367] elu4_1 -> conv4_1 (in-place)
I1010 15:38:54.101619 28708 net.cpp:122] Setting up elu4_1
I1010 15:38:54.103790 28708 net.cpp:129] Top shape: 16 1024 1 1 (16384)
I1010 15:38:54.105967 28708 net.cpp:137] Memory required for data: 869646336
I1010 15:38:54.108147 28708 layer_factory.hpp:77] Creating layer conv4_2
I1010 15:38:54.110327 28708 net.cpp:84] Creating Layer conv4_2
I1010 15:38:54.112519 28708 net.cpp:406] conv4_2 <- conv4_1
I1010 15:38:54.114706 28708 net.cpp:380] conv4_2 -> conv4_2
I1010 15:38:54.126379 28708 net.cpp:122] Setting up conv4_2
I1010 15:38:54.128590 28708 net.cpp:129] Top shape: 16 1024 1 1 (16384)
I1010 15:38:54.130789 28708 net.cpp:137] Memory required for data: 869711872
I1010 15:38:54.132962 28708 layer_factory.hpp:77] Creating layer batchnorm4_2
I1010 15:38:54.135121 28708 net.cpp:84] Creating Layer batchnorm4_2
I1010 15:38:54.137295 28708 net.cpp:406] batchnorm4_2 <- conv4_2
I1010 15:38:54.139474 28708 net.cpp:367] batchnorm4_2 -> conv4_2 (in-place)
I1010 15:38:54.141855 28708 net.cpp:122] Setting up batchnorm4_2
I1010 15:38:54.144029 28708 net.cpp:129] Top shape: 16 1024 1 1 (16384)
I1010 15:38:54.146217 28708 net.cpp:137] Memory required for data: 869777408
I1010 15:38:54.148404 28708 layer_factory.hpp:77] Creating layer elu4_2
I1010 15:38:54.150560 28708 net.cpp:84] Creating Layer elu4_2
I1010 15:38:54.152730 28708 net.cpp:406] elu4_2 <- conv4_2
I1010 15:38:54.154896 28708 net.cpp:367] elu4_2 -> conv4_2 (in-place)
I1010 15:38:54.157061 28708 net.cpp:122] Setting up elu4_2
I1010 15:38:54.159205 28708 net.cpp:129] Top shape: 16 1024 1 1 (16384)
I1010 15:38:54.161379 28708 net.cpp:137] Memory required for data: 869842944
I1010 15:38:54.163523 28708 layer_factory.hpp:77] Creating layer deconv4_3
I1010 15:38:54.165693 28708 net.cpp:84] Creating Layer deconv4_3
I1010 15:38:54.167845 28708 net.cpp:406] deconv4_3 <- conv4_2
I1010 15:38:54.170019 28708 net.cpp:380] deconv4_3 -> deconv4_3
I1010 15:38:54.213105 28708 net.cpp:122] Setting up deconv4_3
I1010 15:38:54.215291 28708 net.cpp:129] Top shape: 16 128 7 7 (100352)
I1010 15:38:54.217427 28708 net.cpp:137] Memory required for data: 870244352
I1010 15:38:54.219576 28708 layer_factory.hpp:77] Creating layer debatchnorm4_3
I1010 15:38:54.221766 28708 net.cpp:84] Creating Layer debatchnorm4_3
I1010 15:38:54.223901 28708 net.cpp:406] debatchnorm4_3 <- deconv4_3
I1010 15:38:54.226034 28708 net.cpp:367] debatchnorm4_3 -> deconv4_3 (in-place)
I1010 15:38:54.228389 28708 net.cpp:122] Setting up debatchnorm4_3
I1010 15:38:54.230568 28708 net.cpp:129] Top shape: 16 128 7 7 (100352)
I1010 15:38:54.232710 28708 net.cpp:137] Memory required for data: 870645760
I1010 15:38:54.234840 28708 layer_factory.hpp:77] Creating layer deelu4_3
I1010 15:38:54.236996 28708 net.cpp:84] Creating Layer deelu4_3
I1010 15:38:54.239146 28708 net.cpp:406] deelu4_3 <- deconv4_3
I1010 15:38:54.241293 28708 net.cpp:367] deelu4_3 -> deconv4_3 (in-place)
I1010 15:38:54.243446 28708 net.cpp:122] Setting up deelu4_3
I1010 15:38:54.245620 28708 net.cpp:129] Top shape: 16 128 7 7 (100352)
I1010 15:38:54.247758 28708 net.cpp:137] Memory required for data: 871047168
I1010 15:38:54.249918 28708 layer_factory.hpp:77] Creating layer unpool3
I1010 15:38:54.252069 28708 net.cpp:84] Creating Layer unpool3
I1010 15:38:54.254237 28708 net.cpp:406] unpool3 <- deconv4_3
I1010 15:38:54.256386 28708 net.cpp:406] unpool3 <- pool3_mask
I1010 15:38:54.258538 28708 net.cpp:406] unpool3 <- pool3_argmax_count
I1010 15:38:54.260679 28708 net.cpp:380] unpool3 -> unpool3
I1010 15:38:54.262838 28708 net.cpp:122] Setting up unpool3
I1010 15:38:54.264986 28708 net.cpp:129] Top shape: 16 128 14 14 (401408)
I1010 15:38:54.267108 28708 net.cpp:137] Memory required for data: 872652800
I1010 15:38:54.269251 28708 layer_factory.hpp:77] Creating layer deconv3_1
I1010 15:38:54.271394 28708 net.cpp:84] Creating Layer deconv3_1
I1010 15:38:54.273526 28708 net.cpp:406] deconv3_1 <- unpool3
I1010 15:38:54.275712 28708 net.cpp:380] deconv3_1 -> deconv3_1
I1010 15:38:54.279661 28708 net.cpp:122] Setting up deconv3_1
I1010 15:38:54.281802 28708 net.cpp:129] Top shape: 16 128 14 14 (401408)
I1010 15:38:54.283923 28708 net.cpp:137] Memory required for data: 874258432
I1010 15:38:54.286058 28708 layer_factory.hpp:77] Creating layer debatchnorm3_1
I1010 15:38:54.288208 28708 net.cpp:84] Creating Layer debatchnorm3_1
I1010 15:38:54.290341 28708 net.cpp:406] debatchnorm3_1 <- deconv3_1
I1010 15:38:54.292479 28708 net.cpp:367] debatchnorm3_1 -> deconv3_1 (in-place)
I1010 15:38:54.294816 28708 net.cpp:122] Setting up debatchnorm3_1
I1010 15:38:54.296978 28708 net.cpp:129] Top shape: 16 128 14 14 (401408)
I1010 15:38:54.299129 28708 net.cpp:137] Memory required for data: 875864064
I1010 15:38:54.301275 28708 layer_factory.hpp:77] Creating layer deelu3_1
I1010 15:38:54.303423 28708 net.cpp:84] Creating Layer deelu3_1
I1010 15:38:54.305567 28708 net.cpp:406] deelu3_1 <- deconv3_1
I1010 15:38:54.307708 28708 net.cpp:367] deelu3_1 -> deconv3_1 (in-place)
I1010 15:38:54.309844 28708 net.cpp:122] Setting up deelu3_1
I1010 15:38:54.311982 28708 net.cpp:129] Top shape: 16 128 14 14 (401408)
I1010 15:38:54.314149 28708 net.cpp:137] Memory required for data: 877469696
I1010 15:38:54.316318 28708 layer_factory.hpp:77] Creating layer deconv3_2
I1010 15:38:54.318452 28708 net.cpp:84] Creating Layer deconv3_2
I1010 15:38:54.320612 28708 net.cpp:406] deconv3_2 <- deconv3_1
I1010 15:38:54.322762 28708 net.cpp:380] deconv3_2 -> deconv3_2
I1010 15:38:54.326753 28708 net.cpp:122] Setting up deconv3_2
I1010 15:38:54.328943 28708 net.cpp:129] Top shape: 16 128 14 14 (401408)
I1010 15:38:54.331085 28708 net.cpp:137] Memory required for data: 879075328
I1010 15:38:54.333240 28708 layer_factory.hpp:77] Creating layer debatchnorm3_2
I1010 15:38:54.335386 28708 net.cpp:84] Creating Layer debatchnorm3_2
I1010 15:38:54.337530 28708 net.cpp:406] debatchnorm3_2 <- deconv3_2
I1010 15:38:54.339679 28708 net.cpp:367] debatchnorm3_2 -> deconv3_2 (in-place)
I1010 15:38:54.342015 28708 net.cpp:122] Setting up debatchnorm3_2
I1010 15:38:54.344157 28708 net.cpp:129] Top shape: 16 128 14 14 (401408)
I1010 15:38:54.346321 28708 net.cpp:137] Memory required for data: 880680960
I1010 15:38:54.348474 28708 layer_factory.hpp:77] Creating layer deelu3_2
I1010 15:38:54.350616 28708 net.cpp:84] Creating Layer deelu3_2
I1010 15:38:54.352780 28708 net.cpp:406] deelu3_2 <- deconv3_2
I1010 15:38:54.354924 28708 net.cpp:367] deelu3_2 -> deconv3_2 (in-place)
I1010 15:38:54.357084 28708 net.cpp:122] Setting up deelu3_2
I1010 15:38:54.359256 28708 net.cpp:129] Top shape: 16 128 14 14 (401408)
I1010 15:38:54.361407 28708 net.cpp:137] Memory required for data: 882286592
I1010 15:38:54.363559 28708 layer_factory.hpp:77] Creating layer deconv3_3
I1010 15:38:54.365718 28708 net.cpp:84] Creating Layer deconv3_3
I1010 15:38:54.367851 28708 net.cpp:406] deconv3_3 <- deconv3_2
I1010 15:38:54.370018 28708 net.cpp:380] deconv3_3 -> deconv3_3
I1010 15:38:54.372797 28708 net.cpp:122] Setting up deconv3_3
I1010 15:38:54.374932 28708 net.cpp:129] Top shape: 16 64 14 14 (200704)
I1010 15:38:54.377097 28708 net.cpp:137] Memory required for data: 883089408
I1010 15:38:54.379252 28708 layer_factory.hpp:77] Creating layer debatchnorm3_3
I1010 15:38:54.381405 28708 net.cpp:84] Creating Layer debatchnorm3_3
I1010 15:38:54.383549 28708 net.cpp:406] debatchnorm3_3 <- deconv3_3
I1010 15:38:54.385673 28708 net.cpp:367] debatchnorm3_3 -> deconv3_3 (in-place)
I1010 15:38:54.388015 28708 net.cpp:122] Setting up debatchnorm3_3
I1010 15:38:54.390127 28708 net.cpp:129] Top shape: 16 64 14 14 (200704)
I1010 15:38:54.392242 28708 net.cpp:137] Memory required for data: 883892224
I1010 15:38:54.394376 28708 layer_factory.hpp:77] Creating layer deelu3_3
I1010 15:38:54.396505 28708 net.cpp:84] Creating Layer deelu3_3
I1010 15:38:54.398632 28708 net.cpp:406] deelu3_3 <- deconv3_3
I1010 15:38:54.400753 28708 net.cpp:367] deelu3_3 -> deconv3_3 (in-place)
I1010 15:38:54.402899 28708 net.cpp:122] Setting up deelu3_3
I1010 15:38:54.405052 28708 net.cpp:129] Top shape: 16 64 14 14 (200704)
I1010 15:38:54.407204 28708 net.cpp:137] Memory required for data: 884695040
I1010 15:38:54.409342 28708 layer_factory.hpp:77] Creating layer unpool2
I1010 15:38:54.411494 28708 net.cpp:84] Creating Layer unpool2
I1010 15:38:54.413643 28708 net.cpp:406] unpool2 <- deconv3_3
I1010 15:38:54.415794 28708 net.cpp:406] unpool2 <- pool2_mask
I1010 15:38:54.417929 28708 net.cpp:406] unpool2 <- pool2_argmax_count
I1010 15:38:54.420068 28708 net.cpp:380] unpool2 -> unpool2
I1010 15:38:54.422225 28708 net.cpp:122] Setting up unpool2
I1010 15:38:54.424353 28708 net.cpp:129] Top shape: 16 64 56 56 (3211264)
I1010 15:38:54.426478 28708 net.cpp:137] Memory required for data: 897540096
I1010 15:38:54.428628 28708 layer_factory.hpp:77] Creating layer deconv2_1
I1010 15:38:54.430780 28708 net.cpp:84] Creating Layer deconv2_1
I1010 15:38:54.432916 28708 net.cpp:406] deconv2_1 <- unpool2
I1010 15:38:54.435036 28708 net.cpp:380] deconv2_1 -> deconv2_1
I1010 15:38:54.437631 28708 net.cpp:122] Setting up deconv2_1
I1010 15:38:54.439769 28708 net.cpp:129] Top shape: 16 64 56 56 (3211264)
I1010 15:38:54.441915 28708 net.cpp:137] Memory required for data: 910385152
I1010 15:38:54.444063 28708 layer_factory.hpp:77] Creating layer debatchnorm2_1
I1010 15:38:54.446257 28708 net.cpp:84] Creating Layer debatchnorm2_1
I1010 15:38:54.448416 28708 net.cpp:406] debatchnorm2_1 <- deconv2_1
I1010 15:38:54.450543 28708 net.cpp:367] debatchnorm2_1 -> deconv2_1 (in-place)
I1010 15:38:54.452895 28708 net.cpp:122] Setting up debatchnorm2_1
I1010 15:38:54.455035 28708 net.cpp:129] Top shape: 16 64 56 56 (3211264)
I1010 15:38:54.457195 28708 net.cpp:137] Memory required for data: 923230208
I1010 15:38:54.459345 28708 layer_factory.hpp:77] Creating layer deelu2_1
I1010 15:38:54.461519 28708 net.cpp:84] Creating Layer deelu2_1
I1010 15:38:54.463681 28708 net.cpp:406] deelu2_1 <- deconv2_1
I1010 15:38:54.465818 28708 net.cpp:367] deelu2_1 -> deconv2_1 (in-place)
I1010 15:38:54.467941 28708 net.cpp:122] Setting up deelu2_1
I1010 15:38:54.470082 28708 net.cpp:129] Top shape: 16 64 56 56 (3211264)
I1010 15:38:54.472247 28708 net.cpp:137] Memory required for data: 936075264
I1010 15:38:54.474400 28708 layer_factory.hpp:77] Creating layer deconv2_2
I1010 15:38:54.476546 28708 net.cpp:84] Creating Layer deconv2_2
I1010 15:38:54.478727 28708 net.cpp:406] deconv2_2 <- deconv2_1
I1010 15:38:54.480885 28708 net.cpp:380] deconv2_2 -> deconv2_2
I1010 15:38:54.483386 28708 net.cpp:122] Setting up deconv2_2
I1010 15:38:54.485498 28708 net.cpp:129] Top shape: 16 32 56 56 (1605632)
I1010 15:38:54.487659 28708 net.cpp:137] Memory required for data: 942497792
I1010 15:38:54.489802 28708 layer_factory.hpp:77] Creating layer debatchnorm2_2
I1010 15:38:54.491974 28708 net.cpp:84] Creating Layer debatchnorm2_2
I1010 15:38:54.494125 28708 net.cpp:406] debatchnorm2_2 <- deconv2_2
I1010 15:38:54.496280 28708 net.cpp:367] debatchnorm2_2 -> deconv2_2 (in-place)
I1010 15:38:54.498637 28708 net.cpp:122] Setting up debatchnorm2_2
I1010 15:38:54.500763 28708 net.cpp:129] Top shape: 16 32 56 56 (1605632)
I1010 15:38:54.502910 28708 net.cpp:137] Memory required for data: 948920320
I1010 15:38:54.505069 28708 layer_factory.hpp:77] Creating layer deelu2_2
I1010 15:38:54.507233 28708 net.cpp:84] Creating Layer deelu2_2
I1010 15:38:54.509397 28708 net.cpp:406] deelu2_2 <- deconv2_2
I1010 15:38:54.511595 28708 net.cpp:367] deelu2_2 -> deconv2_2 (in-place)
I1010 15:38:54.513772 28708 net.cpp:122] Setting up deelu2_2
I1010 15:38:54.515923 28708 net.cpp:129] Top shape: 16 32 56 56 (1605632)
I1010 15:38:54.518079 28708 net.cpp:137] Memory required for data: 955342848
I1010 15:38:54.520236 28708 layer_factory.hpp:77] Creating layer unpool1
I1010 15:38:54.522408 28708 net.cpp:84] Creating Layer unpool1
I1010 15:38:54.524577 28708 net.cpp:406] unpool1 <- deconv2_2
I1010 15:38:54.526759 28708 net.cpp:406] unpool1 <- pool1_mask
I1010 15:38:54.528928 28708 net.cpp:406] unpool1 <- pool1_argmax_count
I1010 15:38:54.531075 28708 net.cpp:380] unpool1 -> unpool1
I1010 15:38:54.533246 28708 net.cpp:122] Setting up unpool1
I1010 15:38:54.535379 28708 net.cpp:129] Top shape: 16 32 224 224 (25690112)
I1010 15:38:54.537549 28708 net.cpp:137] Memory required for data: 1058103296
I1010 15:38:54.539695 28708 layer_factory.hpp:77] Creating layer deconv1_1
I1010 15:38:54.541851 28708 net.cpp:84] Creating Layer deconv1_1
I1010 15:38:54.544008 28708 net.cpp:406] deconv1_1 <- unpool1
I1010 15:38:54.546146 28708 net.cpp:380] deconv1_1 -> deconv1_1
I1010 15:38:54.548601 28708 net.cpp:122] Setting up deconv1_1
I1010 15:38:54.550746 28708 net.cpp:129] Top shape: 16 32 224 224 (25690112)
I1010 15:38:54.552908 28708 net.cpp:137] Memory required for data: 1160863744
I1010 15:38:54.555088 28708 layer_factory.hpp:77] Creating layer debatchnorm1_1
I1010 15:38:54.557277 28708 net.cpp:84] Creating Layer debatchnorm1_1
I1010 15:38:54.559460 28708 net.cpp:406] debatchnorm1_1 <- deconv1_1
I1010 15:38:54.561645 28708 net.cpp:367] debatchnorm1_1 -> deconv1_1 (in-place)
I1010 15:38:54.564046 28708 net.cpp:122] Setting up debatchnorm1_1
I1010 15:38:54.566231 28708 net.cpp:129] Top shape: 16 32 224 224 (25690112)
I1010 15:38:54.568388 28708 net.cpp:137] Memory required for data: 1263624192
I1010 15:38:54.570582 28708 layer_factory.hpp:77] Creating layer deelu1_1
I1010 15:38:54.572793 28708 net.cpp:84] Creating Layer deelu1_1
I1010 15:38:54.574988 28708 net.cpp:406] deelu1_1 <- deconv1_1
I1010 15:38:54.577158 28708 net.cpp:367] deelu1_1 -> deconv1_1 (in-place)
I1010 15:38:54.579329 28708 net.cpp:122] Setting up deelu1_1
I1010 15:38:54.581526 28708 net.cpp:129] Top shape: 16 32 224 224 (25690112)
I1010 15:38:54.583701 28708 net.cpp:137] Memory required for data: 1366384640
I1010 15:38:54.585886 28708 layer_factory.hpp:77] Creating layer deconv1_2
I1010 15:38:54.588109 28708 net.cpp:84] Creating Layer deconv1_2
I1010 15:38:54.590318 28708 net.cpp:406] deconv1_2 <- deconv1_1
I1010 15:38:54.592514 28708 net.cpp:380] deconv1_2 -> deconv1_2
I1010 15:38:54.595036 28708 net.cpp:122] Setting up deconv1_2
I1010 15:38:54.597218 28708 net.cpp:129] Top shape: 16 32 224 224 (25690112)
I1010 15:38:54.599411 28708 net.cpp:137] Memory required for data: 1469145088
I1010 15:38:54.601582 28708 layer_factory.hpp:77] Creating layer debatchnorm1_2
I1010 15:38:54.603806 28708 net.cpp:84] Creating Layer debatchnorm1_2
I1010 15:38:54.606001 28708 net.cpp:406] debatchnorm1_2 <- deconv1_2
I1010 15:38:54.608178 28708 net.cpp:367] debatchnorm1_2 -> deconv1_2 (in-place)
I1010 15:38:54.611408 28708 net.cpp:122] Setting up debatchnorm1_2
I1010 15:38:54.613620 28708 net.cpp:129] Top shape: 16 32 224 224 (25690112)
I1010 15:38:54.615821 28708 net.cpp:137] Memory required for data: 1571905536
I1010 15:38:54.617991 28708 layer_factory.hpp:77] Creating layer deelu1_2
I1010 15:38:54.620201 28708 net.cpp:84] Creating Layer deelu1_2
I1010 15:38:54.622370 28708 net.cpp:406] deelu1_2 <- deconv1_2
I1010 15:38:54.624577 28708 net.cpp:367] deelu1_2 -> deconv1_2 (in-place)
I1010 15:38:54.626775 28708 net.cpp:122] Setting up deelu1_2
I1010 15:38:54.628968 28708 net.cpp:129] Top shape: 16 32 224 224 (25690112)
I1010 15:38:54.631145 28708 net.cpp:137] Memory required for data: 1674665984
I1010 15:38:54.633337 28708 layer_factory.hpp:77] Creating layer segmentation
I1010 15:38:54.635530 28708 net.cpp:84] Creating Layer segmentation
I1010 15:38:54.637728 28708 net.cpp:406] segmentation <- deconv1_2
I1010 15:38:54.639935 28708 net.cpp:380] segmentation -> segmentation
I1010 15:38:54.644544 28708 net.cpp:122] Setting up segmentation
I1010 15:38:54.646813 28708 net.cpp:129] Top shape: 16 3 224 224 (2408448)
I1010 15:38:54.648998 28708 net.cpp:137] Memory required for data: 1684299776
I1010 15:38:54.651191 28708 layer_factory.hpp:77] Creating layer infogainLoss
I1010 15:38:54.653389 28708 net.cpp:84] Creating Layer infogainLoss
I1010 15:38:54.655589 28708 net.cpp:406] infogainLoss <- segmentation
I1010 15:38:54.657788 28708 net.cpp:406] infogainLoss <- label
I1010 15:38:54.659998 28708 net.cpp:380] infogainLoss -> loss
I1010 15:38:54.662233 28708 layer_factory.hpp:77] Creating layer infogainLoss
I1010 15:38:54.669914 28708 net.cpp:122] Setting up infogainLoss
I1010 15:38:54.672209 28708 net.cpp:129] Top shape: (1)
I1010 15:38:54.674434 28708 net.cpp:132]     with loss weight 1
I1010 15:38:54.676681 28708 net.cpp:137] Memory required for data: 1684299780
I1010 15:38:54.678891 28708 net.cpp:198] infogainLoss needs backward computation.
I1010 15:38:54.681121 28708 net.cpp:198] segmentation needs backward computation.
I1010 15:38:54.683351 28708 net.cpp:198] deelu1_2 needs backward computation.
I1010 15:38:54.685551 28708 net.cpp:198] debatchnorm1_2 needs backward computation.
I1010 15:38:54.687779 28708 net.cpp:198] deconv1_2 needs backward computation.
I1010 15:38:54.690004 28708 net.cpp:198] deelu1_1 needs backward computation.
I1010 15:38:54.692242 28708 net.cpp:198] debatchnorm1_1 needs backward computation.
I1010 15:38:54.694475 28708 net.cpp:198] deconv1_1 needs backward computation.
I1010 15:38:54.696688 28708 net.cpp:198] unpool1 needs backward computation.
I1010 15:38:54.698909 28708 net.cpp:198] deelu2_2 needs backward computation.
I1010 15:38:54.701110 28708 net.cpp:198] debatchnorm2_2 needs backward computation.
I1010 15:38:54.703330 28708 net.cpp:198] deconv2_2 needs backward computation.
I1010 15:38:54.705581 28708 net.cpp:198] deelu2_1 needs backward computation.
I1010 15:38:54.707785 28708 net.cpp:198] debatchnorm2_1 needs backward computation.
I1010 15:38:54.710005 28708 net.cpp:198] deconv2_1 needs backward computation.
I1010 15:38:54.712218 28708 net.cpp:198] unpool2 needs backward computation.
I1010 15:38:54.714435 28708 net.cpp:198] deelu3_3 needs backward computation.
I1010 15:38:54.716639 28708 net.cpp:198] debatchnorm3_3 needs backward computation.
I1010 15:38:54.718830 28708 net.cpp:198] deconv3_3 needs backward computation.
I1010 15:38:54.721052 28708 net.cpp:198] deelu3_2 needs backward computation.
I1010 15:38:54.723275 28708 net.cpp:198] debatchnorm3_2 needs backward computation.
I1010 15:38:54.725509 28708 net.cpp:198] deconv3_2 needs backward computation.
I1010 15:38:54.727717 28708 net.cpp:198] deelu3_1 needs backward computation.
I1010 15:38:54.729928 28708 net.cpp:198] debatchnorm3_1 needs backward computation.
I1010 15:38:54.732134 28708 net.cpp:198] deconv3_1 needs backward computation.
I1010 15:38:54.734336 28708 net.cpp:198] unpool3 needs backward computation.
I1010 15:38:54.736555 28708 net.cpp:198] deelu4_3 needs backward computation.
I1010 15:38:54.738770 28708 net.cpp:198] debatchnorm4_3 needs backward computation.
I1010 15:38:54.741008 28708 net.cpp:198] deconv4_3 needs backward computation.
I1010 15:38:54.743203 28708 net.cpp:198] elu4_2 needs backward computation.
I1010 15:38:54.745429 28708 net.cpp:198] batchnorm4_2 needs backward computation.
I1010 15:38:54.747640 28708 net.cpp:198] conv4_2 needs backward computation.
I1010 15:38:54.749847 28708 net.cpp:198] elu4_1 needs backward computation.
I1010 15:38:54.752044 28708 net.cpp:198] batchnorm4_1 needs backward computation.
I1010 15:38:54.754278 28708 net.cpp:198] conv4_1 needs backward computation.
I1010 15:38:54.756485 28708 net.cpp:198] pool3 needs backward computation.
I1010 15:38:54.758694 28708 net.cpp:198] elu3_3 needs backward computation.
I1010 15:38:54.760916 28708 net.cpp:198] batchnorm3_3 needs backward computation.
I1010 15:38:54.763125 28708 net.cpp:198] conv3_3 needs backward computation.
I1010 15:38:54.765347 28708 net.cpp:198] elu3_2 needs backward computation.
I1010 15:38:54.767524 28708 net.cpp:198] batchnorm3_2 needs backward computation.
I1010 15:38:54.769742 28708 net.cpp:198] conv3_2 needs backward computation.
I1010 15:38:54.771947 28708 net.cpp:198] elu3_1 needs backward computation.
I1010 15:38:54.774170 28708 net.cpp:198] batchnorm3_1 needs backward computation.
I1010 15:38:54.776387 28708 net.cpp:198] conv3_1 needs backward computation.
I1010 15:38:54.778569 28708 net.cpp:198] pool2 needs backward computation.
I1010 15:38:54.780745 28708 net.cpp:198] elu2_2 needs backward computation.
I1010 15:38:54.782948 28708 net.cpp:198] batchnorm2_2 needs backward computation.
I1010 15:38:54.785126 28708 net.cpp:198] conv2_2 needs backward computation.
I1010 15:38:54.787310 28708 net.cpp:198] elu2_1 needs backward computation.
I1010 15:38:54.789595 28708 net.cpp:198] batchnorm2_1 needs backward computation.
I1010 15:38:54.791812 28708 net.cpp:198] conv2_1 needs backward computation.
I1010 15:38:54.794024 28708 net.cpp:198] pool1 needs backward computation.
I1010 15:38:54.796227 28708 net.cpp:198] elu1_2 needs backward computation.
I1010 15:38:54.798424 28708 net.cpp:198] batchnorm1_2 needs backward computation.
I1010 15:38:54.800602 28708 net.cpp:198] conv1_2 needs backward computation.
I1010 15:38:54.802816 28708 net.cpp:198] elu1_1 needs backward computation.
I1010 15:38:54.804996 28708 net.cpp:198] batchnorm1_1 needs backward computation.
I1010 15:38:54.807188 28708 net.cpp:198] conv1_1 needs backward computation.
I1010 15:38:54.809382 28708 net.cpp:198] batchnorm0 needs backward computation.
I1010 15:38:54.811573 28708 net.cpp:200] data does not need backward computation.
I1010 15:38:54.813757 28708 net.cpp:242] This network produces output loss
I1010 15:38:54.815985 28708 net.cpp:255] Network initialization done.
I1010 15:38:54.818609 28708 solver.cpp:172] Creating test net (#0) specified by net file: train_val.prototxt
I1010 15:38:54.820902 28708 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1010 15:38:54.823418 28708 net.cpp:51] Initializing net from parameters: 
name: "ZNet3"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/home/grochette/Documents/SegNet/data/HDF5/Validation/hdf5_list.txt"
    batch_size: 2
  }
}
layer {
  name: "batchnorm0"
  type: "BatchNorm"
  bottom: "data"
  top: "data"
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchnorm1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "elu1_1"
  type: "ELU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchnorm1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "elu1_2"
  type: "ELU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  top: "pool1_argmax_count"
  pooling_param {
    pool: MAX
    kernel_size: 4
    stride: 4
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchnorm2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "elu2_1"
  type: "ELU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchnorm2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "elu2_2"
  type: "ELU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  top: "pool2_argmax_count"
  pooling_param {
    pool: MAX
    kernel_size: 4
    stride: 4
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchnorm3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "elu3_1"
  type: "ELU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchnorm3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "elu3_2"
  type: "ELU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchnorm3_3"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "elu3_3"
  type: "ELU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  top: "pool3_argmax_count"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchnorm4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "elu4_1"
  type: "ELU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "batchnorm4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "elu4_2"
  type: "ELU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "deconv4_3"
  type: "Deconvolution"
  bottom: "conv4_2"
  top: "deconv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 7
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "debatchnorm4_3"
  type: "BatchNorm"
  bottom: "deconv4_3"
  top: "deconv4_3"
}
layer {
  name: "deelu4_3"
  type: "ELU"
  bottom: "deconv4_3"
  top: "deconv4_3"
}
layer {
  name: "unpool3"
  type: "Unpooling"
  bottom: "deconv4_3"
  bottom: "pool3_mask"
  bottom: "pool3_argmax_count"
  top: "unpool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "deconv3_1"
  type: "Deconvolution"
  bottom: "unpool3"
  top: "deconv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "debatchnorm3_1"
  type: "BatchNorm"
  bottom: "deconv3_1"
  top: "deconv3_1"
}
layer {
  name: "deelu3_1"
  type: "ELU"
  bottom: "deconv3_1"
  top: "deconv3_1"
}
layer {
  name: "deconv3_2"
  type: "Deconvolution"
  bottom: "deconv3_1"
  top: "deconv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "debatchnorm3_2"
  type: "BatchNorm"
  bottom: "deconv3_2"
  top: "deconv3_2"
}
layer {
  name: "deelu3_2"
  type: "ELU"
  bottom: "deconv3_2"
  top: "deconv3_2"
}
layer {
  name: "deconv3_3"
  type: "Deconvolution"
  bottom: "deconv3_2"
  top: "deconv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "debatchnorm3_3"
  type: "BatchNorm"
  bottom: "deconv3_3"
  top: "deconv3_3"
}
layer {
  name: "deelu3_3"
  type: "ELU"
  bottom: "deconv3_3"
  top: "deconv3_3"
}
layer {
  name: "unpool2"
  type: "Unpooling"
  bottom: "deconv3_3"
  bottom: "pool2_mask"
  bottom: "pool2_argmax_count"
  top: "unpool2"
  pooling_param {
    pool: MAX
    kernel_size: 4
    stride: 4
  }
}
layer {
  name: "deconv2_1"
  type: "Deconvolution"
  bottom: "unpool2"
  top: "deconv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "debatchnorm2_1"
  type: "BatchNorm"
  bottom: "deconv2_1"
  top: "deconv2_1"
}
layer {
  name: "deelu2_1"
  type: "ELU"
  bottom: "deconv2_1"
  top: "deconv2_1"
}
layer {
  name: "deconv2_2"
  type: "Deconvolution"
  bottom: "deconv2_1"
  top: "deconv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "debatchnorm2_2"
  type: "BatchNorm"
  bottom: "deconv2_2"
  top: "deconv2_2"
}
layer {
  name: "deelu2_2"
  type: "ELU"
  bottom: "deconv2_2"
  top: "deconv2_2"
}
layer {
  name: "unpool1"
  type: "Unpooling"
  bottom: "deconv2_2"
  bottom: "pool1_mask"
  bottom: "pool1_argmax_count"
  top: "unpool1"
  pooling_param {
    pool: MAX
    kernel_size: 4
    stride: 4
  }
}
layer {
  name: "deconv1_1"
  type: "Deconvolution"
  bottom: "unpool1"
  top: "deconv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "debatchnorm1_1"
  type: "BatchNorm"
  bottom: "deconv1_1"
  top: "deconv1_1"
}
layer {
  name: "deelu1_1"
  type: "ELU"
  bottom: "deconv1_1"
  top: "deconv1_1"
}
layer {
  name: "deconv1_2"
  type: "Deconvolution"
  bottom: "deconv1_1"
  top: "deconv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "debatchnorm1_2"
  type: "BatchNorm"
  bottom: "deconv1_2"
  top: "deconv1_2"
}
layer {
  name: "deelu1_2"
  type: "ELU"
  bottom: "deconv1_2"
  top: "deconv1_2"
}
layer {
  name: "segmentation"
  type: "Convolution"
  bottom: "deconv1_2"
  top: "segmentation"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 3
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "infogainLoss"
  type: "InfogainLoss"
  bottom: "segmentation"
  bottom: "label"
  top: "loss"
  loss_param {
    ignore_label: 3
  }
  infogain_loss_param {
    source: "/home/grochette/Documents/SegNet/data/OnlyVegas/infogainH.binaryproto"
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "segmentation"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
  include {
    phase: TEST
  }
  accuracy_param {
    ignore_label: 3
  }
}
I1010 15:38:55.823784 28708 layer_factory.hpp:77] Creating layer data
I1010 15:38:55.825008 28708 net.cpp:84] Creating Layer data
I1010 15:38:55.826251 28708 net.cpp:380] data -> data
I1010 15:38:55.827486 28708 net.cpp:380] data -> label
I1010 15:38:55.828718 28708 hdf5_data_layer.cpp:80] Loading list of HDF5 filenames from: /home/grochette/Documents/SegNet/data/HDF5/Validation/hdf5_list.txt
I1010 15:38:55.831029 28708 hdf5_data_layer.cpp:94] Number of HDF5 files: 2
I1010 15:38:58.456627 28708 net.cpp:122] Setting up data
I1010 15:38:58.457988 28708 net.cpp:129] Top shape: 2 4 224 224 (401408)
I1010 15:38:58.459308 28708 net.cpp:129] Top shape: 2 1 224 224 (100352)
I1010 15:38:58.460639 28708 net.cpp:137] Memory required for data: 2007040
I1010 15:38:58.461971 28708 layer_factory.hpp:77] Creating layer label_data_1_split
I1010 15:38:58.463330 28708 net.cpp:84] Creating Layer label_data_1_split
I1010 15:38:58.464682 28708 net.cpp:406] label_data_1_split <- label
I1010 15:38:58.466045 28708 net.cpp:380] label_data_1_split -> label_data_1_split_0
I1010 15:38:58.467407 28708 net.cpp:380] label_data_1_split -> label_data_1_split_1
I1010 15:38:58.468821 28708 net.cpp:122] Setting up label_data_1_split
I1010 15:38:58.470191 28708 net.cpp:129] Top shape: 2 1 224 224 (100352)
I1010 15:38:58.471580 28708 net.cpp:129] Top shape: 2 1 224 224 (100352)
I1010 15:38:58.472952 28708 net.cpp:137] Memory required for data: 2809856
I1010 15:38:58.474334 28708 layer_factory.hpp:77] Creating layer batchnorm0
I1010 15:38:58.475728 28708 net.cpp:84] Creating Layer batchnorm0
I1010 15:38:58.477121 28708 net.cpp:406] batchnorm0 <- data
I1010 15:38:58.478543 28708 net.cpp:367] batchnorm0 -> data (in-place)
I1010 15:38:58.480167 28708 net.cpp:122] Setting up batchnorm0
I1010 15:38:58.481580 28708 net.cpp:129] Top shape: 2 4 224 224 (401408)
I1010 15:38:58.482992 28708 net.cpp:137] Memory required for data: 4415488
I1010 15:38:58.484424 28708 layer_factory.hpp:77] Creating layer conv1_1
I1010 15:38:58.485880 28708 net.cpp:84] Creating Layer conv1_1
I1010 15:38:58.487329 28708 net.cpp:406] conv1_1 <- data
I1010 15:38:58.488790 28708 net.cpp:380] conv1_1 -> conv1_1
I1010 15:38:58.493083 28708 net.cpp:122] Setting up conv1_1
I1010 15:38:58.494556 28708 net.cpp:129] Top shape: 2 32 224 224 (3211264)
I1010 15:38:58.496027 28708 net.cpp:137] Memory required for data: 17260544
I1010 15:38:58.497514 28708 layer_factory.hpp:77] Creating layer batchnorm1_1
I1010 15:38:58.499003 28708 net.cpp:84] Creating Layer batchnorm1_1
I1010 15:38:58.500481 28708 net.cpp:406] batchnorm1_1 <- conv1_1
I1010 15:38:58.501976 28708 net.cpp:367] batchnorm1_1 -> conv1_1 (in-place)
I1010 15:38:58.503720 28708 net.cpp:122] Setting up batchnorm1_1
I1010 15:38:58.505233 28708 net.cpp:129] Top shape: 2 32 224 224 (3211264)
I1010 15:38:58.506758 28708 net.cpp:137] Memory required for data: 30105600
I1010 15:38:58.508301 28708 layer_factory.hpp:77] Creating layer elu1_1
I1010 15:38:58.509831 28708 net.cpp:84] Creating Layer elu1_1
I1010 15:38:58.511390 28708 net.cpp:406] elu1_1 <- conv1_1
I1010 15:38:58.512941 28708 net.cpp:367] elu1_1 -> conv1_1 (in-place)
I1010 15:38:58.514492 28708 net.cpp:122] Setting up elu1_1
I1010 15:38:58.516053 28708 net.cpp:129] Top shape: 2 32 224 224 (3211264)
I1010 15:38:58.517608 28708 net.cpp:137] Memory required for data: 42950656
I1010 15:38:58.519176 28708 layer_factory.hpp:77] Creating layer conv1_2
I1010 15:38:58.520762 28708 net.cpp:84] Creating Layer conv1_2
I1010 15:38:58.522358 28708 net.cpp:406] conv1_2 <- conv1_1
I1010 15:38:58.523967 28708 net.cpp:380] conv1_2 -> conv1_2
I1010 15:38:58.528067 28708 net.cpp:122] Setting up conv1_2
I1010 15:38:58.529690 28708 net.cpp:129] Top shape: 2 32 224 224 (3211264)
I1010 15:38:58.531302 28708 net.cpp:137] Memory required for data: 55795712
I1010 15:38:58.532944 28708 layer_factory.hpp:77] Creating layer batchnorm1_2
I1010 15:38:58.534571 28708 net.cpp:84] Creating Layer batchnorm1_2
I1010 15:38:58.536218 28708 net.cpp:406] batchnorm1_2 <- conv1_2
I1010 15:38:58.537866 28708 net.cpp:367] batchnorm1_2 -> conv1_2 (in-place)
I1010 15:38:58.539742 28708 net.cpp:122] Setting up batchnorm1_2
I1010 15:38:58.541398 28708 net.cpp:129] Top shape: 2 32 224 224 (3211264)
I1010 15:38:58.543089 28708 net.cpp:137] Memory required for data: 68640768
I1010 15:38:58.544849 28708 layer_factory.hpp:77] Creating layer elu1_2
I1010 15:38:58.546547 28708 net.cpp:84] Creating Layer elu1_2
I1010 15:38:58.548259 28708 net.cpp:406] elu1_2 <- conv1_2
I1010 15:38:58.549950 28708 net.cpp:367] elu1_2 -> conv1_2 (in-place)
I1010 15:38:58.551664 28708 net.cpp:122] Setting up elu1_2
I1010 15:38:58.553382 28708 net.cpp:129] Top shape: 2 32 224 224 (3211264)
I1010 15:38:58.555110 28708 net.cpp:137] Memory required for data: 81485824
I1010 15:38:58.556846 28708 layer_factory.hpp:77] Creating layer pool1
I1010 15:38:58.558599 28708 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I1010 15:38:58.560391 28708 net.cpp:84] Creating Layer pool1
I1010 15:38:58.562191 28708 net.cpp:406] pool1 <- conv1_2
I1010 15:38:58.564020 28708 net.cpp:380] pool1 -> pool1
I1010 15:38:58.565830 28708 net.cpp:380] pool1 -> pool1_mask
I1010 15:38:58.567627 28708 net.cpp:380] pool1 -> pool1_argmax_count
I1010 15:38:58.569497 28708 net.cpp:122] Setting up pool1
I1010 15:38:58.571317 28708 net.cpp:129] Top shape: 2 32 56 56 (200704)
I1010 15:38:58.573160 28708 net.cpp:129] Top shape: 2 32 56 56 (200704)
I1010 15:38:58.574987 28708 net.cpp:129] Top shape: 2 32 224 224 (3211264)
I1010 15:38:58.576808 28708 net.cpp:137] Memory required for data: 95936512
I1010 15:38:58.578640 28708 layer_factory.hpp:77] Creating layer conv2_1
I1010 15:38:58.580487 28708 net.cpp:84] Creating Layer conv2_1
I1010 15:38:58.582336 28708 net.cpp:406] conv2_1 <- pool1
I1010 15:38:58.584182 28708 net.cpp:380] conv2_1 -> conv2_1
I1010 15:38:58.588160 28708 net.cpp:122] Setting up conv2_1
I1010 15:38:58.590024 28708 net.cpp:129] Top shape: 2 64 56 56 (401408)
I1010 15:38:58.591917 28708 net.cpp:137] Memory required for data: 97542144
I1010 15:38:58.593791 28708 layer_factory.hpp:77] Creating layer batchnorm2_1
I1010 15:38:58.595695 28708 net.cpp:84] Creating Layer batchnorm2_1
I1010 15:38:58.597591 28708 net.cpp:406] batchnorm2_1 <- conv2_1
I1010 15:38:58.599504 28708 net.cpp:367] batchnorm2_1 -> conv2_1 (in-place)
I1010 15:38:58.601634 28708 net.cpp:122] Setting up batchnorm2_1
I1010 15:38:58.603561 28708 net.cpp:129] Top shape: 2 64 56 56 (401408)
I1010 15:38:58.605497 28708 net.cpp:137] Memory required for data: 99147776
I1010 15:38:58.607452 28708 layer_factory.hpp:77] Creating layer elu2_1
I1010 15:38:58.609395 28708 net.cpp:84] Creating Layer elu2_1
I1010 15:38:58.611366 28708 net.cpp:406] elu2_1 <- conv2_1
I1010 15:38:58.613312 28708 net.cpp:367] elu2_1 -> conv2_1 (in-place)
I1010 15:38:58.615268 28708 net.cpp:122] Setting up elu2_1
I1010 15:38:58.617233 28708 net.cpp:129] Top shape: 2 64 56 56 (401408)
I1010 15:38:58.619201 28708 net.cpp:137] Memory required for data: 100753408
I1010 15:38:58.621192 28708 layer_factory.hpp:77] Creating layer conv2_2
I1010 15:38:58.623208 28708 net.cpp:84] Creating Layer conv2_2
I1010 15:38:58.625200 28708 net.cpp:406] conv2_2 <- conv2_1
I1010 15:38:58.627218 28708 net.cpp:380] conv2_2 -> conv2_2
I1010 15:38:58.631752 28708 net.cpp:122] Setting up conv2_2
I1010 15:38:58.633780 28708 net.cpp:129] Top shape: 2 64 56 56 (401408)
I1010 15:38:58.635809 28708 net.cpp:137] Memory required for data: 102359040
I1010 15:38:58.637858 28708 layer_factory.hpp:77] Creating layer batchnorm2_2
I1010 15:38:58.639926 28708 net.cpp:84] Creating Layer batchnorm2_2
I1010 15:38:58.641979 28708 net.cpp:406] batchnorm2_2 <- conv2_2
I1010 15:38:58.644054 28708 net.cpp:367] batchnorm2_2 -> conv2_2 (in-place)
I1010 15:38:58.646361 28708 net.cpp:122] Setting up batchnorm2_2
I1010 15:38:58.648439 28708 net.cpp:129] Top shape: 2 64 56 56 (401408)
I1010 15:38:58.650528 28708 net.cpp:137] Memory required for data: 103964672
I1010 15:38:58.652634 28708 layer_factory.hpp:77] Creating layer elu2_2
I1010 15:38:58.654748 28708 net.cpp:84] Creating Layer elu2_2
I1010 15:38:58.656867 28708 net.cpp:406] elu2_2 <- conv2_2
I1010 15:38:58.658972 28708 net.cpp:367] elu2_2 -> conv2_2 (in-place)
I1010 15:38:58.661077 28708 net.cpp:122] Setting up elu2_2
I1010 15:38:58.663185 28708 net.cpp:129] Top shape: 2 64 56 56 (401408)
I1010 15:38:58.665307 28708 net.cpp:137] Memory required for data: 105570304
I1010 15:38:58.667415 28708 layer_factory.hpp:77] Creating layer pool2
I1010 15:38:58.669556 28708 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I1010 15:38:58.671730 28708 net.cpp:84] Creating Layer pool2
I1010 15:38:58.673936 28708 net.cpp:406] pool2 <- conv2_2
I1010 15:38:58.676120 28708 net.cpp:380] pool2 -> pool2
I1010 15:38:58.678324 28708 net.cpp:380] pool2 -> pool2_mask
I1010 15:38:58.680528 28708 net.cpp:380] pool2 -> pool2_argmax_count
I1010 15:38:58.682799 28708 net.cpp:122] Setting up pool2
I1010 15:38:58.685001 28708 net.cpp:129] Top shape: 2 64 14 14 (25088)
I1010 15:38:58.687221 28708 net.cpp:129] Top shape: 2 64 14 14 (25088)
I1010 15:38:58.689440 28708 net.cpp:129] Top shape: 2 64 56 56 (401408)
I1010 15:38:58.691653 28708 net.cpp:137] Memory required for data: 107376640
I1010 15:38:58.693871 28708 layer_factory.hpp:77] Creating layer conv3_1
I1010 15:38:58.696100 28708 net.cpp:84] Creating Layer conv3_1
I1010 15:38:58.698307 28708 net.cpp:406] conv3_1 <- pool2
I1010 15:38:58.700537 28708 net.cpp:380] conv3_1 -> conv3_1
I1010 15:38:58.705186 28708 net.cpp:122] Setting up conv3_1
I1010 15:38:58.707387 28708 net.cpp:129] Top shape: 2 128 14 14 (50176)
I1010 15:38:58.709574 28708 net.cpp:137] Memory required for data: 107577344
I1010 15:38:58.711763 28708 layer_factory.hpp:77] Creating layer batchnorm3_1
I1010 15:38:58.713953 28708 net.cpp:84] Creating Layer batchnorm3_1
I1010 15:38:58.716132 28708 net.cpp:406] batchnorm3_1 <- conv3_1
I1010 15:38:58.718300 28708 net.cpp:367] batchnorm3_1 -> conv3_1 (in-place)
I1010 15:38:58.720760 28708 net.cpp:122] Setting up batchnorm3_1
I1010 15:38:58.722950 28708 net.cpp:129] Top shape: 2 128 14 14 (50176)
I1010 15:38:58.725108 28708 net.cpp:137] Memory required for data: 107778048
I1010 15:38:58.727304 28708 layer_factory.hpp:77] Creating layer elu3_1
I1010 15:38:58.729495 28708 net.cpp:84] Creating Layer elu3_1
I1010 15:38:58.731678 28708 net.cpp:406] elu3_1 <- conv3_1
I1010 15:38:58.733846 28708 net.cpp:367] elu3_1 -> conv3_1 (in-place)
I1010 15:38:58.736029 28708 net.cpp:122] Setting up elu3_1
I1010 15:38:58.738226 28708 net.cpp:129] Top shape: 2 128 14 14 (50176)
I1010 15:38:58.740423 28708 net.cpp:137] Memory required for data: 107978752
I1010 15:38:58.742635 28708 layer_factory.hpp:77] Creating layer conv3_2
I1010 15:38:58.744828 28708 net.cpp:84] Creating Layer conv3_2
I1010 15:38:58.747021 28708 net.cpp:406] conv3_2 <- conv3_1
I1010 15:38:58.749222 28708 net.cpp:380] conv3_2 -> conv3_2
I1010 15:38:58.755010 28708 net.cpp:122] Setting up conv3_2
I1010 15:38:58.757215 28708 net.cpp:129] Top shape: 2 128 14 14 (50176)
I1010 15:38:58.759393 28708 net.cpp:137] Memory required for data: 108179456
I1010 15:38:58.761602 28708 layer_factory.hpp:77] Creating layer batchnorm3_2
I1010 15:38:58.763809 28708 net.cpp:84] Creating Layer batchnorm3_2
I1010 15:38:58.766012 28708 net.cpp:406] batchnorm3_2 <- conv3_2
I1010 15:38:58.768196 28708 net.cpp:367] batchnorm3_2 -> conv3_2 (in-place)
I1010 15:38:58.770634 28708 net.cpp:122] Setting up batchnorm3_2
I1010 15:38:58.772830 28708 net.cpp:129] Top shape: 2 128 14 14 (50176)
I1010 15:38:58.775032 28708 net.cpp:137] Memory required for data: 108380160
I1010 15:38:58.777238 28708 layer_factory.hpp:77] Creating layer elu3_2
I1010 15:38:58.779443 28708 net.cpp:84] Creating Layer elu3_2
I1010 15:38:58.781647 28708 net.cpp:406] elu3_2 <- conv3_2
I1010 15:38:58.783854 28708 net.cpp:367] elu3_2 -> conv3_2 (in-place)
I1010 15:38:58.786049 28708 net.cpp:122] Setting up elu3_2
I1010 15:38:58.788250 28708 net.cpp:129] Top shape: 2 128 14 14 (50176)
I1010 15:38:58.790429 28708 net.cpp:137] Memory required for data: 108580864
I1010 15:38:58.792636 28708 layer_factory.hpp:77] Creating layer conv3_3
I1010 15:38:58.794849 28708 net.cpp:84] Creating Layer conv3_3
I1010 15:38:58.797072 28708 net.cpp:406] conv3_3 <- conv3_2
I1010 15:38:58.799275 28708 net.cpp:380] conv3_3 -> conv3_3
I1010 15:38:58.804940 28708 net.cpp:122] Setting up conv3_3
I1010 15:38:58.807147 28708 net.cpp:129] Top shape: 2 128 14 14 (50176)
I1010 15:38:58.809353 28708 net.cpp:137] Memory required for data: 108781568
I1010 15:38:58.811553 28708 layer_factory.hpp:77] Creating layer batchnorm3_3
I1010 15:38:58.813772 28708 net.cpp:84] Creating Layer batchnorm3_3
I1010 15:38:58.815995 28708 net.cpp:406] batchnorm3_3 <- conv3_3
I1010 15:38:58.818186 28708 net.cpp:367] batchnorm3_3 -> conv3_3 (in-place)
I1010 15:38:58.820621 28708 net.cpp:122] Setting up batchnorm3_3
I1010 15:38:58.822815 28708 net.cpp:129] Top shape: 2 128 14 14 (50176)
I1010 15:38:58.825031 28708 net.cpp:137] Memory required for data: 108982272
I1010 15:38:58.827230 28708 layer_factory.hpp:77] Creating layer elu3_3
I1010 15:38:58.829452 28708 net.cpp:84] Creating Layer elu3_3
I1010 15:38:58.831660 28708 net.cpp:406] elu3_3 <- conv3_3
I1010 15:38:58.833854 28708 net.cpp:367] elu3_3 -> conv3_3 (in-place)
I1010 15:38:58.836048 28708 net.cpp:122] Setting up elu3_3
I1010 15:38:58.838251 28708 net.cpp:129] Top shape: 2 128 14 14 (50176)
I1010 15:38:58.840450 28708 net.cpp:137] Memory required for data: 109182976
I1010 15:38:58.842661 28708 layer_factory.hpp:77] Creating layer pool3
I1010 15:38:58.844866 28708 layer_factory.cpp:91] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I1010 15:38:58.847095 28708 net.cpp:84] Creating Layer pool3
I1010 15:38:58.849344 28708 net.cpp:406] pool3 <- conv3_3
I1010 15:38:58.851557 28708 net.cpp:380] pool3 -> pool3
I1010 15:38:58.853796 28708 net.cpp:380] pool3 -> pool3_mask
I1010 15:38:58.856012 28708 net.cpp:380] pool3 -> pool3_argmax_count
I1010 15:38:58.858264 28708 net.cpp:122] Setting up pool3
I1010 15:38:58.860468 28708 net.cpp:129] Top shape: 2 128 7 7 (12544)
I1010 15:38:58.862645 28708 net.cpp:129] Top shape: 2 128 7 7 (12544)
I1010 15:38:58.864819 28708 net.cpp:129] Top shape: 2 128 14 14 (50176)
I1010 15:38:58.866991 28708 net.cpp:137] Memory required for data: 109484032
I1010 15:38:58.869158 28708 layer_factory.hpp:77] Creating layer conv4_1
I1010 15:38:58.871372 28708 net.cpp:84] Creating Layer conv4_1
I1010 15:38:58.873555 28708 net.cpp:406] conv4_1 <- pool3
I1010 15:38:58.875761 28708 net.cpp:380] conv4_1 -> conv4_1
I1010 15:38:58.920641 28708 net.cpp:122] Setting up conv4_1
I1010 15:38:58.922850 28708 net.cpp:129] Top shape: 2 1024 1 1 (2048)
I1010 15:38:58.925042 28708 net.cpp:137] Memory required for data: 109492224
I1010 15:38:58.927244 28708 layer_factory.hpp:77] Creating layer batchnorm4_1
I1010 15:38:58.929456 28708 net.cpp:84] Creating Layer batchnorm4_1
I1010 15:38:58.931669 28708 net.cpp:406] batchnorm4_1 <- conv4_1
I1010 15:38:58.934005 28708 net.cpp:367] batchnorm4_1 -> conv4_1 (in-place)
I1010 15:38:58.936659 28708 net.cpp:122] Setting up batchnorm4_1
I1010 15:38:58.938953 28708 net.cpp:129] Top shape: 2 1024 1 1 (2048)
I1010 15:38:58.941247 28708 net.cpp:137] Memory required for data: 109500416
I1010 15:38:58.943465 28708 layer_factory.hpp:77] Creating layer elu4_1
I1010 15:38:58.945673 28708 net.cpp:84] Creating Layer elu4_1
I1010 15:38:58.947885 28708 net.cpp:406] elu4_1 <- conv4_1
I1010 15:38:58.950086 28708 net.cpp:367] elu4_1 -> conv4_1 (in-place)
I1010 15:38:58.952261 28708 net.cpp:122] Setting up elu4_1
I1010 15:38:58.954464 28708 net.cpp:129] Top shape: 2 1024 1 1 (2048)
I1010 15:38:58.956681 28708 net.cpp:137] Memory required for data: 109508608
I1010 15:38:58.958885 28708 layer_factory.hpp:77] Creating layer conv4_2
I1010 15:38:58.961421 28708 net.cpp:84] Creating Layer conv4_2
I1010 15:38:58.963623 28708 net.cpp:406] conv4_2 <- conv4_1
I1010 15:38:58.965842 28708 net.cpp:380] conv4_2 -> conv4_2
I1010 15:38:58.977005 28708 net.cpp:122] Setting up conv4_2
I1010 15:38:58.979243 28708 net.cpp:129] Top shape: 2 1024 1 1 (2048)
I1010 15:38:58.981427 28708 net.cpp:137] Memory required for data: 109516800
I1010 15:38:58.983633 28708 layer_factory.hpp:77] Creating layer batchnorm4_2
I1010 15:38:58.985795 28708 net.cpp:84] Creating Layer batchnorm4_2
I1010 15:38:58.988001 28708 net.cpp:406] batchnorm4_2 <- conv4_2
I1010 15:38:58.990195 28708 net.cpp:367] batchnorm4_2 -> conv4_2 (in-place)
I1010 15:38:58.992606 28708 net.cpp:122] Setting up batchnorm4_2
I1010 15:38:58.994786 28708 net.cpp:129] Top shape: 2 1024 1 1 (2048)
I1010 15:38:58.996986 28708 net.cpp:137] Memory required for data: 109524992
I1010 15:38:58.999187 28708 layer_factory.hpp:77] Creating layer elu4_2
I1010 15:38:59.001384 28708 net.cpp:84] Creating Layer elu4_2
I1010 15:38:59.003582 28708 net.cpp:406] elu4_2 <- conv4_2
I1010 15:38:59.005759 28708 net.cpp:367] elu4_2 -> conv4_2 (in-place)
I1010 15:38:59.007962 28708 net.cpp:122] Setting up elu4_2
I1010 15:38:59.010138 28708 net.cpp:129] Top shape: 2 1024 1 1 (2048)
I1010 15:38:59.012342 28708 net.cpp:137] Memory required for data: 109533184
I1010 15:38:59.014533 28708 layer_factory.hpp:77] Creating layer deconv4_3
I1010 15:38:59.016724 28708 net.cpp:84] Creating Layer deconv4_3
I1010 15:38:59.018894 28708 net.cpp:406] deconv4_3 <- conv4_2
I1010 15:38:59.021112 28708 net.cpp:380] deconv4_3 -> deconv4_3
I1010 15:38:59.064185 28708 net.cpp:122] Setting up deconv4_3
I1010 15:38:59.066390 28708 net.cpp:129] Top shape: 2 128 7 7 (12544)
I1010 15:38:59.068567 28708 net.cpp:137] Memory required for data: 109583360
I1010 15:38:59.070739 28708 layer_factory.hpp:77] Creating layer debatchnorm4_3
I1010 15:38:59.072901 28708 net.cpp:84] Creating Layer debatchnorm4_3
I1010 15:38:59.075073 28708 net.cpp:406] debatchnorm4_3 <- deconv4_3
I1010 15:38:59.077235 28708 net.cpp:367] debatchnorm4_3 -> deconv4_3 (in-place)
I1010 15:38:59.079635 28708 net.cpp:122] Setting up debatchnorm4_3
I1010 15:38:59.081794 28708 net.cpp:129] Top shape: 2 128 7 7 (12544)
I1010 15:38:59.083956 28708 net.cpp:137] Memory required for data: 109633536
I1010 15:38:59.086103 28708 layer_factory.hpp:77] Creating layer deelu4_3
I1010 15:38:59.088291 28708 net.cpp:84] Creating Layer deelu4_3
I1010 15:38:59.090456 28708 net.cpp:406] deelu4_3 <- deconv4_3
I1010 15:38:59.092644 28708 net.cpp:367] deelu4_3 -> deconv4_3 (in-place)
I1010 15:38:59.094815 28708 net.cpp:122] Setting up deelu4_3
I1010 15:38:59.096979 28708 net.cpp:129] Top shape: 2 128 7 7 (12544)
I1010 15:38:59.099155 28708 net.cpp:137] Memory required for data: 109683712
I1010 15:38:59.101302 28708 layer_factory.hpp:77] Creating layer unpool3
I1010 15:38:59.103500 28708 net.cpp:84] Creating Layer unpool3
I1010 15:38:59.105682 28708 net.cpp:406] unpool3 <- deconv4_3
I1010 15:38:59.107847 28708 net.cpp:406] unpool3 <- pool3_mask
I1010 15:38:59.110023 28708 net.cpp:406] unpool3 <- pool3_argmax_count
I1010 15:38:59.112186 28708 net.cpp:380] unpool3 -> unpool3
I1010 15:38:59.114363 28708 net.cpp:122] Setting up unpool3
I1010 15:38:59.116518 28708 net.cpp:129] Top shape: 2 128 14 14 (50176)
I1010 15:38:59.118651 28708 net.cpp:137] Memory required for data: 109884416
I1010 15:38:59.120824 28708 layer_factory.hpp:77] Creating layer deconv3_1
I1010 15:38:59.122997 28708 net.cpp:84] Creating Layer deconv3_1
I1010 15:38:59.125154 28708 net.cpp:406] deconv3_1 <- unpool3
I1010 15:38:59.127321 28708 net.cpp:380] deconv3_1 -> deconv3_1
I1010 15:38:59.131410 28708 net.cpp:122] Setting up deconv3_1
I1010 15:38:59.133568 28708 net.cpp:129] Top shape: 2 128 14 14 (50176)
I1010 15:38:59.135721 28708 net.cpp:137] Memory required for data: 110085120
I1010 15:38:59.137879 28708 layer_factory.hpp:77] Creating layer debatchnorm3_1
I1010 15:38:59.140056 28708 net.cpp:84] Creating Layer debatchnorm3_1
I1010 15:38:59.142211 28708 net.cpp:406] debatchnorm3_1 <- deconv3_1
I1010 15:38:59.144369 28708 net.cpp:367] debatchnorm3_1 -> deconv3_1 (in-place)
I1010 15:38:59.146775 28708 net.cpp:122] Setting up debatchnorm3_1
I1010 15:38:59.148936 28708 net.cpp:129] Top shape: 2 128 14 14 (50176)
I1010 15:38:59.151080 28708 net.cpp:137] Memory required for data: 110285824
I1010 15:38:59.153237 28708 layer_factory.hpp:77] Creating layer deelu3_1
I1010 15:38:59.155426 28708 net.cpp:84] Creating Layer deelu3_1
I1010 15:38:59.157586 28708 net.cpp:406] deelu3_1 <- deconv3_1
I1010 15:38:59.159775 28708 net.cpp:367] deelu3_1 -> deconv3_1 (in-place)
I1010 15:38:59.161936 28708 net.cpp:122] Setting up deelu3_1
I1010 15:38:59.164085 28708 net.cpp:129] Top shape: 2 128 14 14 (50176)
I1010 15:38:59.166261 28708 net.cpp:137] Memory required for data: 110486528
I1010 15:38:59.168429 28708 layer_factory.hpp:77] Creating layer deconv3_2
I1010 15:38:59.170608 28708 net.cpp:84] Creating Layer deconv3_2
I1010 15:38:59.172766 28708 net.cpp:406] deconv3_2 <- deconv3_1
I1010 15:38:59.174927 28708 net.cpp:380] deconv3_2 -> deconv3_2
I1010 15:38:59.178951 28708 net.cpp:122] Setting up deconv3_2
I1010 15:38:59.181120 28708 net.cpp:129] Top shape: 2 128 14 14 (50176)
I1010 15:38:59.183282 28708 net.cpp:137] Memory required for data: 110687232
I1010 15:38:59.185425 28708 layer_factory.hpp:77] Creating layer debatchnorm3_2
I1010 15:38:59.187598 28708 net.cpp:84] Creating Layer debatchnorm3_2
I1010 15:38:59.189761 28708 net.cpp:406] debatchnorm3_2 <- deconv3_2
I1010 15:38:59.191912 28708 net.cpp:367] debatchnorm3_2 -> deconv3_2 (in-place)
I1010 15:38:59.194298 28708 net.cpp:122] Setting up debatchnorm3_2
I1010 15:38:59.196465 28708 net.cpp:129] Top shape: 2 128 14 14 (50176)
I1010 15:38:59.198614 28708 net.cpp:137] Memory required for data: 110887936
I1010 15:38:59.200778 28708 layer_factory.hpp:77] Creating layer deelu3_2
I1010 15:38:59.202927 28708 net.cpp:84] Creating Layer deelu3_2
I1010 15:38:59.205090 28708 net.cpp:406] deelu3_2 <- deconv3_2
I1010 15:38:59.207264 28708 net.cpp:367] deelu3_2 -> deconv3_2 (in-place)
I1010 15:38:59.209422 28708 net.cpp:122] Setting up deelu3_2
I1010 15:38:59.211585 28708 net.cpp:129] Top shape: 2 128 14 14 (50176)
I1010 15:38:59.213749 28708 net.cpp:137] Memory required for data: 111088640
I1010 15:38:59.215929 28708 layer_factory.hpp:77] Creating layer deconv3_3
I1010 15:38:59.218070 28708 net.cpp:84] Creating Layer deconv3_3
I1010 15:38:59.220255 28708 net.cpp:406] deconv3_3 <- deconv3_2
I1010 15:38:59.222426 28708 net.cpp:380] deconv3_3 -> deconv3_3
I1010 15:38:59.225281 28708 net.cpp:122] Setting up deconv3_3
I1010 15:38:59.227443 28708 net.cpp:129] Top shape: 2 64 14 14 (25088)
I1010 15:38:59.229593 28708 net.cpp:137] Memory required for data: 111188992
I1010 15:38:59.231784 28708 layer_factory.hpp:77] Creating layer debatchnorm3_3
I1010 15:38:59.233934 28708 net.cpp:84] Creating Layer debatchnorm3_3
I1010 15:38:59.236090 28708 net.cpp:406] debatchnorm3_3 <- deconv3_3
I1010 15:38:59.238226 28708 net.cpp:367] debatchnorm3_3 -> deconv3_3 (in-place)
I1010 15:38:59.240572 28708 net.cpp:122] Setting up debatchnorm3_3
I1010 15:38:59.242699 28708 net.cpp:129] Top shape: 2 64 14 14 (25088)
I1010 15:38:59.244843 28708 net.cpp:137] Memory required for data: 111289344
I1010 15:38:59.246984 28708 layer_factory.hpp:77] Creating layer deelu3_3
I1010 15:38:59.249137 28708 net.cpp:84] Creating Layer deelu3_3
I1010 15:38:59.251272 28708 net.cpp:406] deelu3_3 <- deconv3_3
I1010 15:38:59.253422 28708 net.cpp:367] deelu3_3 -> deconv3_3 (in-place)
I1010 15:38:59.255610 28708 net.cpp:122] Setting up deelu3_3
I1010 15:38:59.257758 28708 net.cpp:129] Top shape: 2 64 14 14 (25088)
I1010 15:38:59.259918 28708 net.cpp:137] Memory required for data: 111389696
I1010 15:38:59.262094 28708 layer_factory.hpp:77] Creating layer unpool2
I1010 15:38:59.264248 28708 net.cpp:84] Creating Layer unpool2
I1010 15:38:59.266412 28708 net.cpp:406] unpool2 <- deconv3_3
I1010 15:38:59.268579 28708 net.cpp:406] unpool2 <- pool2_mask
I1010 15:38:59.270745 28708 net.cpp:406] unpool2 <- pool2_argmax_count
I1010 15:38:59.272902 28708 net.cpp:380] unpool2 -> unpool2
I1010 15:38:59.275084 28708 net.cpp:122] Setting up unpool2
I1010 15:38:59.277246 28708 net.cpp:129] Top shape: 2 64 56 56 (401408)
I1010 15:38:59.279381 28708 net.cpp:137] Memory required for data: 112995328
I1010 15:38:59.281509 28708 layer_factory.hpp:77] Creating layer deconv2_1
I1010 15:38:59.283668 28708 net.cpp:84] Creating Layer deconv2_1
I1010 15:38:59.285797 28708 net.cpp:406] deconv2_1 <- unpool2
I1010 15:38:59.287961 28708 net.cpp:380] deconv2_1 -> deconv2_1
I1010 15:38:59.290601 28708 net.cpp:122] Setting up deconv2_1
I1010 15:38:59.292744 28708 net.cpp:129] Top shape: 2 64 56 56 (401408)
I1010 15:38:59.294868 28708 net.cpp:137] Memory required for data: 114600960
I1010 15:38:59.297041 28708 layer_factory.hpp:77] Creating layer debatchnorm2_1
I1010 15:38:59.299208 28708 net.cpp:84] Creating Layer debatchnorm2_1
I1010 15:38:59.301342 28708 net.cpp:406] debatchnorm2_1 <- deconv2_1
I1010 15:38:59.303501 28708 net.cpp:367] debatchnorm2_1 -> deconv2_1 (in-place)
I1010 15:38:59.305874 28708 net.cpp:122] Setting up debatchnorm2_1
I1010 15:38:59.308032 28708 net.cpp:129] Top shape: 2 64 56 56 (401408)
I1010 15:38:59.310163 28708 net.cpp:137] Memory required for data: 116206592
I1010 15:38:59.312328 28708 layer_factory.hpp:77] Creating layer deelu2_1
I1010 15:38:59.314491 28708 net.cpp:84] Creating Layer deelu2_1
I1010 15:38:59.316640 28708 net.cpp:406] deelu2_1 <- deconv2_1
I1010 15:38:59.318776 28708 net.cpp:367] deelu2_1 -> deconv2_1 (in-place)
I1010 15:38:59.320919 28708 net.cpp:122] Setting up deelu2_1
I1010 15:38:59.323056 28708 net.cpp:129] Top shape: 2 64 56 56 (401408)
I1010 15:38:59.325213 28708 net.cpp:137] Memory required for data: 117812224
I1010 15:38:59.327391 28708 layer_factory.hpp:77] Creating layer deconv2_2
I1010 15:38:59.329551 28708 net.cpp:84] Creating Layer deconv2_2
I1010 15:38:59.331717 28708 net.cpp:406] deconv2_2 <- deconv2_1
I1010 15:38:59.333868 28708 net.cpp:380] deconv2_2 -> deconv2_2
I1010 15:38:59.336396 28708 net.cpp:122] Setting up deconv2_2
I1010 15:38:59.338523 28708 net.cpp:129] Top shape: 2 32 56 56 (200704)
I1010 15:38:59.340669 28708 net.cpp:137] Memory required for data: 118615040
I1010 15:38:59.342820 28708 layer_factory.hpp:77] Creating layer debatchnorm2_2
I1010 15:38:59.344974 28708 net.cpp:84] Creating Layer debatchnorm2_2
I1010 15:38:59.347134 28708 net.cpp:406] debatchnorm2_2 <- deconv2_2
I1010 15:38:59.349273 28708 net.cpp:367] debatchnorm2_2 -> deconv2_2 (in-place)
I1010 15:38:59.351639 28708 net.cpp:122] Setting up debatchnorm2_2
I1010 15:38:59.353788 28708 net.cpp:129] Top shape: 2 32 56 56 (200704)
I1010 15:38:59.355936 28708 net.cpp:137] Memory required for data: 119417856
I1010 15:38:59.358100 28708 layer_factory.hpp:77] Creating layer deelu2_2
I1010 15:38:59.360268 28708 net.cpp:84] Creating Layer deelu2_2
I1010 15:38:59.362426 28708 net.cpp:406] deelu2_2 <- deconv2_2
I1010 15:38:59.364576 28708 net.cpp:367] deelu2_2 -> deconv2_2 (in-place)
I1010 15:38:59.366735 28708 net.cpp:122] Setting up deelu2_2
I1010 15:38:59.368858 28708 net.cpp:129] Top shape: 2 32 56 56 (200704)
I1010 15:38:59.371006 28708 net.cpp:137] Memory required for data: 120220672
I1010 15:38:59.373152 28708 layer_factory.hpp:77] Creating layer unpool1
I1010 15:38:59.375326 28708 net.cpp:84] Creating Layer unpool1
I1010 15:38:59.377475 28708 net.cpp:406] unpool1 <- deconv2_2
I1010 15:38:59.379621 28708 net.cpp:406] unpool1 <- pool1_mask
I1010 15:38:59.381780 28708 net.cpp:406] unpool1 <- pool1_argmax_count
I1010 15:38:59.383903 28708 net.cpp:380] unpool1 -> unpool1
I1010 15:38:59.386056 28708 net.cpp:122] Setting up unpool1
I1010 15:38:59.388187 28708 net.cpp:129] Top shape: 2 32 224 224 (3211264)
I1010 15:38:59.390342 28708 net.cpp:137] Memory required for data: 133065728
I1010 15:38:59.392483 28708 layer_factory.hpp:77] Creating layer deconv1_1
I1010 15:38:59.394615 28708 net.cpp:84] Creating Layer deconv1_1
I1010 15:38:59.396767 28708 net.cpp:406] deconv1_1 <- unpool1
I1010 15:38:59.398914 28708 net.cpp:380] deconv1_1 -> deconv1_1
I1010 15:38:59.401389 28708 net.cpp:122] Setting up deconv1_1
I1010 15:38:59.403542 28708 net.cpp:129] Top shape: 2 32 224 224 (3211264)
I1010 15:38:59.405676 28708 net.cpp:137] Memory required for data: 145910784
I1010 15:38:59.407833 28708 layer_factory.hpp:77] Creating layer debatchnorm1_1
I1010 15:38:59.409991 28708 net.cpp:84] Creating Layer debatchnorm1_1
I1010 15:38:59.412149 28708 net.cpp:406] debatchnorm1_1 <- deconv1_1
I1010 15:38:59.414302 28708 net.cpp:367] debatchnorm1_1 -> deconv1_1 (in-place)
I1010 15:38:59.417418 28708 net.cpp:122] Setting up debatchnorm1_1
I1010 15:38:59.419571 28708 net.cpp:129] Top shape: 2 32 224 224 (3211264)
I1010 15:38:59.421720 28708 net.cpp:137] Memory required for data: 158755840
I1010 15:38:59.423868 28708 layer_factory.hpp:77] Creating layer deelu1_1
I1010 15:38:59.426033 28708 net.cpp:84] Creating Layer deelu1_1
I1010 15:38:59.428184 28708 net.cpp:406] deelu1_1 <- deconv1_1
I1010 15:38:59.430356 28708 net.cpp:367] deelu1_1 -> deconv1_1 (in-place)
I1010 15:38:59.432508 28708 net.cpp:122] Setting up deelu1_1
I1010 15:38:59.434653 28708 net.cpp:129] Top shape: 2 32 224 224 (3211264)
I1010 15:38:59.436815 28708 net.cpp:137] Memory required for data: 171600896
I1010 15:38:59.438997 28708 layer_factory.hpp:77] Creating layer deconv1_2
I1010 15:38:59.441159 28708 net.cpp:84] Creating Layer deconv1_2
I1010 15:38:59.443357 28708 net.cpp:406] deconv1_2 <- deconv1_1
I1010 15:38:59.445540 28708 net.cpp:380] deconv1_2 -> deconv1_2
I1010 15:38:59.448043 28708 net.cpp:122] Setting up deconv1_2
I1010 15:38:59.450206 28708 net.cpp:129] Top shape: 2 32 224 224 (3211264)
I1010 15:38:59.452338 28708 net.cpp:137] Memory required for data: 184445952
I1010 15:38:59.454504 28708 layer_factory.hpp:77] Creating layer debatchnorm1_2
I1010 15:38:59.456677 28708 net.cpp:84] Creating Layer debatchnorm1_2
I1010 15:38:59.458842 28708 net.cpp:406] debatchnorm1_2 <- deconv1_2
I1010 15:38:59.461014 28708 net.cpp:367] debatchnorm1_2 -> deconv1_2 (in-place)
I1010 15:38:59.463403 28708 net.cpp:122] Setting up debatchnorm1_2
I1010 15:38:59.465581 28708 net.cpp:129] Top shape: 2 32 224 224 (3211264)
I1010 15:38:59.467717 28708 net.cpp:137] Memory required for data: 197291008
I1010 15:38:59.469873 28708 layer_factory.hpp:77] Creating layer deelu1_2
I1010 15:38:59.472033 28708 net.cpp:84] Creating Layer deelu1_2
I1010 15:38:59.474195 28708 net.cpp:406] deelu1_2 <- deconv1_2
I1010 15:38:59.476354 28708 net.cpp:367] deelu1_2 -> deconv1_2 (in-place)
I1010 15:38:59.478513 28708 net.cpp:122] Setting up deelu1_2
I1010 15:38:59.480674 28708 net.cpp:129] Top shape: 2 32 224 224 (3211264)
I1010 15:38:59.482838 28708 net.cpp:137] Memory required for data: 210136064
I1010 15:38:59.484982 28708 layer_factory.hpp:77] Creating layer segmentation
I1010 15:38:59.487164 28708 net.cpp:84] Creating Layer segmentation
I1010 15:38:59.489329 28708 net.cpp:406] segmentation <- deconv1_2
I1010 15:38:59.491523 28708 net.cpp:380] segmentation -> segmentation
I1010 15:38:59.496145 28708 net.cpp:122] Setting up segmentation
I1010 15:38:59.498329 28708 net.cpp:129] Top shape: 2 3 224 224 (301056)
I1010 15:38:59.500485 28708 net.cpp:137] Memory required for data: 211340288
I1010 15:38:59.502638 28708 layer_factory.hpp:77] Creating layer segmentation_segmentation_0_split
I1010 15:38:59.504815 28708 net.cpp:84] Creating Layer segmentation_segmentation_0_split
I1010 15:38:59.507019 28708 net.cpp:406] segmentation_segmentation_0_split <- segmentation
I1010 15:38:59.509225 28708 net.cpp:380] segmentation_segmentation_0_split -> segmentation_segmentation_0_split_0
I1010 15:38:59.511435 28708 net.cpp:380] segmentation_segmentation_0_split -> segmentation_segmentation_0_split_1
I1010 15:38:59.513128 28708 net.cpp:122] Setting up segmentation_segmentation_0_split
I1010 15:38:59.514760 28708 net.cpp:129] Top shape: 2 3 224 224 (301056)
I1010 15:38:59.516386 28708 net.cpp:129] Top shape: 2 3 224 224 (301056)
I1010 15:38:59.517988 28708 net.cpp:137] Memory required for data: 213748736
I1010 15:38:59.519718 28708 layer_factory.hpp:77] Creating layer infogainLoss
I1010 15:38:59.521925 28708 net.cpp:84] Creating Layer infogainLoss
I1010 15:38:59.524144 28708 net.cpp:406] infogainLoss <- segmentation_segmentation_0_split_0
I1010 15:38:59.526340 28708 net.cpp:406] infogainLoss <- label_data_1_split_0
I1010 15:38:59.528534 28708 net.cpp:380] infogainLoss -> loss
I1010 15:38:59.530725 28708 layer_factory.hpp:77] Creating layer infogainLoss
I1010 15:38:59.534024 28708 net.cpp:122] Setting up infogainLoss
I1010 15:38:59.536237 28708 net.cpp:129] Top shape: (1)
I1010 15:38:59.538403 28708 net.cpp:132]     with loss weight 1
I1010 15:38:59.540612 28708 net.cpp:137] Memory required for data: 213748740
I1010 15:38:59.542815 28708 layer_factory.hpp:77] Creating layer accuracy
I1010 15:38:59.545029 28708 net.cpp:84] Creating Layer accuracy
I1010 15:38:59.547241 28708 net.cpp:406] accuracy <- segmentation_segmentation_0_split_1
I1010 15:38:59.549477 28708 net.cpp:406] accuracy <- label_data_1_split_1
I1010 15:38:59.551698 28708 net.cpp:380] accuracy -> accuracy
I1010 15:38:59.553910 28708 net.cpp:380] accuracy -> per_class_accuracy
I1010 15:38:59.556169 28708 net.cpp:122] Setting up accuracy
I1010 15:38:59.558358 28708 net.cpp:129] Top shape: (1)
I1010 15:38:59.560556 28708 net.cpp:129] Top shape: 3 (3)
I1010 15:38:59.562746 28708 net.cpp:137] Memory required for data: 213748756
I1010 15:38:59.564975 28708 net.cpp:200] accuracy does not need backward computation.
I1010 15:38:59.567186 28708 net.cpp:198] infogainLoss needs backward computation.
I1010 15:38:59.569398 28708 net.cpp:198] segmentation_segmentation_0_split needs backward computation.
I1010 15:38:59.571626 28708 net.cpp:198] segmentation needs backward computation.
I1010 15:38:59.573840 28708 net.cpp:198] deelu1_2 needs backward computation.
I1010 15:38:59.576066 28708 net.cpp:198] debatchnorm1_2 needs backward computation.
I1010 15:38:59.578285 28708 net.cpp:198] deconv1_2 needs backward computation.
I1010 15:38:59.580493 28708 net.cpp:198] deelu1_1 needs backward computation.
I1010 15:38:59.582722 28708 net.cpp:198] debatchnorm1_1 needs backward computation.
I1010 15:38:59.584916 28708 net.cpp:198] deconv1_1 needs backward computation.
I1010 15:38:59.587146 28708 net.cpp:198] unpool1 needs backward computation.
I1010 15:38:59.589351 28708 net.cpp:198] deelu2_2 needs backward computation.
I1010 15:38:59.591579 28708 net.cpp:198] debatchnorm2_2 needs backward computation.
I1010 15:38:59.593781 28708 net.cpp:198] deconv2_2 needs backward computation.
I1010 15:38:59.596009 28708 net.cpp:198] deelu2_1 needs backward computation.
I1010 15:38:59.598224 28708 net.cpp:198] debatchnorm2_1 needs backward computation.
I1010 15:38:59.600436 28708 net.cpp:198] deconv2_1 needs backward computation.
I1010 15:38:59.602634 28708 net.cpp:198] unpool2 needs backward computation.
I1010 15:38:59.604859 28708 net.cpp:198] deelu3_3 needs backward computation.
I1010 15:38:59.607064 28708 net.cpp:198] debatchnorm3_3 needs backward computation.
I1010 15:38:59.609294 28708 net.cpp:198] deconv3_3 needs backward computation.
I1010 15:38:59.611497 28708 net.cpp:198] deelu3_2 needs backward computation.
I1010 15:38:59.613734 28708 net.cpp:198] debatchnorm3_2 needs backward computation.
I1010 15:38:59.615931 28708 net.cpp:198] deconv3_2 needs backward computation.
I1010 15:38:59.618135 28708 net.cpp:198] deelu3_1 needs backward computation.
I1010 15:38:59.620352 28708 net.cpp:198] debatchnorm3_1 needs backward computation.
I1010 15:38:59.622579 28708 net.cpp:198] deconv3_1 needs backward computation.
I1010 15:38:59.624781 28708 net.cpp:198] unpool3 needs backward computation.
I1010 15:38:59.626996 28708 net.cpp:198] deelu4_3 needs backward computation.
I1010 15:38:59.629212 28708 net.cpp:198] debatchnorm4_3 needs backward computation.
I1010 15:38:59.631440 28708 net.cpp:198] deconv4_3 needs backward computation.
I1010 15:38:59.633637 28708 net.cpp:198] elu4_2 needs backward computation.
I1010 15:38:59.635845 28708 net.cpp:198] batchnorm4_2 needs backward computation.
I1010 15:38:59.638069 28708 net.cpp:198] conv4_2 needs backward computation.
I1010 15:38:59.640274 28708 net.cpp:198] elu4_1 needs backward computation.
I1010 15:38:59.642480 28708 net.cpp:198] batchnorm4_1 needs backward computation.
I1010 15:38:59.644701 28708 net.cpp:198] conv4_1 needs backward computation.
I1010 15:38:59.646912 28708 net.cpp:198] pool3 needs backward computation.
I1010 15:38:59.649116 28708 net.cpp:198] elu3_3 needs backward computation.
I1010 15:38:59.651306 28708 net.cpp:198] batchnorm3_3 needs backward computation.
I1010 15:38:59.653543 28708 net.cpp:198] conv3_3 needs backward computation.
I1010 15:38:59.655753 28708 net.cpp:198] elu3_2 needs backward computation.
I1010 15:38:59.657974 28708 net.cpp:198] batchnorm3_2 needs backward computation.
I1010 15:38:59.660179 28708 net.cpp:198] conv3_2 needs backward computation.
I1010 15:38:59.662389 28708 net.cpp:198] elu3_1 needs backward computation.
I1010 15:38:59.664595 28708 net.cpp:198] batchnorm3_1 needs backward computation.
I1010 15:38:59.666818 28708 net.cpp:198] conv3_1 needs backward computation.
I1010 15:38:59.669005 28708 net.cpp:198] pool2 needs backward computation.
I1010 15:38:59.671206 28708 net.cpp:198] elu2_2 needs backward computation.
I1010 15:38:59.673395 28708 net.cpp:198] batchnorm2_2 needs backward computation.
I1010 15:38:59.675604 28708 net.cpp:198] conv2_2 needs backward computation.
I1010 15:38:59.677809 28708 net.cpp:198] elu2_1 needs backward computation.
I1010 15:38:59.680025 28708 net.cpp:198] batchnorm2_1 needs backward computation.
I1010 15:38:59.682251 28708 net.cpp:198] conv2_1 needs backward computation.
I1010 15:38:59.684443 28708 net.cpp:198] pool1 needs backward computation.
I1010 15:38:59.686657 28708 net.cpp:198] elu1_2 needs backward computation.
I1010 15:38:59.688856 28708 net.cpp:198] batchnorm1_2 needs backward computation.
I1010 15:38:59.691085 28708 net.cpp:198] conv1_2 needs backward computation.
I1010 15:38:59.693295 28708 net.cpp:198] elu1_1 needs backward computation.
I1010 15:38:59.695513 28708 net.cpp:198] batchnorm1_1 needs backward computation.
I1010 15:38:59.697716 28708 net.cpp:198] conv1_1 needs backward computation.
I1010 15:38:59.699937 28708 net.cpp:198] batchnorm0 needs backward computation.
I1010 15:38:59.702107 28708 net.cpp:200] label_data_1_split does not need backward computation.
I1010 15:38:59.704329 28708 net.cpp:200] data does not need backward computation.
I1010 15:38:59.706558 28708 net.cpp:242] This network produces output accuracy
I1010 15:38:59.708783 28708 net.cpp:242] This network produces output loss
I1010 15:38:59.710989 28708 net.cpp:242] This network produces output per_class_accuracy
I1010 15:38:59.713222 28708 net.cpp:255] Network initialization done.
I1010 15:38:59.715559 28708 solver.cpp:56] Solver scaffolding done.
I1010 15:38:59.722900 28708 caffe.cpp:248] Starting Optimization
I1010 15:38:59.725137 28708 solver.cpp:272] Solving ZNet3
I1010 15:38:59.727383 28708 solver.cpp:273] Learning Rate Policy: fixed
I1010 15:38:59.734133 28708 solver.cpp:330] Iteration 0, Testing net (#0)
I1010 15:44:53.812047 28708 solver.cpp:397]     Test net output #0: accuracy = 1.30923e-05
I1010 15:44:53.814380 28708 solver.cpp:397]     Test net output #1: loss = nan (* 1 = nan loss)
I1010 15:44:53.816642 28708 solver.cpp:397]     Test net output #2: per_class_accuracy = 1.59225e-05
I1010 15:44:53.818897 28708 solver.cpp:397]     Test net output #3: per_class_accuracy = 2.3533e-06
I1010 15:44:53.821120 28708 solver.cpp:397]     Test net output #4: per_class_accuracy = 2.53337e-06
I1010 15:45:11.231758 28708 solver.cpp:218] Iteration 0 (-4876.69 iter/s, 371.504s/500 iters), loss = 1.29964
I1010 15:45:11.234040 28708 solver.cpp:237]     Train net output #0: loss = 1.10201 (* 1 = 1.10201 loss)
I1010 15:45:11.236275 28708 sgd_solver.cpp:105] Iteration 0, lr = 0.001
I1010 18:08:48.657411 28708 solver.cpp:447] Snapshotting to binary proto file snapshots/znet3_iter_500.caffemodel
I1010 18:08:49.007560 28708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/znet3_iter_500.solverstate
I1010 18:08:49.173130 28708 solver.cpp:330] Iteration 500, Testing net (#0)
I1010 18:14:54.063236 28708 solver.cpp:397]     Test net output #0: accuracy = 0.694638
I1010 18:14:54.065783 28708 solver.cpp:397]     Test net output #1: loss = 0.545096 (* 1 = 0.545096 loss)
I1010 18:14:54.068110 28708 solver.cpp:397]     Test net output #2: per_class_accuracy = 0.652255
I1010 18:14:54.070446 28708 solver.cpp:397]     Test net output #3: per_class_accuracy = 0.64847
I1010 18:14:54.072775 28708 solver.cpp:397]     Test net output #4: per_class_accuracy = 0.859331
I1010 18:15:11.170909 28708 solver.cpp:218] Iteration 500 (0.0555556 iter/s, 9000s/500 iters), loss = 0.5205
I1010 18:15:11.173276 28708 solver.cpp:237]     Train net output #0: loss = 0.483311 (* 1 = 0.483311 loss)
I1010 18:15:11.175607 28708 sgd_solver.cpp:105] Iteration 500, lr = 0.001
I1010 20:38:45.902483 28708 solver.cpp:447] Snapshotting to binary proto file snapshots/znet3_iter_1000.caffemodel
I1010 20:38:46.204480 28708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/znet3_iter_1000.solverstate
I1010 20:38:46.373193 28708 solver.cpp:330] Iteration 1000, Testing net (#0)
I1010 20:44:51.196478 28708 solver.cpp:397]     Test net output #0: accuracy = 0.68918
I1010 20:44:51.199065 28708 solver.cpp:397]     Test net output #1: loss = 0.77357 (* 1 = 0.77357 loss)
I1010 20:44:51.201503 28708 solver.cpp:397]     Test net output #2: per_class_accuracy = 0.644611
I1010 20:44:51.203903 28708 solver.cpp:397]     Test net output #3: per_class_accuracy = 0.433566
I1010 20:44:51.206303 28708 solver.cpp:397]     Test net output #4: per_class_accuracy = 0.910204
I1010 20:45:08.315054 28708 solver.cpp:218] Iteration 1000 (0.0555728 iter/s, 8997.2s/500 iters), loss = 0.506821
I1010 20:45:08.317492 28708 solver.cpp:237]     Train net output #0: loss = 0.501549 (* 1 = 0.501549 loss)
I1010 20:45:08.319901 28708 sgd_solver.cpp:105] Iteration 1000, lr = 0.001
I1010 23:08:40.194181 28708 solver.cpp:447] Snapshotting to binary proto file snapshots/znet3_iter_1500.caffemodel
I1010 23:08:40.493538 28708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/znet3_iter_1500.solverstate
I1010 23:08:40.658038 28708 solver.cpp:330] Iteration 1500, Testing net (#0)
I1010 23:14:46.600391 28708 solver.cpp:397]     Test net output #0: accuracy = 0.743785
I1010 23:14:46.603601 28708 solver.cpp:397]     Test net output #1: loss = 0.482334 (* 1 = 0.482334 loss)
I1010 23:14:46.606065 28708 solver.cpp:397]     Test net output #2: per_class_accuracy = 0.724234
I1010 23:14:46.608543 28708 solver.cpp:397]     Test net output #3: per_class_accuracy = 0.735957
I1010 23:14:46.611042 28708 solver.cpp:397]     Test net output #4: per_class_accuracy = 0.77702
I1010 23:15:03.716071 28708 solver.cpp:218] Iteration 1500 (0.0555836 iter/s, 8995.46s/500 iters), loss = 0.525143
I1010 23:15:03.718595 28708 solver.cpp:237]     Train net output #0: loss = 0.393701 (* 1 = 0.393701 loss)
I1010 23:15:03.721076 28708 sgd_solver.cpp:105] Iteration 1500, lr = 0.001
I1011 01:38:42.165552 28708 solver.cpp:447] Snapshotting to binary proto file snapshots/znet3_iter_2000.caffemodel
I1011 01:38:42.477329 28708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/znet3_iter_2000.solverstate
I1011 01:38:42.646793 28708 solver.cpp:330] Iteration 2000, Testing net (#0)
I1011 01:44:49.197679 28708 solver.cpp:397]     Test net output #0: accuracy = 0.821101
I1011 01:44:49.200467 28708 solver.cpp:397]     Test net output #1: loss = 0.509515 (* 1 = 0.509515 loss)
I1011 01:44:49.203045 28708 solver.cpp:397]     Test net output #2: per_class_accuracy = 0.826123
I1011 01:44:49.205591 28708 solver.cpp:397]     Test net output #3: per_class_accuracy = 0.641519
I1011 01:44:49.208150 28708 solver.cpp:397]     Test net output #4: per_class_accuracy = 0.752904
I1011 01:45:06.309346 28708 solver.cpp:218] Iteration 2000 (0.0555391 iter/s, 9002.67s/500 iters), loss = 0.448056
I1011 01:45:06.311957 28708 solver.cpp:237]     Train net output #0: loss = 0.368812 (* 1 = 0.368812 loss)
I1011 01:45:06.314558 28708 sgd_solver.cpp:105] Iteration 2000, lr = 0.001
I1011 04:08:35.705755 28708 solver.cpp:447] Snapshotting to binary proto file snapshots/znet3_iter_2500.caffemodel
I1011 04:08:36.005980 28708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/znet3_iter_2500.solverstate
I1011 04:08:36.171700 28708 solver.cpp:330] Iteration 2500, Testing net (#0)
I1011 04:14:42.677491 28708 solver.cpp:397]     Test net output #0: accuracy = 0.815583
I1011 04:14:42.680347 28708 solver.cpp:397]     Test net output #1: loss = 0.530923 (* 1 = 0.530923 loss)
I1011 04:14:42.682993 28708 solver.cpp:397]     Test net output #2: per_class_accuracy = 0.8187
I1011 04:14:42.685694 28708 solver.cpp:397]     Test net output #3: per_class_accuracy = 0.631848
I1011 04:14:42.688324 28708 solver.cpp:397]     Test net output #4: per_class_accuracy = 0.726752
I1011 04:14:59.787838 28708 solver.cpp:218] Iteration 2500 (0.0555956 iter/s, 8993.52s/500 iters), loss = 0.499178
I1011 04:14:59.790558 28708 solver.cpp:237]     Train net output #0: loss = 0.445917 (* 1 = 0.445917 loss)
I1011 04:14:59.793247 28708 sgd_solver.cpp:105] Iteration 2500, lr = 0.001
I1011 06:38:27.156239 28708 solver.cpp:447] Snapshotting to binary proto file snapshots/znet3_iter_3000.caffemodel
I1011 06:38:27.455981 28708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/znet3_iter_3000.solverstate
I1011 06:38:27.621897 28708 solver.cpp:330] Iteration 3000, Testing net (#0)
I1011 06:44:34.628769 28708 solver.cpp:397]     Test net output #0: accuracy = 0.796629
I1011 06:44:34.632186 28708 solver.cpp:397]     Test net output #1: loss = 0.436597 (* 1 = 0.436597 loss)
I1011 06:44:34.634898 28708 solver.cpp:397]     Test net output #2: per_class_accuracy = 0.778645
I1011 06:44:34.637629 28708 solver.cpp:397]     Test net output #3: per_class_accuracy = 0.68409
I1011 06:44:34.640384 28708 solver.cpp:397]     Test net output #4: per_class_accuracy = 0.842411
I1011 06:44:51.735508 28708 solver.cpp:218] Iteration 3000 (0.0556048 iter/s, 8992.03s/500 iters), loss = 0.431983
I1011 06:44:51.738304 28708 solver.cpp:237]     Train net output #0: loss = 0.514611 (* 1 = 0.514611 loss)
I1011 06:44:51.741067 28708 sgd_solver.cpp:105] Iteration 3000, lr = 0.001
I1011 09:08:26.836442 28708 solver.cpp:447] Snapshotting to binary proto file snapshots/znet3_iter_3500.caffemodel
I1011 09:08:27.143251 28708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/znet3_iter_3500.solverstate
I1011 09:08:27.311012 28708 solver.cpp:330] Iteration 3500, Testing net (#0)
I1011 09:14:34.518476 28708 solver.cpp:397]     Test net output #0: accuracy = 0.698461
I1011 09:14:34.521512 28708 solver.cpp:397]     Test net output #1: loss = 0.463191 (* 1 = 0.463191 loss)
I1011 09:14:34.524312 28708 solver.cpp:397]     Test net output #2: per_class_accuracy = 0.659897
I1011 09:14:34.527143 28708 solver.cpp:397]     Test net output #3: per_class_accuracy = 0.739624
I1011 09:14:34.529963 28708 solver.cpp:397]     Test net output #4: per_class_accuracy = 0.847107
I1011 09:14:51.626976 28708 solver.cpp:218] Iteration 3500 (0.055556 iter/s, 8999.93s/500 iters), loss = 0.446175
I1011 09:14:51.629904 28708 solver.cpp:237]     Train net output #0: loss = 0.432219 (* 1 = 0.432219 loss)
I1011 09:14:51.632776 28708 sgd_solver.cpp:105] Iteration 3500, lr = 0.001
I1011 11:38:27.035241 28708 solver.cpp:447] Snapshotting to binary proto file snapshots/znet3_iter_4000.caffemodel
I1011 11:38:27.335685 28708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/znet3_iter_4000.solverstate
I1011 11:38:27.500929 28708 solver.cpp:330] Iteration 4000, Testing net (#0)
I1011 11:44:34.355705 28708 solver.cpp:397]     Test net output #0: accuracy = 0.717666
I1011 11:44:34.358829 28708 solver.cpp:397]     Test net output #1: loss = 0.54666 (* 1 = 0.54666 loss)
I1011 11:44:34.361759 28708 solver.cpp:397]     Test net output #2: per_class_accuracy = 0.708352
I1011 11:44:34.364683 28708 solver.cpp:397]     Test net output #3: per_class_accuracy = 0.738127
I1011 11:44:34.367625 28708 solver.cpp:397]     Test net output #4: per_class_accuracy = 0.714509
I1011 11:44:51.465306 28708 solver.cpp:218] Iteration 4000 (0.0555562 iter/s, 8999.9s/500 iters), loss = 0.513006
I1011 11:44:51.468305 28708 solver.cpp:237]     Train net output #0: loss = 0.552667 (* 1 = 0.552667 loss)
I1011 11:44:51.471264 28708 sgd_solver.cpp:105] Iteration 4000, lr = 0.001
I1011 14:08:22.873235 28708 solver.cpp:447] Snapshotting to binary proto file snapshots/znet3_iter_4500.caffemodel
I1011 14:08:23.175014 28708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/znet3_iter_4500.solverstate
I1011 14:08:23.341742 28708 solver.cpp:330] Iteration 4500, Testing net (#0)
I1011 14:14:30.500155 28708 solver.cpp:397]     Test net output #0: accuracy = 0.665985
I1011 14:14:30.502599 28708 solver.cpp:397]     Test net output #1: loss = 0.550887 (* 1 = 0.550887 loss)
I1011 14:14:30.504925 28708 solver.cpp:397]     Test net output #2: per_class_accuracy = 0.626271
I1011 14:14:30.507210 28708 solver.cpp:397]     Test net output #3: per_class_accuracy = 0.667408
I1011 14:14:30.510215 28708 solver.cpp:397]     Test net output #4: per_class_accuracy = 0.853234
I1011 14:14:47.614645 28708 solver.cpp:218] Iteration 4500 (0.0555789 iter/s, 8996.21s/500 iters), loss = 0.444891
I1011 14:14:47.617722 28708 solver.cpp:237]     Train net output #0: loss = 0.44582 (* 1 = 0.44582 loss)
I1011 14:14:47.620777 28708 sgd_solver.cpp:105] Iteration 4500, lr = 0.001
I1011 16:38:21.947783 28708 solver.cpp:447] Snapshotting to binary proto file snapshots/znet3_iter_5000.caffemodel
I1011 16:38:22.255774 28708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/znet3_iter_5000.solverstate
I1011 16:38:22.434095 28708 solver.cpp:330] Iteration 5000, Testing net (#0)
I1011 16:44:29.453402 28708 solver.cpp:397]     Test net output #0: accuracy = 0.795812
I1011 16:44:29.457154 28708 solver.cpp:397]     Test net output #1: loss = 0.452648 (* 1 = 0.452648 loss)
I1011 16:44:29.460275 28708 solver.cpp:397]     Test net output #2: per_class_accuracy = 0.774662
I1011 16:44:29.463423 28708 solver.cpp:397]     Test net output #3: per_class_accuracy = 0.640652
I1011 16:44:29.466516 28708 solver.cpp:397]     Test net output #4: per_class_accuracy = 0.857868
I1011 16:44:46.565665 28708 solver.cpp:218] Iteration 5000 (0.0555616 iter/s, 8999.01s/500 iters), loss = 0.601443
I1011 16:44:46.568881 28708 solver.cpp:237]     Train net output #0: loss = 1.14192 (* 1 = 1.14192 loss)
I1011 16:44:46.572036 28708 sgd_solver.cpp:105] Iteration 5000, lr = 0.001
I1011 19:08:09.536954 28708 solver.cpp:447] Snapshotting to binary proto file snapshots/znet3_iter_5500.caffemodel
I1011 19:08:09.845245 28708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/znet3_iter_5500.solverstate
I1011 19:08:10.012122 28708 solver.cpp:330] Iteration 5500, Testing net (#0)
I1011 19:14:16.766902 28708 solver.cpp:397]     Test net output #0: accuracy = 0.528566
I1011 19:14:16.770335 28708 solver.cpp:397]     Test net output #1: loss = 0.820877 (* 1 = 0.820877 loss)
I1011 19:14:16.773579 28708 solver.cpp:397]     Test net output #2: per_class_accuracy = 0.536634
I1011 19:14:16.776787 28708 solver.cpp:397]     Test net output #3: per_class_accuracy = 0.755618
I1011 19:14:16.780009 28708 solver.cpp:397]     Test net output #4: per_class_accuracy = 0.365584
I1011 19:14:33.883088 28708 solver.cpp:218] Iteration 5500 (0.0556336 iter/s, 8987.37s/500 iters), loss = 0.487699
I1011 19:14:33.886333 28708 solver.cpp:237]     Train net output #0: loss = 0.369948 (* 1 = 0.369948 loss)
I1011 19:14:33.889590 28708 sgd_solver.cpp:105] Iteration 5500, lr = 0.001
I1011 21:38:05.858206 28708 solver.cpp:447] Snapshotting to binary proto file snapshots/znet3_iter_6000.caffemodel
I1011 21:38:06.156935 28708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/znet3_iter_6000.solverstate
I1011 21:38:06.323388 28708 solver.cpp:330] Iteration 6000, Testing net (#0)
I1011 21:44:13.046586 28708 solver.cpp:397]     Test net output #0: accuracy = 0.615292
I1011 21:44:13.050073 28708 solver.cpp:397]     Test net output #1: loss = 0.896074 (* 1 = 0.896074 loss)
I1011 21:44:13.053364 28708 solver.cpp:397]     Test net output #2: per_class_accuracy = 0.566089
I1011 21:44:13.056637 28708 solver.cpp:397]     Test net output #3: per_class_accuracy = 0.371519
I1011 21:44:13.059886 28708 solver.cpp:397]     Test net output #4: per_class_accuracy = 0.928058
I1011 21:44:30.157435 28708 solver.cpp:218] Iteration 6000 (0.0555781 iter/s, 8996.34s/500 iters), loss = 0.635802
I1011 21:44:30.160782 28708 solver.cpp:237]     Train net output #0: loss = 0.501008 (* 1 = 0.501008 loss)
I1011 21:44:30.164134 28708 sgd_solver.cpp:105] Iteration 6000, lr = 0.001
I1012 00:08:02.013527 28708 solver.cpp:447] Snapshotting to binary proto file snapshots/znet3_iter_6500.caffemodel
I1012 00:08:02.316737 28708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/znet3_iter_6500.solverstate
I1012 00:08:02.485096 28708 solver.cpp:330] Iteration 6500, Testing net (#0)
I1012 00:14:09.542867 28708 solver.cpp:397]     Test net output #0: accuracy = 0.665477
I1012 00:14:09.550348 28708 solver.cpp:397]     Test net output #1: loss = 0.557111 (* 1 = 0.557111 loss)
I1012 00:14:09.555390 28708 solver.cpp:397]     Test net output #2: per_class_accuracy = 0.635015
I1012 00:14:09.559658 28708 solver.cpp:397]     Test net output #3: per_class_accuracy = 0.702887
I1012 00:14:09.563457 28708 solver.cpp:397]     Test net output #4: per_class_accuracy = 0.794546
I1012 00:14:26.668432 28708 solver.cpp:218] Iteration 6500 (0.0555769 iter/s, 8996.54s/500 iters), loss = 0.449611
I1012 00:14:26.671802 28708 solver.cpp:237]     Train net output #0: loss = 0.44071 (* 1 = 0.44071 loss)
I1012 00:14:26.675146 28708 sgd_solver.cpp:105] Iteration 6500, lr = 0.001
I1012 02:37:56.222088 28708 solver.cpp:447] Snapshotting to binary proto file snapshots/znet3_iter_7000.caffemodel
I1012 02:37:56.521111 28708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/znet3_iter_7000.solverstate
I1012 02:37:56.688007 28708 solver.cpp:330] Iteration 7000, Testing net (#0)
I1012 02:44:04.014132 28708 solver.cpp:397]     Test net output #0: accuracy = 0.815449
I1012 02:44:04.017599 28708 solver.cpp:397]     Test net output #1: loss = 0.624774 (* 1 = 0.624774 loss)
I1012 02:44:04.020952 28708 solver.cpp:397]     Test net output #2: per_class_accuracy = 0.833213
I1012 02:44:04.024296 28708 solver.cpp:397]     Test net output #3: per_class_accuracy = 0.542662
I1012 02:44:04.027596 28708 solver.cpp:397]     Test net output #4: per_class_accuracy = 0.7191
I1012 02:44:21.131165 28708 solver.cpp:218] Iteration 7000 (0.0555893 iter/s, 8994.53s/500 iters), loss = 0.417586
I1012 02:44:21.134521 28708 solver.cpp:237]     Train net output #0: loss = 0.386231 (* 1 = 0.386231 loss)
I1012 02:44:21.137869 28708 sgd_solver.cpp:105] Iteration 7000, lr = 0.001
I1012 05:07:55.802626 28708 solver.cpp:447] Snapshotting to binary proto file snapshots/znet3_iter_7500.caffemodel
I1012 05:07:56.105732 28708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/znet3_iter_7500.solverstate
I1012 05:07:56.273178 28708 solver.cpp:330] Iteration 7500, Testing net (#0)
I1012 05:14:03.613878 28708 solver.cpp:397]     Test net output #0: accuracy = 0.791082
I1012 05:14:03.617455 28708 solver.cpp:397]     Test net output #1: loss = 0.514769 (* 1 = 0.514769 loss)
I1012 05:14:03.620743 28708 solver.cpp:397]     Test net output #2: per_class_accuracy = 0.779414
I1012 05:14:03.624070 28708 solver.cpp:397]     Test net output #3: per_class_accuracy = 0.621605
I1012 05:14:03.627358 28708 solver.cpp:397]     Test net output #4: per_class_accuracy = 0.810909
I1012 05:14:20.734665 28708 solver.cpp:218] Iteration 7500 (0.0555577 iter/s, 8999.66s/500 iters), loss = 0.553083
I1012 05:14:20.738056 28708 solver.cpp:237]     Train net output #0: loss = 0.519783 (* 1 = 0.519783 loss)
I1012 05:14:20.741415 28708 sgd_solver.cpp:105] Iteration 7500, lr = 0.001
I1012 07:37:49.948287 28708 solver.cpp:447] Snapshotting to binary proto file snapshots/znet3_iter_8000.caffemodel
I1012 07:37:50.254199 28708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/znet3_iter_8000.solverstate
I1012 07:37:50.421442 28708 solver.cpp:330] Iteration 8000, Testing net (#0)
I1012 07:43:57.749685 28708 solver.cpp:397]     Test net output #0: accuracy = 0.717877
I1012 07:43:57.753206 28708 solver.cpp:397]     Test net output #1: loss = 0.536343 (* 1 = 0.536343 loss)
I1012 07:43:57.756525 28708 solver.cpp:397]     Test net output #2: per_class_accuracy = 0.693509
I1012 07:43:57.759862 28708 solver.cpp:397]     Test net output #3: per_class_accuracy = 0.688528
I1012 07:43:57.763175 28708 solver.cpp:397]     Test net output #4: per_class_accuracy = 0.761563
I1012 07:44:14.867281 28708 solver.cpp:218] Iteration 8000 (0.0555915 iter/s, 8994.19s/500 iters), loss = 0.466722
I1012 07:44:14.870646 28708 solver.cpp:237]     Train net output #0: loss = 0.530264 (* 1 = 0.530264 loss)
I1012 07:44:14.873994 28708 sgd_solver.cpp:105] Iteration 8000, lr = 0.001
I1012 10:07:49.320142 28708 solver.cpp:447] Snapshotting to binary proto file snapshots/znet3_iter_8500.caffemodel
I1012 10:07:49.620467 28708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/znet3_iter_8500.solverstate
I1012 10:07:49.789408 28708 solver.cpp:330] Iteration 8500, Testing net (#0)
I1012 10:13:57.116410 28708 solver.cpp:397]     Test net output #0: accuracy = 0.637391
I1012 10:13:57.120409 28708 solver.cpp:397]     Test net output #1: loss = 0.67592 (* 1 = 0.67592 loss)
I1012 10:13:57.123740 28708 solver.cpp:397]     Test net output #2: per_class_accuracy = 0.619394
I1012 10:13:57.127073 28708 solver.cpp:397]     Test net output #3: per_class_accuracy = 0.722014
I1012 10:13:57.130391 28708 solver.cpp:397]     Test net output #4: per_class_accuracy = 0.613701
I1012 10:14:14.234760 28708 solver.cpp:218] Iteration 8500 (0.055559 iter/s, 8999.44s/500 iters), loss = 0.507533
I1012 10:14:14.238162 28708 solver.cpp:237]     Train net output #0: loss = 0.694589 (* 1 = 0.694589 loss)
I1012 10:14:14.241500 28708 sgd_solver.cpp:105] Iteration 8500, lr = 0.001
I1012 12:37:41.794288 28708 solver.cpp:447] Snapshotting to binary proto file snapshots/znet3_iter_9000.caffemodel
I1012 12:37:42.110522 28708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/znet3_iter_9000.solverstate
I1012 12:37:42.280897 28708 solver.cpp:330] Iteration 9000, Testing net (#0)
I1012 12:43:49.327406 28708 solver.cpp:397]     Test net output #0: accuracy = 0.708924
I1012 12:43:49.330946 28708 solver.cpp:397]     Test net output #1: loss = 0.530975 (* 1 = 0.530975 loss)
I1012 12:43:49.334286 28708 solver.cpp:397]     Test net output #2: per_class_accuracy = 0.685081
I1012 12:43:49.337615 28708 solver.cpp:397]     Test net output #3: per_class_accuracy = 0.681554
I1012 12:43:49.340929 28708 solver.cpp:397]     Test net output #4: per_class_accuracy = 0.81416
I1012 12:44:06.440057 28708 solver.cpp:218] Iteration 9000 (0.0556034 iter/s, 8992.26s/500 iters), loss = 0.499269
I1012 12:44:06.443416 28708 solver.cpp:237]     Train net output #0: loss = 0.476324 (* 1 = 0.476324 loss)
I1012 12:44:06.446787 28708 sgd_solver.cpp:105] Iteration 9000, lr = 0.001
I1012 15:07:36.582805 28708 solver.cpp:447] Snapshotting to binary proto file snapshots/znet3_iter_9500.caffemodel
I1012 15:07:36.883916 28708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/znet3_iter_9500.solverstate
I1012 15:07:37.050360 28708 solver.cpp:330] Iteration 9500, Testing net (#0)
I1012 15:13:44.101003 28708 solver.cpp:397]     Test net output #0: accuracy = 0.731312
I1012 15:13:44.104580 28708 solver.cpp:397]     Test net output #1: loss = 0.526591 (* 1 = 0.526591 loss)
I1012 15:13:44.107923 28708 solver.cpp:397]     Test net output #2: per_class_accuracy = 0.698628
I1012 15:13:44.111263 28708 solver.cpp:397]     Test net output #3: per_class_accuracy = 0.627569
I1012 15:13:44.114562 28708 solver.cpp:397]     Test net output #4: per_class_accuracy = 0.856357
I1012 15:14:01.208763 28708 solver.cpp:218] Iteration 9500 (0.0555875 iter/s, 8994.83s/500 iters), loss = 0.517635
I1012 15:14:01.212143 28708 solver.cpp:237]     Train net output #0: loss = 0.418849 (* 1 = 0.418849 loss)
I1012 15:14:01.215598 28708 sgd_solver.cpp:105] Iteration 9500, lr = 0.001
I1012 17:37:33.155736 28708 solver.cpp:447] Snapshotting to binary proto file snapshots/znet3_iter_10000.caffemodel
I1012 17:37:33.457958 28708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/znet3_iter_10000.solverstate
I1012 17:37:33.626343 28708 solver.cpp:330] Iteration 10000, Testing net (#0)
I1012 17:43:40.855026 28708 solver.cpp:397]     Test net output #0: accuracy = 0.63173
I1012 17:43:40.859058 28708 solver.cpp:397]     Test net output #1: loss = 0.637898 (* 1 = 0.637898 loss)
I1012 17:43:40.862402 28708 solver.cpp:397]     Test net output #2: per_class_accuracy = 0.58863
I1012 17:43:40.865710 28708 solver.cpp:397]     Test net output #3: per_class_accuracy = 0.654316
I1012 17:43:40.869037 28708 solver.cpp:397]     Test net output #4: per_class_accuracy = 0.840236
I1012 17:43:57.977792 28708 solver.cpp:218] Iteration 10000 (0.0555751 iter/s, 8996.83s/500 iters), loss = 0.553628
I1012 17:43:57.981164 28708 solver.cpp:237]     Train net output #0: loss = 0.446442 (* 1 = 0.446442 loss)
I1012 17:43:57.984517 28708 sgd_solver.cpp:105] Iteration 10000, lr = 0.001
I1012 20:07:29.261354 28708 solver.cpp:447] Snapshotting to binary proto file snapshots/znet3_iter_10500.caffemodel
I1012 20:07:29.563103 28708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/znet3_iter_10500.solverstate
I1012 20:07:29.731411 28708 solver.cpp:330] Iteration 10500, Testing net (#0)
I1012 20:13:36.594931 28708 solver.cpp:397]     Test net output #0: accuracy = 0.707058
I1012 20:13:36.598973 28708 solver.cpp:397]     Test net output #1: loss = 0.586928 (* 1 = 0.586928 loss)
I1012 20:13:36.602313 28708 solver.cpp:397]     Test net output #2: per_class_accuracy = 0.672184
I1012 20:13:36.605624 28708 solver.cpp:397]     Test net output #3: per_class_accuracy = 0.596704
I1012 20:13:36.608955 28708 solver.cpp:397]     Test net output #4: per_class_accuracy = 0.833049
I1012 20:13:53.715972 28708 solver.cpp:218] Iteration 10500 (0.0555815 iter/s, 8995.8s/500 iters), loss = 0.625365
I1012 20:13:53.719344 28708 solver.cpp:237]     Train net output #0: loss = 0.665554 (* 1 = 0.665554 loss)
I1012 20:13:53.722757 28708 sgd_solver.cpp:105] Iteration 10500, lr = 0.001
I1012 22:37:28.161830 28708 solver.cpp:447] Snapshotting to binary proto file snapshots/znet3_iter_11000.caffemodel
I1012 22:37:28.466280 28708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/znet3_iter_11000.solverstate
I1012 22:37:28.633415 28708 solver.cpp:330] Iteration 11000, Testing net (#0)
I1012 22:43:35.678797 28708 solver.cpp:397]     Test net output #0: accuracy = 0.283581
I1012 22:43:35.682201 28708 solver.cpp:397]     Test net output #1: loss = 1.65229 (* 1 = 1.65229 loss)
I1012 22:43:35.685559 28708 solver.cpp:397]     Test net output #2: per_class_accuracy = 0.164903
I1012 22:43:35.688885 28708 solver.cpp:397]     Test net output #3: per_class_accuracy = 0.144828
I1012 22:43:35.692174 28708 solver.cpp:397]     Test net output #4: per_class_accuracy = 0.950502
I1012 22:43:52.792773 28708 solver.cpp:218] Iteration 11000 (0.055561 iter/s, 8999.12s/500 iters), loss = 0.493711
I1012 22:43:52.796118 28708 solver.cpp:237]     Train net output #0: loss = 0.449562 (* 1 = 0.449562 loss)
I1012 22:43:52.799443 28708 sgd_solver.cpp:105] Iteration 11000, lr = 0.001
I1013 01:07:28.024492 28708 solver.cpp:447] Snapshotting to binary proto file snapshots/znet3_iter_11500.caffemodel
I1013 01:07:28.323163 28708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/znet3_iter_11500.solverstate
I1013 01:07:28.489831 28708 solver.cpp:330] Iteration 11500, Testing net (#0)
I1013 01:13:35.780294 28708 solver.cpp:397]     Test net output #0: accuracy = 0.679701
I1013 01:13:35.783795 28708 solver.cpp:397]     Test net output #1: loss = 0.536329 (* 1 = 0.536329 loss)
I1013 01:13:35.787107 28708 solver.cpp:397]     Test net output #2: per_class_accuracy = 0.645583
I1013 01:13:35.790437 28708 solver.cpp:397]     Test net output #3: per_class_accuracy = 0.694772
I1013 01:13:35.793751 28708 solver.cpp:397]     Test net output #4: per_class_accuracy = 0.820123
I1013 01:13:52.898540 28708 solver.cpp:218] Iteration 11500 (0.0555545 iter/s, 9000.17s/500 iters), loss = 0.461233
I1013 01:13:52.901912 28708 solver.cpp:237]     Train net output #0: loss = 0.49677 (* 1 = 0.49677 loss)
I1013 01:13:52.905253 28708 sgd_solver.cpp:105] Iteration 11500, lr = 0.001
I1013 03:37:27.413166 28708 solver.cpp:447] Snapshotting to binary proto file snapshots/znet3_iter_12000.caffemodel
I1013 03:37:27.723302 28708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/znet3_iter_12000.solverstate
I1013 03:37:27.892882 28708 solver.cpp:330] Iteration 12000, Testing net (#0)
I1013 03:43:34.526350 28708 solver.cpp:397]     Test net output #0: accuracy = 0.796177
I1013 03:43:34.530333 28708 solver.cpp:397]     Test net output #1: loss = 0.579939 (* 1 = 0.579939 loss)
I1013 03:43:34.533668 28708 solver.cpp:397]     Test net output #2: per_class_accuracy = 0.804177
I1013 03:43:34.536993 28708 solver.cpp:397]     Test net output #3: per_class_accuracy = 0.625953
I1013 03:43:34.540310 28708 solver.cpp:397]     Test net output #4: per_class_accuracy = 0.696406
I1013 03:43:51.651664 28708 solver.cpp:218] Iteration 12000 (0.0555629 iter/s, 8998.81s/500 iters), loss = 0.507128
I1013 03:43:51.655028 28708 solver.cpp:237]     Train net output #0: loss = 0.545067 (* 1 = 0.545067 loss)
I1013 03:43:51.658351 28708 sgd_solver.cpp:105] Iteration 12000, lr = 0.001
I1013 06:07:29.240614 28708 solver.cpp:447] Snapshotting to binary proto file snapshots/znet3_iter_12500.caffemodel
I1013 06:07:29.548456 28708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/znet3_iter_12500.solverstate
I1013 06:07:29.716948 28708 solver.cpp:330] Iteration 12500, Testing net (#0)
I1013 06:13:36.320672 28708 solver.cpp:397]     Test net output #0: accuracy = 0.689636
I1013 06:13:36.324187 28708 solver.cpp:397]     Test net output #1: loss = 0.54301 (* 1 = 0.54301 loss)
I1013 06:13:36.327507 28708 solver.cpp:397]     Test net output #2: per_class_accuracy = 0.644942
I1013 06:13:36.330801 28708 solver.cpp:397]     Test net output #3: per_class_accuracy = 0.635925
I1013 06:13:36.334090 28708 solver.cpp:397]     Test net output #4: per_class_accuracy = 0.840714
I1013 06:13:53.439846 28708 solver.cpp:218] Iteration 12500 (0.0555441 iter/s, 9001.86s/500 iters), loss = 0.474811
I1013 06:13:53.443202 28708 solver.cpp:237]     Train net output #0: loss = 0.64911 (* 1 = 0.64911 loss)
I1013 06:13:53.446527 28708 sgd_solver.cpp:105] Iteration 12500, lr = 0.001
I1013 08:37:25.605994 28708 solver.cpp:447] Snapshotting to binary proto file snapshots/znet3_iter_13000.caffemodel
I1013 08:37:25.904664 28708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/znet3_iter_13000.solverstate
I1013 08:37:26.084197 28708 solver.cpp:330] Iteration 13000, Testing net (#0)
I1013 08:43:33.180047 28708 solver.cpp:397]     Test net output #0: accuracy = 0.826335
I1013 08:43:33.183588 28708 solver.cpp:397]     Test net output #1: loss = 0.520891 (* 1 = 0.520891 loss)
I1013 08:43:33.186899 28708 solver.cpp:397]     Test net output #2: per_class_accuracy = 0.826486
I1013 08:43:33.190208 28708 solver.cpp:397]     Test net output #3: per_class_accuracy = 0.561566
I1013 08:43:33.193507 28708 solver.cpp:397]     Test net output #4: per_class_accuracy = 0.81547
I1013 08:43:50.295013 28708 solver.cpp:218] Iteration 13000 (0.0555746 iter/s, 8996.91s/500 iters), loss = 0.399285
I1013 08:43:50.298365 28708 solver.cpp:237]     Train net output #0: loss = 0.448961 (* 1 = 0.448961 loss)
I1013 08:43:50.301729 28708 sgd_solver.cpp:105] Iteration 13000, lr = 0.001
I1013 11:07:26.876209 28708 solver.cpp:447] Snapshotting to binary proto file snapshots/znet3_iter_13500.caffemodel
I1013 11:07:27.186244 28708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/znet3_iter_13500.solverstate
I1013 11:07:27.364783 28708 solver.cpp:330] Iteration 13500, Testing net (#0)
I1013 11:13:34.136154 28708 solver.cpp:397]     Test net output #0: accuracy = 0.741886
I1013 11:13:34.139703 28708 solver.cpp:397]     Test net output #1: loss = 0.52709 (* 1 = 0.52709 loss)
I1013 11:13:34.143025 28708 solver.cpp:397]     Test net output #2: per_class_accuracy = 0.714841
I1013 11:13:34.146330 28708 solver.cpp:397]     Test net output #3: per_class_accuracy = 0.646656
I1013 11:13:34.149623 28708 solver.cpp:397]     Test net output #4: per_class_accuracy = 0.808819
I1013 11:13:51.257477 28708 solver.cpp:218] Iteration 13500 (0.0555492 iter/s, 9001.03s/500 iters), loss = 0.467074
I1013 11:13:51.260828 28708 solver.cpp:237]     Train net output #0: loss = 0.43497 (* 1 = 0.43497 loss)
I1013 11:13:51.264175 28708 sgd_solver.cpp:105] Iteration 13500, lr = 0.001
I1013 11:23:02.666384 28708 solver.cpp:447] Snapshotting to binary proto file snapshots/znet3_iter_13533.caffemodel
I1013 11:23:02.966766 28708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/znet3_iter_13533.solverstate
I1013 11:23:03.133654 28708 solver.cpp:294] Optimization stopped early.
I1013 11:23:03.137266 28708 caffe.cpp:259] Optimization Done.
