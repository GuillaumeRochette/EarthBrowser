\documentclass[a4paper, 10pt]{report}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx, float}
\usepackage{algorithm, algorithmic}
\usepackage{csquotes}
\usepackage{wasysym}
\usepackage{dsfont}
\usepackage{yhmath}
\usepackage{hyperref}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}

\author{Guillaume Rochette}
\title{Stage de Fin d'Études
		\\
Création d'un Moteur de Recherche dans les Images Satellite}

\newcommand{\lexp}[1]{\phantom{}^{#1}}
\newcommand{\elem}[4]{\lexp{#2}#1^{#3}_{#4}}

\begin{document}
\maketitle
\tableofcontents
	
\chapter{Introduction}
\section{Présentation de l'Entreprise}
\subsection{Le Groupe Thales}
Le groupe Thales, historiquement fabricant d'électronique, est un acteur français majeur dans les secteurs de l'aéronautique, le spatial, la défense, la sécurité et le transport terrestre.
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.3]{Images/Secteurs_Activites.png}
		\caption{Secteurs d'activités de Thales}
	\end{center}
\end{figure}
Le groupe Thales est implanté dans $56$ pays et emploie $64000$ salariés, dont $34000$ collaborateurs répartis dans $70$ sites en France.
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.4]{Images/Chiffres_Cles.png}
		\caption{Chiffres Clés du Groupe Thales}
	\end{center}
\end{figure}
\subsection{Thales Services}
Thales Services est une entreprise spécialisée dans les activités de conception, développement et maintenance de systèmes informatiques sécurisés.

Elle est implantée sur tout le territoire français, chaque site ayant des spécialisations différentes.
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.75]{Images/TS_France.png}
		\caption{Implantation de Thales Services en France}
	\end{center}
\end{figure}
Le groupe Thales, et par extension Thales Services, est organisé de façon \emph{matricielle}, c'est-à-dire par zones géographiques et par domaines d'activités.
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.4]{Images/Matrice_Thales_Services.png}
		\caption{Organisation matricielle de Thales Services}
	\end{center}
\end{figure}
Ce stage s'effectue dans le \emph{Centre de Compétences} \textbf{Logiciel Orienté Machine} de la \emph{Région Sud-Ouest}.
%\section{Problématique(s)}
\section{Objectifs du Stage}
La place de l'apprentissage profond grandit dans de nombreux domaines de l'industrie, et particulièrement dans les secteurs liés au traitement d'image.

Le potentiel de l'apprentissage profond à réaliser des tâches jugées complexes pour des algorithmes \emph{traditionnels} est immense.
Pour certaines applications de vision, la machine offre aujourd'hui des performances supérieures à celles d'un humain.
Les avancées les plus spectaculaires à ce jour sont majoritairement réalisées sur des images provenant de la photographie grand-public, avec ses particularités et ses contraintes.

Thales Services, dont le client principal est le Centre National d'Études Spatiales (CNES), produit des suites de logiciels utilisés dans la chaîne de traitement d'images pour des satellites tels que Pléiades, SPOT ou encore Sentinel-2.

L'application de méthodes d'apprentissage profond à des images satellites est prometteuse mais encore peu utilisée, justifiant l'intérêt et la volonté de Thales Services de monter en compétence dans ce domaine.

Les objectifs de ce stage sont les suivants :
\begin{itemize}
	\item Apporter des connaissances relatives à l'apprentissage profond appliqué au traitement de l'image.
	\item Déterminer des opportunités d'application de l'apprentissage profond à la recherche dans les images.
	\item Proposer et évaluer des modèles pour les applications proposées.
\end{itemize}

\chapter{L'Imagerie Satellite}
De tout temps, l'humain a toujours souhaité pouvoir observer le monde, que ce soit à des fins militaires, scientifiques ou à simple but de contemplation.

Les besoins en matière de \emph{télédétection} sont plus anciens que les premiers satellites artificiels. Dès la fin du XIX ème siècle, lors du siège de Paris en $1870$, des ballons effectuaient des missions de reconnaissance en utilisant les progrès en matière de photographie.

Jusqu'aux années $1970$, la télédétection servait majoritairement à l'espionnage et la cartographie, principalement réalisée par le biais d'appareils photographies emporté dans des avions.
Les premières images de la Terre depuis l'Espace ont été réalisé de cette même manière, des appareils photographiques à microfilm étaient embarqués dans des satellites artificiels. Il est à noter qu'un défi de taille était la réception de ces microfilms alors largués vers la Terre depuis l'Espace.

L'apparition de \emph{capteurs numériques} a révolutionné le domaine de la télédétection, car permettant de s'abstraire du support physique, problématique de par sa quantité limité à bord, ainsi que sa réception.

Nous aborderons d'abord le fonctionnement d'un \emph{satellite d'observation}, puis nous survolerons les différentes particularités d'une image satellite.
\section{Fonctionnement d'un Satellite d'Observation}
Nous allons d'abord présenter brièvement le fonctionnement des différents types de capteurs numériques existants.
Puis nous aborderons les différents mécanismes relatif au contrôle de la trajectoire du satellite.
\subsection{Capteurs Optiques}
Selon leur longueur d'onde, les ondes électromagnétique portent des noms différents
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{Images/Spectre_Electromagnetique.png}
		\caption{Domaines du spectre électromagnétique}
	\end{center}
\end{figure}
Le domaine \emph{optique} est la réunion du domaine du visible et de l'infrarouge (I.R.).
Bien que les satellites puissent embarquer aussi d'autres types de capteurs, nous n'en parlerons pas, car cela n'a pas de rapport avec l'Imagerie Satellite.

Par ailleurs, nous nous focaliserons uniquement sur les capteurs passifs, c'est à dire des capteurs qui ne font que mesurer le rayonnement d'un objet, contrairement aux capteurs actifs, comme les radars qui émettent un rayonnement et en observent l'écho sur l'objet.
\subsubsection{Capteurs de type Whisk Broom}
Ce sont les premiers capteurs historiques utilisés pour l'imagerie satellite, utilisés par exemple dès $1970$ sur les satellites du programme LANDSAT de la NASA.

Le fonctionnement de ce type de capteur s'apparente au mécanisme des premiers scanners, c'est à dire une unique cellule de détection, qui nécessitait un double balayage selon les axes des lignes et des colonnes pour décrire la scène.
En anglais, le terme \emph{whisk broom} désigne des balais à \emph{fouetter}, comme par exemple des plumeaux.

Voici un schéma décrivant le fonctionnement d'un capteur de type \emph{whisk broom} :
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.7]{Images/Whisk_Broom.jpg}
		\caption{Capteur de type \emph{Whisk Broom}}
	\end{center}
\end{figure}
Les avantages d'un capteur \emph{whisk broom} sont les suivants :
\begin{itemize}
	\item Étant donné qu'un seul capteur n'est utilisé, l'étalonnage de l'appareil est facile, permettant ainsi un rendu homogène de l'image.
	\item La fauchée, c'est-à-dire la largeur au sol de l'image, peut-être très large.
\end{itemize}
Ce type de capteur présente aussi des inconvénients :
\begin{itemize}
	\item Le balayage mécanique est complexe à mettre en œuvre, au niveau des mécanismes à utiliser pour compenser les oscillations du satellite. L'usure de tels mécanismes limitent la durée de vie utile du satellite.
	\item Le temps d'intégration, c'est-à-dire le temps d'acquisition requis pour effectuer une mesure, est le fruit d'un compromis entre une bonne qualité radiométrique et la résolution au sol. En effet, pour obtenir une mesure de qualité, on préfère faire une moyenne sur un grand nombre d'acquisitions, limité par la vitesse orbitale du satellite et l'amplitude des oscillations du capteur, impactant directement la largeur de la fauchée.
\end{itemize}
\subsubsection{Capteurs de type Push Broom}
Le fonctionnement de ces capteurs est inspiré des scanners et photocopieurs grand-publics apparus dans les années $1980$.

Le premier satellite équipé d'un tel dispositif était SPOT $1$, un satellite conçu par le CNES en $1986$.
Le principe de fonctionnement est assez simple, au lieu d'utiliser une unique cellule comme pour les capteurs \emph{whisk broom}, on utilise des lignes, aussi appelées barrettes, de cellules de détection.
Ainsi l'acquisition est simultanée pour les détecteurs composants une seule et même ligne.

Une image, composées de $m$ lignes et $n$ colonnes, est donc le résultat de $n$ acquisitions simultanées répétées à $m$ intervalles de temps suivant trajectoire du satellite.

Voici un schéma décrivant le fonctionnement d'un capteur de type \emph{push broom} :
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.7]{Images/Push_Broom.jpg}
		\caption{Capteur de type \emph{Push Broom}}
	\end{center}
\end{figure}
Les avantages d'un capteur \emph{push broom} sont les suivants :
\begin{itemize}
	\item Simplicité du système.
	\item Perturbations géométriques seulement le long des colonnes.
	\item Larges fauchées grâce à la miniaturisation des cellules.
\end{itemize}
Ce type de capteur présente aussi des inconvénients :
\begin{itemize}
	\item Le plan focal, ou l'alignement, de l'ensemble des capteurs est assez difficile à réaliser.
	\item En raison du nombre important de détecteurs, l'étalonnage radiométrique de l'ensemble est assez complexe.
\end{itemize}

\subsubsection{Capteurs de type Matriciel}
Le fonctionnement de ce capteur est similaire à celui d'un appareil photographique disponible au grand public.

Les cellules de détection sont réparties en forme de grille. Ainsi tous les pixels de l'image sont acquis de façon simultanée.
Voici un schéma décrivant le fonctionnement d'un capteur de type \emph{matriciel} :
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.7]{Images/CCD_Sensor.png}
		\caption{Capteur de type \emph{Matriciel}}
	\end{center}
\end{figure}

Les avantages d'un capteur \emph{push broom} sont les suivants :
\begin{itemize}
	\item Grâce à l'acquisition simultanée de tous les pixels de l'image, il ne peut y avoir de perturbations géométriques, sauf en cas de flou de bougé.
	\item Possibilité de photographier une zone selon plusieurs angles (de visée).
\end{itemize}
Ce type de capteur présente aussi des inconvénients :
\begin{itemize}
	\item Alignement des capteurs très difficile à réaliser de par le nombre très important de détecteurs et de leur répartition en forme de matrice.
	\item Étalonnage radiométrique délicat en raison du grand nombre de détecteurs.
	\item Difficultés d'assembler des prises de vue pour en faire des mosaïques.
\end{itemize}
\subsection{L'Orbite des Satellites}
Le mouvement d'un satellite artificiel autour de la Terre, appelé \emph{orbite}, est qualifié de képlérien car il respecte les trois lois de Kepler :
\begin{itemize}
	\item \emph{Loi des orbites} : Le satellite décrit une trajectoire elliptique, l'un des foyer de l'ellipse étant la Terre. Dans le cas présent, l'ellipse est quasi-circulaire.
	\item \emph{Loi des aires} : L'aire de la surface délimitée par la Terre et un arc $\wideparen{AB}$ de la trajectoire du satellite, noté $\wideparen{AB}T$, est égale à l'aire d'une autre surface définie par un autre arc $\wideparen{CD}$ de l'ellipse, , noté $\wideparen{CD}T$, si le temps de parcours de l'arc $\wideparen{AB}$, noté $t_{\wideparen{AB}}$, est égal à $t_{\wideparen{CD}}$.
	\item \emph{Loi des périodes} : Le carré de la période $T$ d'un satellite est proportionnel au cube du demi-grand axe $a$ de la trajectoire elliptique du satellite : $\frac{T^2}{a^3} = \frac{4 \pi^2}{\mu}$
\end{itemize}
Deux types d'orbites sont principalement utilisé pour les satellites
\subsubsection{L'Orbite Géostationnaire}
L'orbite \emph{géostationnaire} implique comme son nom l'indique que la position du satellite est fixe par rapport à la Terre.
Pour se faire, il faut que l'orbite du satellite soit circulaire autour de la Terre, et que la vitesse \emph{angulaire} du satellite soit égale à la vitesse \emph{angulaire} de la Terre.

Ce type d'orbite est utilisé pour les satellites de télécommunication, ainsi que pour des applications de surveillance de la Terre comme la météorologie, nécessitant un survol constant d'une zone définie.
\subsubsection{L'Orbite Héliosynchrone}
L'orbite \emph{héliosynchrone} signifiant que le satellite soit "synchronisé" avec le soleil, ce qui en d'autres termes implique que le satellite doive tourner à la même vitesse autour de la Terre que la Terre autour du Soleil.

On s'intéresse particulièrement aux orbites quasi-polaires héliosynchrones. En effet, le satellite se déplace presque dans selon une longitude et conserve un angle constant entre le plan d'orbite et la direction Terre-Soleil.
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.3]{Images/Orbite_Heliosynchrone.png}
		\caption{Orbite Héliosynchrone}
	\end{center}
\end{figure}
Ce type d'orbite est très intéressant pour l'imagerie spatiale car cela signifie que le satellite repasse à un point à la même heure de la journée, ce qui dans le cas d'un satellite d'observation nous permet de prendre des photographies avec une lumière ayant toujours le même angle d'incidence et donc un ensoleillement comparable.
\subsubsection{Trace au Sol et Fauchée d'un Satellite}
La trace au sol est la projection de la trajectoire décrite par un satellite à la surface du globe terrestre.

La fauchée d'un satellite est la la surface au sol couverte par la prise de vue du capteur optique.
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.4]{Images/Swath.png}
		\caption{Fauchée d'un satellite}
	\end{center}
\end{figure}
Dans le cas d'une orbite quasi-polaire, la trace au sol recouvrira alors presque toute la surface de la Terre (sauf aux pôles) $p$ périodes, permettant de photographier les même zones de façon périodique et constamment à la même d'heure grâce aux propriétés d'héliosynchronisme.
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{Images/Trace_Sol_SPOT.jpg}
		\caption{Trace au sol des satellites SPOT}
	\end{center}
\end{figure}
\section{Images Satellite}
Après avoir détaillé les différents types de capteurs optiques et différentes orbites utilisées pour les satellites, nous allons à présent développer un peu plus en détail le produit, les \emph{images satellite}.

\subsection{Métadonnées}
À chaque image satellite, on associe des métadonnées, c'est-à-dire des données externes, qui ne sont pas des \emph{données images}, mais qui apportent des informations complémentaires à l'image.

Voici une liste non-exhaustive des informations habituellement contenues dans les métadonnées.
\subsubsection{Le Système de Coordonnées}
Un système de coordonnées est un référentiel permettant d'exprimer la position de points dans un espace, et par conséquent une position sur le globe terrestre.
La Terre n'offre pas de surface géométriquement régulière, de ce fait on peut la représenter de différentes manières :
\begin{itemize}
	\item Une sphère est une approximation grossière de la Terre, venant du fait que la Terre est aplatie aux pôles, ce qui est dû à sa rotation. Mais cette approximation ne suffit pas une cartographie précise.
	\item Un ellipsoïde, une ellipse en trois dimensions, nous permet de modéliser cet aplatissement. C'est ce modèle qui est retenu pour la cartographie.
\end{itemize}

Le système géodésique le plus courant est WGS 84 (World Geodetic System 1984), car utilisé par le système GPS. Il définit une représentation de l'ellipsoïde terrestre, ce système est référencé en $2$ dimensions, longitude et latitude, et en $3$ dimensions en ajoutant l'altitude.

On peut aussi les exprimer en représentation plane, résultant d'une projection, parfois partielle, de l'ellipsoïde (en $3$ dimensions) sur un plan (en $2$ dimensions). On citera par exemple les projections de Mercator ou de Lambert.

Ces informations, décrivant le système de coordonnées, sont contenues dans le \emph{Well-Known Text}, qui est une chaine de caractères structurée résumant la définition du repère géographique. En voici un exemple :

\begin{verbatim}
GEOGCS["WGS 84",
    DATUM["WGS_1984",
        SPHEROID["WGS 84",6378137,298.257223563,
            AUTHORITY["EPSG","7030"]],
        AUTHORITY["EPSG","6326"]],
    PRIMEM["Greenwich",0],
    UNIT["degree",0.0174532925199433],
    AUTHORITY["EPSG","4326"]]
\end{verbatim}

\subsubsection{Positionnement et Résolution de l'Image}
Il est indispensable d'associer à toute image satellite une position dans l'espace. Une origine, généralement le coin supérieur gauche, est définie dans le système de référencement.

À cette origine, on associe la résolution spatiale de l'image, c'est-à-dire les dimensions d'un pixel dans l'espace projeté.
Par exemple,
\begin{verbatim}
Origin = (32.503388399999999,15.548911199899999)
Pixel Size = (0.000002700000000,-0.000002700000000)
\end{verbatim}
La seconde composante de la taille d'un pixel est ici négative, car l'image à pour origine le coin supérieur gauche, le parcours de l'image se fait donc en avançant dans les longitudes (sens Ouest-Est) mais en descendant les latitudes (sens Nord-Sud).

En ajoutant à ces connaissances la dimension de l'image en pixel, interpoler la position des autres coins de l'image. Ce calcul d'interpolation reste une approximation car il faut prendre en compte l'angle de visée du satellite par rapport au sol.

\subsection{Compression et Formats de Fichier}
Le format de fichier, aussi appelé \emph{driver}, spécifie la façon dont les données sont écrites sur le disque de stockage.
Il existe de nombreux formats de fichiers offrant des possibilités de compression avec ou sans pertes.

Un format très utilisé dans l'imagerie spatiale est le format GeoTIFF, ou GTiff, qui est un dérivé du format TIFF. Il est très utilisé de par sa flexibilité et le nombre de méthodes de compression existantes.

On citera aussi les formats :
\begin{itemize}
	\item JPEG est le format le plus courant en photographie numérique, mais étant un format de compression avec pertes il est peu utilisé en imagerie spatiale.
	\item JPEG2000 est un format propriétaire, successeur annoncé du JPEG, il offre de grandes possibilités de compression utilisant des ondelettes (ratio de 1:50), mais la lecture/écriture sont très lentes dues aux opérations de compression/décompression.
	\item LUM est un format utilisé par le CNES en interne sur la chaîne de traitement des images et pour des simulations, c'est un fichier de format binaire accompagné de métadonnées.
\end{itemize}


\subsection{Caractéristiques d'une Image Satellite}
Nous allons à présent voir quelques propriétés concernant les images, ainsi que certaines particularités des images satellite.
\subsubsection{Angle de visée}
Contrairement aux appareils photographiques classiques, où l'angle de visée dépend de celui qui tient l'appareil, l'angle de visée d'un satellite est généralement situé au \emph{nadir} de celui-ci.

Le \emph{nadir} est le vecteur normal à la surface terrestre depuis le satellite. C'est donc le vecteur opposé du \emph{zénith}.
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{Images/Nadir.png}
		\caption{Nadir, Zénith et Horizons}
	\end{center}
\end{figure}

Le fait que l'angle de visée soit pratiquement toujours le même permet d'unifier les traitements à appliquer sur l'image brute.

L'angle de visée est variable et ce qui permet de re-photographier une zone sans avoir à attendre une période orbitale entière, durant environ $26$ jours pour les satellites de la famille SPOT. Dans ce cas là, il faudra en plus corriger les images pour les ramener à un angle de vue proche du \emph{nadir}, on parle alors de \emph{dépointage} d'une image.

\subsubsection{Bandes et Fusion d'Images}
Une image, et en particulier une image satellite, est constituée de bandes. 

Chaque bande contient la réponse impulsionnelle de la scène sur une longueur d'onde donnée.

Voici les caractéristiques radiométriques du satellite Pléiades :
\begin{center}
	\begin{tabular}{|c|c|c|}
	\hline
	Couleur & Bande Spectrale & Résolution \\
	\hline 
	Bleu & $430$-$550$nm & $2$m \\ 
	\hline 
	Vert & $490$-$610$nm & $2$m \\ 
	\hline 
	Rouge & $600$-$720$nm & $2$m \\ 
	\hline 
	Proche Infrarouge & $750$-$950$nm & $2$m \\ 
	\hline 
	Panchromatique & $480$-$830$nm & $0.5$m \\ 
	\hline 
	\end{tabular}
\end{center}
La bande panchromatique ne discrimine pas les couleurs, son domaine de sensibilité est similaire à la vision humaine, la bande spectrale est située autour de $400$-$750$nm. Ce sont des images en noir et blanc.

Comme nous pouvons le voir sur le tableau, toutes les bandes produites par le satellite Pléiades ne sont pas à la même résolution, les bandes \emph{multispectrales} sont à $2$m, tandis que la bande \emph{panchromatique} est à $0.5$m.
Pourtant le produit après traitement est composé des $4$ bandes couleurs échantillonnées à $0.5$m.

Le traitement appliqué s'appelle la fusion d'images et repose sur :
\begin{enumerate}
	\item La transformée en ondelettes de l'image \emph{panchromatique haute résolution} en une image approximée, c'est-à-dire de plus basse résolution.
	\item La substitution de l'image approximée par l'image \emph{multispectrale}.
	\item La transformée inverse en ondelettes de l'image \emph{multispectrale} pour obtenir une image \emph{multispectrale haute résolution}.
\end{enumerate}

\subsubsection{Prétraitement d'une Image Satellite}
Un grand nombre de traitements interviennent dans la correction géométrique des images afin que le produit final puisse être superposable à une carte.
Voici un récapitulatif des niveaux de traitements pour une image satellite de la famille SPOT :
\begin{itemize}
	\item Niveau 1A : Correction des défauts radiométriques issus des écarts de sensibilité entre les détecteurs élémentaires.
	\item Niveau 1B : Égalisation radiométrique et traitements géométriques relatifs aux variations d'altitude du satellite, à la rotation et à la courbure de la Terre, aux variations de l'angle de visée, etc.
	\item Niveau 2A : Projection de l'image dans le référentiel WGS $84$, la localisation d'un pixel est précise à $300$m.
	\item Niveau 2B : Correction géométriques : utilisation de points d'appuis au sol, de la modélisation de la dynamique de vol, etc.
	\item Niveau 3 : Produit appelé \emph{orthoimage}, où l'erreur de localisation est encore diminuée grâce à des modèles numériques d'élévation pour ajuster le relief, l'erreur de localisation est de $10$m pour des images ayant une résolution de $10$m.
\end{itemize}

\chapter{L'Apprentissage Machine}
L'apprentissage machine permet d'accomplir des tâches traditionnellement compliquées pour les ordinateurs, mais vues comme simple pour l'humain.
En effet, l'humain apprend par exemple dès le plus jeune âge à discerner les contours sur une image, d'en décrire le contenu et même de visualiser un objet sous différents angles. Des algorithmes classiques ont du mal à produire des bons résultats sur ce genre de problèmes.
À l'inverse, les ordinateurs possèdent une capacité très supérieure à l'humain pour résoudre des calculs complexes, ou des problèmes d'ordre combinatoire.

D'un point de vue scientifique et philosophique, l'apprentissage machine est très intéressant et soulève beaucoup de questions, car l'étude de l'apprentissage appliqué aux machines nous permettrait peut-être d'entrevoir certains principes définissant l'intelligence.
\section{Définition d'un Algorithme Apprenant}
Un algorithme apprenant est un algorithme capable d'utiliser des données pour accomplir des tâches. La définition la plus célèbre, proposée par T.M Mitchell, est la suivante :
\begin{displayquote}
	On dit qu'un algorithme apprend grâce à une expérience \emph{E}, par rapport à une classe de tâches à accomplir \emph{T}, dont on peut calculer la mesure de performance (ou d'accomplissement) \emph{P}, si sa capacité d'accomplir la tâche \emph{T}, mesurée par la performance \emph{P}, s'améliore avec l'expérience \emph{E}.
\end{displayquote}

Un tel algorithme basera son apprentissage sur un jeu de données. Un jeu de données est un ensemble d'exemples.
Chaque exemple, noté $e$, est composé d'une entrée, notée $x$, à laquelle on peut associer, dans le cas d'un apprentissage supervisé, une sortie attendue, notée $\hat{y}$.
\subsection{La Tâche}
Le processus d'apprentissage ne représente pas la tâche. L'apprentissage symbolise les moyens d'acquérir la possibilité, qui peut-être aussi vue comme la capacité, d'accomplir une tâche en particulier.
Par exemple, si l'on veut apprendre à un robot à lire, la tâche en question sera la capacité à lire.

En apprentissage machine, une tâche, notée \emph{T}, consiste à faire, pour chaque exemple $e$, correspondre une entrée $x$ à un résultat de sortie $y$.
Une entrée $x$ est au sens statistique un individu décrit par un ensemble de variables.
\begin{center}
	Un individu est représenté par un vecteur $x \in \mathbb{R}^n$, avec $n$ étant le nombre de variables décrivant l'individu et $x_i$ la $i$-ème variable.
\end{center}
Par exemple, une image est vue comme une matrice $I \in \mathbb{R}^{m \times n}$ de pixels, que nous pouvons projeter sur un vecteur $x \in \mathbb{R}^k$, avec $k = m \times n$.

Voici à présent un aperçu non exhaustif des tâches.
\subsubsection{Classification}
La classification consiste à déterminer, pour une entrée $x \in \mathbb{R}^n$, en sortie, une ou plusieurs parmi $k$ catégories, ou classes, associées à l'entrée.

Pour résoudre ce type de problème, l'algorithme apprenant doit produire une fonction $f : \mathbb{R}^n \in E$, avec $E$ étant un ensemble de dimension $k$.
On notera que la structure de $E$ n'est pas fixée.

On peut par exemple avoir :
\begin{itemize}
	\item $E = \{1,..,k\}$, dans ce cas, la classification est dite simple, car pour tout individu $x$ donné, il ne peut correspondre qu'une seule classe.
	\item $E = \{0,1\}^k$, dans ce cas la classification est multiple, car il peut correspondre $0$, $1$ ou plusieurs classes.
	\item $E = \{y \in [0,1]^k/ \sum_{i=1}^{k}{y_i}=1  \}$, dans ce cas, la sortie $y$ représente une distribution de probabilité.
\end{itemize}
La classification est par exemple utilisée pour la reconnaissance d'objets, l'entrée $x$ étant l'image, et la sortie $y$, la classe de l'objet dans l'image.
\subsubsection{Régression}
La régression consiste à prédire une valeur réelle en fonction d'un individu en entrée.

L'algorithme doit par conséquent se comporter comme une fonction $f : \mathbb{R}^n \rightarrow \mathbb{R}$, en faisant correspond à un individu donné $x \in \mathbb{R}^n$, une prédiction $y \in \mathbb{R}$.

On l'utilise par exemple pour l'approximation de fonctions modélisant un phénomène ou encore la prédiction des cours des actions.
\subsubsection{Autres Applications}
Les deux applications citées ci-dessus sont les plus connues et les plus largement utilisées, toutefois il en existe un grand nombre telles que :
\begin{itemize}
	\item La transcription, consistant à traduire des données sans structure particulière en données ayant une structure discrète. Par exemple, extraire le texte d'une image, ou la reconnaissance vocale.
	\item La traduction, consistant à traduire une suite de caractères d'une langue à une autre.
	\item Le débruitage, ou \emph{denoising} : Il s'agit de reconstituer à partir d'un exemple bruité $\tilde{x} \in \mathbb{R}^n$, l'original $x \in \mathbb{R}^n$, en prédisant la probabilité $p(x|\tilde{x})$, c'est à dire que $x$ soit l'original de $\tilde{x}$.
\end{itemize}
		
\subsection{La Mesure de la Performance}
Afin de quantifier les performances d'un algorithme d'apprentissage machine, il nous faut définir une mesure. Cette mesure, notée \emph{P}, est généralement spécifique à la tâche \emph{T} donnée à l'algorithme.
Pour des tâches, telles que la classification, la transcription ou la traduction, on mesure généralement la précision, c'est à dire la proportion d'exemples ou la sortie proposée par le modèle est similaire à la sortie attendue.
Néanmoins, cette mesure n'est pas générale, en effet, par exemple pour une tâche de régression, si l'écart entre la sortie produite et la sortie attendue est faible mais non nul, alors faut-il considérer le modèle comme valide ?

Pour cela, nous définissons une mesure plus générale, une \emph{fonction de perte }associée.
Cette fonction de perte n'a pas de forme particulière car elle dépend de la tâche \emph{T} à réaliser, mais elle décroît à mesure que la sortie $y$ produite par l'algorithme est "bonne".

Afin de réaliser un bon apprentissage, il nous donc minimiser cette \emph{fonction de perte}.

L'apprentissage machine se résume donc à optimiser notre algorithme pour modéliser au mieux une situation.
		
\subsection{L'Expérience}
On peut distinguer deux grandes classes d'algorithmes d'apprentissage machines, les algorithmes d'apprentissage \emph{non-supervisés} et \emph{supervisés}.

Une expérience \emph{E} peut être comprise comme le fait d'apprendre sur un \emph{jeu de données}.
\subsubsection{Apprentissage Non-Supervisé}
Les algorithmes d'apprentissage machine non-supervisés ont pour but d'apprendre sur des jeux de données ne contenant que des entrées $x$, et par exemple apprendre la distribution de probabilité $p(x)$ du jeu de données, ou bien de répartir les données dans des clusters, par le biais d'une distance donnée.
\subsubsection{Apprentissage Supervisé}
Les algorithmes d'apprentissage machine supervisés ont pour but d'apprendre sur un jeu de données, à associer une entrée $x$ à une sortie $y$, que l'on veut proche de la sortie attendue $\hat{y}$. Ce qui peut être vu comme l'apprentissage de la probabilité de $p(y|x)$.
	
\section{Contraintes d'Apprentissage et Régularisation}
\subsection{Sous-apprentissage, Sur-apprentissage et Capacité d'un Algorithme Apprenant}
L'un des défi, et intérêt, majeur en apprentissage machine est la possibilité de bien raisonner sur de nouveaux exemples encore inconnus de l'algorithme. Cette capacité de raisonnement s'appelle la généralisation.
En effet, un algorithme apprenant s'appuie pour l'entraînement sur un ensemble d'apprentissage, ce qui nous permet de mesurer l'\emph{erreur d'apprentissage}, terme équivalent à la \emph{fonction de perte} sur les données d'apprentissage, et ainsi de la minimiser.

Ce qui différencie un simple problème d'optimisation de l'apprentissage machine, est que nous souhaitons non seulement que notre algorithme ait une \emph{erreur d’apprentissage} faible, mais que sa capacité à généraliser, traduite par l'\emph{erreur de généralisation} ou \emph{erreur de test}, soit aussi petite que possible.

Ainsi, pour juger de l'efficacité d'un algorithme apprenant, nous devons prendre en compte l'\emph{erreur d'apprentissage}, mais aussi que la différence entre l'\emph{erreur d'apprentissage} et l'\emph{erreur de test}.
\subsubsection{Sous-apprentissage}
Le phénomène de sous-apprentissage survient lorsque pour un problème donné et un modèle choisi, l'\emph{erreur d'apprentissage} n'est pas suffisamment faible pour obtenir de bons résultats.
On peut donc interpréter le sous-apprentissage comme étant l'incapacité d'un modèle à ajuster un phénomène.
\subsubsection{Sur-apprentissage}
Le phénomène de sur-apprentissage survient lorsque l'écart entre l'\emph{erreur d'apprentissage} et l'\emph{erreur de test} est trop grand. Cela signifie que notre modèle, proposé par l'algorithme d'apprentissage, a été capable d'apprendre suffisamment sur les exemples d'entraînement, mais n'est pas capable de généraliser sur des exemples de test, sur lesquels il n'a pas appris.
\subsubsection{Capacité}
On peut alors définir la \emph{capacité} d'un modèle comme étant la mesure théorique de ses performances d'apprentissage mais aussi de ses performances en terme de généralisation.

Ainsi le modèle le plus adapté à notre problème aura une capacité suffisante pour apprendre correctement la fonction à produire par rapport aux données, mais ne sera pas trop grande, afin de garder un pouvoir suffisant de généralisation.
			
\subsubsection{Exemple}
Nous allons maintenant introduire un exemple nous permettant d'illustrer ces concepts.

La tâche \emph{T} est une régression polynomiale, c'est-à-dire que nous devons trouver un polynôme $P \in \mathbb{R}^{q}$ ajustant au mieux nos données.

$P$ est donc de la forme :
$$P(z) = b + \sum_{j=1}^{q}{\theta_j z^j}$$
L'expérience \emph{E} est un ensemble de $n$ points $(x_i,y_i)$, que l'on peut résumer en deux vecteurs :
$$x, y \in \mathbb{R}^n$$
Et la mesure de performance \emph{P}, le critère des moindres carrés, c'est-à-dire :
$$J_0(x,y) =\frac{1}{2} \sum_{i=1}^{n}{(P(x_i)-y_i)^2}$$
Si l'on considère que $P(x) = (P(x_i))_{i=1..q}$, alors on peut réécrire $J_0(x,y)$ tel que :
$$J_0(x,y) = \frac{1}{2} (P(x)-y)^T(P(x)-y)$$
Voici le nuage de $10$ points à ajuster :
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{Images/Fitting_Problem.png}
		\caption{Nuage de $10$ points à ajuster}		
	\end{center}
\end{figure}
			
			
Si nous choisissons un polynôme $P \in \mathbb{R}^1$, c'est à dire de la forme $P(z) = b + \theta z$, en minimisant le \emph{problème des moindres carrés}, nous obtenons la courbe suivante.
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{Images/Underfitting.png}
		\caption{Cas de sous-apprentissage}			
	\end{center}
\end{figure}
Sans même faire d'études statistiques, on peut voir que le modèle ajuste mal les données.
Si nous choisissons par contre un polynôme $P \in \mathbb{R}^9$, en minimisant le \emph{problème des moindres carrés}, nous obtenons la courbe suivante.
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{Images/Overfitting.png}
		\caption{Cas de sur-apprentissage}
	\end{center}
\end{figure}
On peut s'apercevoir que même si la droite passe exactement par nos $10$ points, le modèle ne semblera pas ajuster d'éventuelles nouvelles données.
			
Enfin, si l'on choisit un polynôme $P \in \mathbb{R}^2$, nous ajustons tous les points du jeu de données et le modèle semble suffisamment simple pour généraliser de nouvelles données.
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{Images/Good_Fitting.png}
		\caption{Capacité du modèle adaptée}
	\end{center}
\end{figure}
		
\subsection{Régularisation}
Dans l'exemple précédent, nous avons vu que le choix du modèle influait sur sa capacité, c'est à dire de tenter de produire une fonction suffisamment générale par rapport au phénomène représenté par les données.
Afin d'améliorer les capacités de généralisation des algorithmes d'apprentissage machine, un principe, dont les premières formulations sont attribuées à Ptolémée, $II^e$ siècle, connu dans la littérature, sous le nom du Rasoir d'Occam (ou Ockham) est le suivant : 
\begin{displayquote}
	Les hypothèses suffisantes les plus simples sont les plus vraisemblables.
\end{displayquote}
Ce principe de parcimonie, ou de simplicité, consiste à ne pas utiliser d'hypothèses spécifiques à un problème, si il existe des hypothèses générales plus simples répondant à ce même problème.

Ainsi pour résoudre notre problème, notre modèle doit être suffisamment performant sur un problème spécifique, mais doit être assez général pour produire des résultats corrects si l'on change quelques hypothèses.
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{Images/Regularization.png}
		\caption{Dilemme du choix entre deux modèles}
	\end{center}
\end{figure}
Dans cet exemple, nous choisirons bien entendu la courbe verte, car le modèle vert est beaucoup plus simple et nous semble plus cohérent par rapport à nos données.
Cette recherche d'un modèle optimal mais suffisamment simple peut se faire en ajoutant une composante à la mesure de performance.

En reprenant l'exemple précédent, nous pouvons ajouter à $J_0(x,y)$ une fonction $f$ arbitraire, qui aurait tendance à pénaliser l'effet de sur-apprentissage.
Cette fonction $f$ peut dépendre par exemple des coefficients $\theta_i$ du polynôme.
Ce qui nous donne une fonction :
$$J(x,y,\theta) = J_0(x,y) + \lambda f(\theta)$$
On peut choisir par exemple $f(\theta) = \sum_{i=1}^{q}{\theta_i^i}$ et ainsi pénaliser les coefficients d'ordre élevé, ainsi notre algorithme aura tendance à proposer des polynômes ayant des coefficients d'ordre élevé de petite taille, et ainsi réduire artificiellement l'ordre du polynôme choisi.

Le terme de \emph{régularisation} est employé pour tout modification apportée à l'algorithme apprenant visant à réduire l'\emph{erreur de généralisation}, mais pas l'\emph{erreur d'apprentissage}.
	
\section{Paramétrisation et Validation d'un Algorithme}
La plupart des algorithmes d'apprentissage machine sont paramétrés afin de contrôler plus précisément leur apprentissage.
Ces paramètres s'appellent des \emph{hyper-paramètres}.

Par exemple dans l'exemple de la régression polynomiale, nous avons utilisé deux \emph{hyper-paramètres} :
\begin{itemize}
	\item $q$ : le degré du polynôme $P$ utilisé.
	\item $\lambda$ : le coefficient de décroissance appliquée à la fonction $f(\theta)$.
\end{itemize}
En effet, ces deux paramètres doivent être manuellement choisis par rapport à notre problème, en fonction de notre besoin de généralisation ($\lambda$) ou de performance sur l'apprentissage ($q$).

Afin de vérifier que notre algorithme soit correctement paramétré, il nous faut construire un troisième jeu de données, appelé ensemble de validation.
Voici les propriétés de ces jeux de données.
\begin{itemize}
	\item Le premier jeu de données est l'ensemble d'apprentissage, notre algorithme apprendra donc uniquement sur cet ensemble.
	\item Le second jeu de données est l'ensemble de test, il est indépendant du premier. Nous pourrons vérifier grâce à ce jeu de données si l'algorithme est apte à généraliser.
	\item Le troisième jeu de données est l'ensemble de validation. En règle générale, on soustrait au jeu d'apprentissage une petite fraction de ses données. Grâce à lui, nous pouvons vérifier l'hyper-paramétrisation de notre algorithme.
\end{itemize}
Ainsi la procédure d'expérimentation est la suivante :
\begin{enumerate}
	\item Choix d'un modèle.
	\item Choix des hyper-paramètres.
	\item Apprentissage sur l'ensemble d'apprentissage.
	\item Estimation de la capacité de généralisation du modèle sur l'ensemble de validation.
	\item Si la capacité à généraliser est trop faible, c'est à dire que l'\emph{erreur de validation} est trop élevée, on modifie les hyper-paramètres, puis retour à l'étape d'apprentissage, sinon on passe à l'étape suivante.
	\item Évaluation finale des performances du modèle sur l'ensemble de test.
	\item Si l'\emph{erreur de test} est trop élevée, alors il retourner à la première étape et choisir un nouveau modèle, sinon on valide le modèle.
\end{enumerate}
	
\section{Optimisation}
Dans cette section, nous aborderons les grands principes utilisés pour réaliser l'apprentissage à proprement parler.
Nous rappelons qu'en effet le but d'un algorithme d'apprentissage machine est s'améliorer à réaliser une tâche \emph{T} grâce à une expérience \emph{E}, cette amélioration étant mesurée par \emph{P}.

Nous voulons donc ici, minimiser l'\emph{erreur d'apprentissage} afin d'améliorer nos performances sur la tâche à réaliser.
\subsection{Méthodes exactes}
Les méthodes exactes sont très pratiques, car elles permettent de trouver la solution de façon immédiate.
Pour résoudre le problème $min_{\theta}J(x,y)$, il nous faut donc annuler le gradient de la fonction de perte, soit
\begin{center}
	$\nabla_{\theta} J(x,y) = 0$
\end{center}
Cela nécessite un certain travail en amont, dépendant entièrement du type d'algorithme utilisé.

De plus il n'existe \textbf{pas toujours de solution exacte unique}.
\subsubsection{Exemple}
Prenons le cas de la régression polynomiale, le problème est le suivant :
\begin{center}
	$min_{\theta,b} J(x,y) = \frac{1}{2} (P(x)-y)^T(P(x)-y)$
	
	$\leftrightarrow$ Trouver $\theta \in \mathbb{R}^q$ et $b \in \mathbb{R}$, tels que la fonction de perte $J(x,y)$ soit minimale.
\end{center}
Pour rappel, 
\begin{center}
	$P(z) = b + \sum_{j=1}^{q}{\theta_j z^j}$,
		un polynôme de degré $q$,
		et $P(x) = (P(x_i))_{i=1..n}$,
		le polynôme d'un vecteur $P(x)$ est le vecteur de polynômes $P(x_i)$.
		Donc $P(x) = 
	\begin{pmatrix}
		1      & x_1    & \cdots & x_1^q  \\
		\vdots & \cdots & \cdots & \vdots \\
		\vdots & \cdots & \cdots & \vdots \\
		1      & x_n    & \cdots & x_n^q  
	\end{pmatrix} 
	\begin{pmatrix}
		b        \\
		\theta_1 \\
		\vdots   \\
		\theta_n 
	\end{pmatrix}
	= X \theta
	$
\end{center}
On peut alors réécrire $J(x,y)$ de la façon suivante :
\begin{center}
	$J(x,y) = \frac{1}{2} (P(x)-y)^T(P(x)-y) = \frac{1}{2} (X\theta-y)^T(X\theta-y)$
		$\rightarrow J(x,y) =\frac{1}{2} (\theta^TX^TX\theta - 2\theta^TX^Ty + y^Ty)$
\end{center}
Il nous faut maintenant trouver le minimum de $J(x,y)$, ce qui revient à résoudre $\nabla_\theta J(x,y) = 0$
Or, grâce aux dérivées vectorielles ($\frac{\partial x^Ta}{\partial x} = a$, et $\frac{\partial x^TAx}{\partial x} = 2Ax$ )
\begin{center}
	$\nabla_\theta J(x,y) = \frac{1}{2} (2X^TX\theta-2X^Ty) = X^TX\theta-X^Ty$
\end{center}
Donc,
\begin{center}
	$X^TX\theta-X^Ty = 0$
		$\rightarrow X^TX\theta = X^Ty$
		$\rightarrow \theta = (X^TX)^{-1} X^Ty$
\end{center}
Néanmoins une méthode exacte présente des inconvénients.

Par exemple, pour calculer $\theta$, la complexité algorithmique est de l'ordre de $O(n^3)$, avec $n$ le nombre de données, à cause de l'inversion de matrice.
Cette complexité cubique pose donc des problèmes quand $n$ est très grand.
De plus cette méthode présente des problèmes de stabilité numérique, si le conditionnement de $X^TX$ est grand.
		
\subsection{Méthodes itératives}
Nous avons vu dans un premier temps, que les méthodes exactes permettaient parfois avec, un peu de calcul formel, d'avoir une solution optimale à notre problème, et ce immédiatement.

Une méthode itérative, comme son nom l'indique, converge vers le résultat après plusieurs itérations.
Elles peuvent remplacer les méthodes exactes, quand celles-ci sont soit inapplicables, coûteuses ou inconnues. De plus lorsqu'un problème est mal conditionné, elles limitent la propagation des erreurs.

Il existe un grand nombre de méthodes itératives, mais nous n'en aborderons qu'une seule catégorie, car utile pour la suite, les méthodes de descente du gradient.

Les méthodes de descente de gradient, sont très utilisées en apprentissage machine, de par leur facilité d'implémentation, ainsi que de leur convergence plutôt rapide.
\subsubsection{Algorithme de Descente de Gradient}
Voici à présent l'algorithme général du gradient, appliqué à une fonction $J(x,y,\theta)$.
\begin{algorithm}[H]
	\caption{Algorithme général de Descente de Gradient}
	\begin{algorithmic}
		\REQUIRE {
			L'ensemble des entrées $x=(x_i)_{i=1}^n$ et l'ensemble des sorties $y=(y_i)_{i=1}^n$
						$x_i$ et $y_i$ sont des vecteurs réels de dimensions quelconques,
						$\theta_0$, les paramètres initiaux du modèle,
						et $\epsilon > 0$, seuil de tolérance.
		}
		\REPEAT
		\STATE Calcul de $\nabla_\theta J(x,y,\theta_k)$.
		\STATE Calcul de $\alpha_k$.
		\COMMENT{$\alpha_k$ peut être soit une constante, soit calculé en fonction de gradients $\nabla_\theta J(x,y,\theta)$}
		\STATE $\theta_{k+1} = \theta_k - \alpha_k \nabla_\theta J(x,y,\theta_k)$.
		\UNTIL{$\nabla_\theta J(x,y,\theta_k) \leq \epsilon$}
		\RETURN $\theta_{k+1}$
	\end{algorithmic}
\end{algorithm}
Dans notre cas, nous souhaitons minimiser la fonction de perte de associée à notre modèle par rapport aux données d'apprentissage.

Soit $x$ et $y \in \mathbb{R}^n$, les entrées et les sorties.

On pose ici $J(x,y,\theta)$ l'erreur moyenne du modèle par rapport aux données d'apprentissage.
$$J(x,y,\theta) = \frac{1}{n} \sum_{i=1}^{n}{J(x_i,y_i,\theta)}$$
Donc,
$$\nabla_\theta J(x,y,\theta) = \frac{1}{n} \sum_{i=1}^{n}{\nabla_\theta J(x_i,y_i,\theta)}$$
\			
\subsubsection{Algorithme de Descente de Gradient Stochastique}
La réflexion derrière la descente de gradient stochastique est que le gradient de l'ensemble est la moyenne des gradients des couples $(x,y)$ .

D'après la Loi des Grands Nombres, $$\mathbb{E}(X) \approx \frac{1}{n} \sum_{i=1}^{n}{x_i}$$
Avec $X$ une distribution, dont les données $x_i$ sont issues.

Par ailleurs, si l'on échantillonne de façon uniforme $m$ individus parmi les $n$ données d'apprentissage, on aura :
$$\mathbb{E}(X) \approx \frac{1}{m} \sum_{i=1}^{m}{x_i}$$
Ainsi,
$$\frac{1}{n} \sum_{i=1}^{n}{x_i} \approx \frac{1}{m} \sum_{i=1}^{m}{x_i}$$
L'ensemble des $m$ variables extraites de $x$ s'appelle \emph{mini-lot} ou \emph{mini-batch}
\begin{algorithm}[H]
	\caption{Algorithme de Descente de Gradient Stochastique}
	\begin{algorithmic}
		\REQUIRE {
			L'ensemble des entrées $x=(x_i)_{i=1}^n$ et l'ensemble des sorties $y=(y_i)_{i=1}^n$
						$x_i$ et $y_i$ sont des vecteurs réels de dimensions quelconques,
						$m < n$,
						$\theta_0$, les paramètres initiaux du modèle, initialisés aléatoirement,
						$\alpha > 0$, le pas de descente
						et $\epsilon > 0$, seuil de tolérance.
		}
		\REPEAT
		\STATE $\hat{x},\hat{y} = sample(x,y,m)$
		\STATE Calcul de $\nabla_\theta J(\hat{x},\hat{y},\theta_k)$.
		\STATE Calcul de $\alpha_k$.
		\COMMENT{$\alpha_k$ peut être soit une constante, soit calculé en fonction de gradients $\nabla_\theta J(x,y,\theta)$}
		\STATE $\theta_{k+1} = \theta_k - \alpha_k \nabla_\theta J(\hat{x},\hat{y},\theta_k)$.
		\UNTIL{$\nabla_\theta J(\hat{x},\hat{y},\theta_k) \leq \epsilon$}
		\RETURN $\theta_{k+1}$
	\end{algorithmic}
\end{algorithm}
L'intérêt de cette méthode repose principalement sur le fait que le gradient moyen du \emph{mini-batch} est une très bonne approximation du gradient moyen calculé sur l'ensemble des données, et nous permet ainsi d'ajuster les paramètres du modèle plus souvent, permettant généralement une convergence plus rapide.
\chapter{L'Apprentissage Profond}
L'apprentissage profond se différencie de l'apprentissage machine classique particulièrement sur deux points :
\begin{itemize}
	\item Il existe des dizaines, voire des centaines de classes d'algorithmes d'apprentissage pour résoudre des tâches variées, et par extension des problèmes très variés, cependant dans le cas de l'apprentissage profond, même si il existe des différences, le principe utilisé reste globalement le même.
	
	De ce fait leur capacité de généralisation est beaucoup plus forte, permettant ainsi de résoudre plus efficacement certains problèmes jugés difficiles à résoudre par des algorithmes d'apprentissage classiques.
	\item Si le principe de l'algorithme reste globalement le même, la structure du modèle est quant à elle très variable, et il est même très important de la faire varier d'un problème à un autre, car elle est intrinsèquement dépendante du problème et de ses données.
	      \end{itemize}
Nous présenterons, dans un premier temps, le fonctionnement des réseaux totalement connectés, car les plus simples. Ainsi que différentes méthodes employées pour améliorer les performances des modèles.

Dans un second temps, nous verrons une variante, les réseaux convolutifs.

Enfin, nous aborderons succinctement différentes applications existantes appliquées à la vision.
\section{Réseaux de Neurones Profonds}
Les réseaux de neurones profonds, aussi appelés \emph{Deep Feedforward Networks}, définissent un \emph{mapping} entre un vecteur d'entrée $x$ et sa sortie associée $y$ de sorte que $y = f(x,\theta)$ et apprennent les paramètres $\theta$ de sorte à produire la meilleure estimation.

Ils sont dits "\emph{feedforward}", ou en français à "propagation unique", car l'information se déplace à travers la fonction, depuis l'entrée $x$, puis par des étapes intermédiaires, pour arriver à la sortie $y$, sans aucun retour en arrière.

Les réseaux de neurones permettant un \emph{feedback} ou \emph{retour d'expérience} sont appelés font partie de la classe des réseaux récurrents.
Les réseaux de types "\emph{feedforward}" sont de loin les réseaux de neurones les plus utilisés.

On utilise le mot \emph{réseau} dans l’appellation réseaux de neurones, car ils sont composés d'une multitude de fonctions \emph{simples}, organisées en réseau.

On pourrait par exemple imaginer notre fonction $f(x,\theta)$ comme étant la composée de plusieurs fonctions, telle que $f(x,\theta) = u_{\theta_1} \circ v_{\theta_2} \circ w_{\theta_3}(x)$ avec $\theta = (\theta_1,\theta_2, \theta_3))$, un ensemble de paramètres.
C'est par ailleurs cette architecture distribuée, qui grâce à une puissance de calcul grandissante, par le biais du calcul GPU, permet de résoudre des problèmes de plus en plus complexes.
\subsection{Définition d'un Neurone Artificiel}
Ce que l'on appelle \emph{neurone} est effectivement inspiré du fonctionnement d'un neurone biologique, bien que différent à bien des égards.

Un neurone artificiel est une application $f : \mathbb{R}^p \rightarrow \mathbb{R}$, paramétrée par $\theta = (b,w) = (b, w_1, ..., w_p)$.

Le réel $b$ s'appelle le biais, et le vecteur $w = (w_1, ..., w_p)$ s'appelle vecteur de poids.
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{Images/Neuron.png}
		\caption{Schéma de représentation d'un Neurone}
	\end{center}
\end{figure}
Cette application est la composée de deux fonctions distinctes :
\begin{itemize}
	\item Une fonction d’\emph{agrégation} $h : \mathbb{R}^p \rightarrow \mathbb{R}$, combinant l'entrée $x$ avec les poids $w$ et le biais $b$.
	      	      Dans le cas d'un neurone \emph{totalement connecté} (le plus basique), elle à l'allure suivante :
	      $$h_\theta(x) = h_{b,w}(x) = w^Tx + b = \sum_{i=1}^{p}{w_i x_i} + b$$
	\item Une fonction d'\emph{activation} $g : \mathbb{R} \rightarrow \mathbb{R}$, \emph{non-linéaire}.
	      	      Des exemples :
	      \begin{itemize}
	      	\item \emph{ReLU}, pour \emph{Rectified Linear Unit} : $g(z) = max(0,z)$
	      	\item \emph{Sigmoïde} : $g(z) = \frac{1}{1+e^{-z}}$
	      	\item \emph{Tangente hyperbolique} : $g(z) = \tanh(z)$
	      \end{itemize}
\end{itemize}
Il est important de garder à l'esprit que ces deux opérations successives sont distinctes, mais qu'elles sont regroupées ici pour montrer les similarités avec les neurones biologiques.

Ainsi notre neurone peut être résumé par une fonction $f$ telle que :
$$f_\theta(x) = g \circ h_\theta(x) = g(w^Tx + b)$$
La sortie de notre neurone, par la suite notée $a$, est l'\emph{image} de la fonction $f$ par l'entrée $x$:
$$a = f_\theta(x) = g \circ h_\theta(x) = g(w^Tx + b)$$
\subsection{Définition d'un Réseau de Neurones}
Avec la définition précédente d'un neurone, nous pouvons alors schématiser un réseau de neurones de la façon suivante :
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{Images/Neural_Network.png}
		\caption{Schéma pédagogique de représentation d'un Réseau de Neurones}
	\end{center}
\end{figure}
Ici, chaque cercle représente un neurone, équivalent à ceux définis précédemment.
Toutefois, sur la première couche, appelée \emph{couche d'entrée}, les neurones produisent en sortie, le \emph{vecteur d'entrée} $x$, ici $x \in \mathbb{R}^6$.
On peut noter aussi que la dernière couche, appelée \emph{couche de sortie}, les neurones produisent le vecteur $y$, ici $y\in \mathbb{R}^1 = \mathbb{R}$.

Attention, la description faite ici, n'est qu'à but pédagogique. Dans le cas courant, on ne considère pas un réseau en individualisant chaque neurone, mais plutôt couche par couche :
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.4]{Images/Toy_Example.png}
		\caption{Schéma courant de représentation d'un Réseau de Neurones}
	\end{center}
\end{figure}

Ainsi, pour décrire un réseau de neurones, nous considérons deux caractéristiques :
\subsubsection{Profondeur}
\begin{center}
	Le nombre de couches d'un réseau de neurones est appelé \emph{profondeur}, plus ce nombre est élevé, plus la capacité théorique de généralisation est forte.
\end{center}
Même si il n'existe pas de seuil officiel différenciant les réseaux de neurones, \emph{peu profonds}, dits \emph{superficiels}, des réseaux de neurones \emph{profonds}, on parle d'\emph{apprentissage profond} lorsque le nombre de couches cachées est $\geq 2$.
On parlera d'apprentissage très profond, lorsque le nombre de couches cachées est $\geq 10$.
\subsubsection{Largeur}
\begin{center}
	Le nombre de neurones composant une couche est appelé \emph{largeur}.
	\end{center}
Nous pouvons par ailleurs noter que le nombre de paramètres $\theta = (b,w) = (b,w_1,..,w_p)$ d'un neurone n'est pas arbitraire.
En effet, la \emph{largeur} de chaque couche est égale au nombre de paramètres $\theta$ des neurones de la couche suivante.
Par ailleurs, la \emph{largeur} de la première couche est égale à la taille du vecteur d'entrée $x$.
\subsubsection{Expression Gnérale}
On explicitera généralement l'architecture d'un réseau de neurones par un vecteur $s \in \mathbb{N}^L$.
Ainsi $S = (S_1, S_2, ..., S_L)$ représente un réseau de neurones de \emph{profondeur} $L$ ($L$ couches), chacune possédant $s_i$ neurones ayant $s_{i-1}$ poids et un biais par neurone.
\subsection{Notations}
Afin de ne pas se perdre dans les calculs qui vont survenir, nous allons définir une notation nous permettant de repérer sans ambiguïté la position des différents éléments d'un réseau de neurones.
\begin{center}
	\emph{\textbf{Important !}}
\end{center}
Chaque élément du réseau de neurones peut être défini par sa position dans le réseau.\\
Pour les \emph{poids} :
\begin{itemize}
	\item Un poids \emph{réel} noté $\elem{W}{k}{j}{i}$ sera le $i$-ème poids du $j$-ème neurone, situé dans la $k$-ème couche.
	\item Par conséquent $\elem{W}{k}{j}{}$ sera quant à lui le vecteur de poids du $j$-ème neurone, situé dans la $k$-ème couche.
	\item Enfin $\elem{W}{k}{}{}$ sera la matrice des poids de la $k$-ème couche.
	      \end{itemize}
Pour les \emph{biais} :
\begin{itemize}
	\item Un biais \emph{réel} noté $\elem{b}{k}{j}{}$ sera le biais du $j$-ème neurone, situé dans la $k$-ème couche.
	\item Par conséquent $\elem{b}{k}{}{}$ sera quant à lui le vecteur de biais de la $k$-ème couche.
	      \end{itemize}
Nous noterons par ailleurs avec la lettre $a$, qui sera indicée par la suite, la sortie d'une couche du réseau.
Pour les \emph{sorties} :
\begin{itemize}
	\item Une sortie d'un neurone noté $\elem{a}{k}{j}{}$ sera la sortie du $j$-ème neurone, situé dans la $k$-ème couche.
	\item Par conséquent $\elem{a}{k}{}{}$ représente le vecteur de sortie de la $k$-ème couche, mais aussi le vecteur d'entrée de la $(k+1)$-ème couche.
	\item Le vecteur d'entrée $x$, sera noté $\elem{a}{0}{}{}$.
	\item Le vecteur de sortie $y$, sera noté $\elem{a}{L}{}{}$ dans réseau de $L$ couches.
	      \end{itemize}
Enfin, les résultats de la fonction de combinaison sont de même dimensions que les sorties de couche.
Pour les \emph{combinaisons} :
\begin{itemize}
	\item Une combinaison noté $\elem{z}{k}{j}{}$ sera la combinaison du $j$-ème neurone, situé dans la $k$-ème couche.
	\item Par conséquent $\elem{z}{k}{}{}$ représente le vecteur des combinaisons de la $k$-ème couche.
	      \end{itemize}
			
\subsection{Propagation}
On parle de \emph{propagation à sens unique} dans un réseau de neurones, car l'entrée $x$, affectée à la première couche, est transmise à la suivante, qui produira alors un vecteur de sortie.
Ce vecteur de sortie sera alors considéré comme un vecteur d'entrée pour la couche suivante, qui produira à l'aide de cette entrée un autre vecteur de sortie.
Et ainsi de suite, jusqu'à la dernière couche, qui produira finalement la sortie du réseau : $y$.
		
Nous voilà à présent correctement armés pour voir la propagation dans un réseau de neurones.
Voici l'algorithme de propagation au sein d'un réseau de neurones : 
\begin{algorithm}[H]
	\caption{Algorithme de Propagation}
	\begin{algorithmic}
		\REQUIRE {
			Un réseau de neurones de $L$ couches, défini par $S = (S_1, S_2, ..., S_L)$.
						Un vecteur d'entrée $x \in \mathbb{R}^n = \mathbb{R}^{S_1}$,
					}
		\STATE $\elem{a}{0}{}{} = x$
		\FOR{$k=1$ \TO $L$}
		\FOR{$j=1$ \TO $S_k$}
		\STATE $\elem{z}{k}{j}{} = (\elem{W}{k}{j}{})^T(\elem{a}{k-1}{}{}) + \elem{b}{k}{j}{} = \sum_{i=1}^{S_{k-1}}{\elem{W}{k}{j}{i} \times \elem{a}{k-1}{i}{}} + \elem{b}{k}{j}{}$
		\STATE $\elem{a}{k}{j}{} = g(\elem{z}{k}{j}{})$
				\COMMENT{$\elem{a}{k}{j}{}$ est, comme vu précédemment, la sortie du $j$-ème neurone de la $k$-ème couche,
						$\elem{z}{k}{j}{}$ est le résultat de la fonction d'agrégation, résultat très utile par la suite.
			$\elem{W}{k}{j}{}$ est le vecteur de poids du $j$-ème neurone de la $k$-ème couche,
						et $\elem{b}{k}{j}{}$ est le biais du $j$-ème neurone de la $k$-ème couche.}
		\ENDFOR
		\ENDFOR
		\RETURN $\elem{a}{L}{}{}$
		\COMMENT{$\elem{a}{L}{}{}$ est la sortie du réseau de neurones, que nous comparerons ensuite à $y$.}
	\end{algorithmic}
\end{algorithm}
			
Néanmoins, il existe aujourd'hui un grand nombre de bibliothèques permettant de faire du calcul matriciel de façon optimisée, appelées Basic Linear Algebra Subprograms (BLAS), telles que ATLAS, GotoBLAS, OpenBLAS.

Pour rappel, $\elem{W}{k}{}{}$ représente la matrice des poids de la $k$-ème couche, et $\elem{a}{k-1}{}{}$ le vecteur de sortie de la $(k-1)$-ème couche.
Par conséquent, on peut calculer le vecteur de sortie de la $k$-ème couche de la façon suivante :
$$\elem{z}{k}{}{} = (\elem{W}{k}{}{})^T(\elem{a}{k-1}{}{}) + \elem{b}{k}{}{}$$
$$\elem{a}{k}{}{} = g(\elem{z}{k}{}{})$$
Ainsi,
\begin{algorithm}[H]
	\caption{Algorithme matriciel de Propagation}
	\begin{algorithmic}
		\REQUIRE {
			Un réseau de neurones de $L$ couches, défini par $S = (S_1, S_2, ..., S_L)$.
						Un vecteur d'entrée $x \in \mathbb{R}^n = \mathbb{R}^{S_1}$,
					}
		\STATE $\elem{a}{0}{}{} = x$
		\FOR{$k=1$ \TO $L$}
		\STATE $\elem{z}{k}{}{} = (\elem{W}{k}{}{})^T(\elem{a}{k-1}{}{}) + \elem{b}{k}{}{}$
		\STATE $\elem{a}{k}{}{} = g(\elem{z}{k}{}{})$
		\ENDFOR
		\RETURN $\elem{a}{L}{}{}$
	\end{algorithmic}
\end{algorithm}
			
\subsection{Rétro-propagation du Gradient}
		
L'algorithme de rétro-propagation est souvent à tort considéré comme étant la méthode d'optimisation utilisée pour minimiser la fonction de perte.
C'est en effet le rôle d'une méthode de descente de gradient.

Voici pour rappel une méthode générale de descente de gradient, vue dans la première partie :
\begin{algorithm}[H]
	\caption{Algorithme général de Descente de Gradient}
	\begin{algorithmic}
		\REQUIRE {
			$x$ et $y \in \mathbb{R}^n$,
						$\theta_0$, les paramètres initiaux du modèle,
						et $\epsilon > 0$, seuil de tolérance.
		}
		\REPEAT
		\STATE Calcul de $\nabla_\theta J(x,y,\theta_k)$.
		\STATE Calcul de $\alpha_k$.
		\COMMENT{$\alpha_k$ peut être soit une constante, soit calculé en fonction de gradients $\nabla_\theta J(x,y,\theta)$}
		\STATE $\theta_{k+1} = \theta_k - \alpha_k \nabla_\theta J(x,y,\theta_k)$.
		\UNTIL{$\nabla_\theta J(x,y,\theta_k) \leq \epsilon$}
		\RETURN $\theta_{k+1}$
	\end{algorithmic}
\end{algorithm}
L'algorithme de rétro-propagation du gradient a pour simple but de calculer, de façon élégante, le gradient $\nabla_\theta J(x,y,\theta)$, avec $\theta$ représentant ici tous les paramètres du modèle, c'est à dire l'ensemble des poids $\elem{W}{k}{j}{i}$ et des biais $\elem{b}{k}{j}{}$.
		
\subsubsection{Calcul Formel du Gradient}
			
Il nous faut donc calculer $\frac{\partial J(x,y,\theta)}{\partial \elem{W}{k}{j}{i}}$, traduisant l'influence du poids $\elem{W}{k}{j}{i}$ sur la fonction de perte $J(x,y,\theta)$.

Et $\frac{\partial J(x,y,\theta)}{\partial \elem{b}{k}{j}{}}$, qui traduit l'influence du biais $\elem{b}{k}{j}{}$ sur la fonction de perte $J(x,y,\theta)$.
\begin{center}
	\textbf{Toute dérivée partielle $\frac{\partial u}{\partial v}$ représente l'influence qu'a l'élément $v$ sur l'élément $u$.}
\end{center}
Nous utiliserons le Théorème de dérivation des fonctions composées, aussi appelée \emph{chain rule}.
Nous rappelons que $J(x,y,\theta)$ est une fonction de perte de la forme :
$$J(x,y,\theta) = C(\elem{a}{L}{}{}(x),y)$$
				
\emph{Afin de mieux comprendre la preuve, on peut s'aider d'un \textbf{dessin \smiley{}}.}
				
\paragraph{Calcul sur la Couche de Sortie}
				
Commençons par calculer le gradient de l'erreur pour les poids de la couche de sortie, $\frac{\partial C}{\partial \elem{W}{L}{j}{i}}$.
Ainsi que le gradient pour les biais de la couche de sortie, $\frac{\partial C}{\partial \elem{b}{L}{j}{}}$.

Sur la dernière couche, nous avons
$$\elem{z}{L}{j}{} = (\elem{W}{L}{j}{})^T(\elem{a}{L-1}{}{}) + \elem{b}{L}{j}{}$$
Et
$$\elem{a}{L}{j}{} = g(\elem{z}{L}{j}{})$$
Utilisons à présent la règle de chaînage sur $\frac{\partial C}{\partial \elem{W}{L}{j}{i}}$, car $\elem{a}{L}{j}{}$ est une fonction composée.

Nous obtenons donc,
$$\left\{
\begin{array}{l}
	\frac{\partial C}{\partial \elem{W}{L}{j}{i}} = \frac{\partial C}{\partial \elem{a}{L}{j}{}} \times \frac{\partial \elem{a}{L}{j}{}}{\partial \elem{z}{L}{j}{}} \times \frac{\partial \elem{z}{L}{j}{}}{\partial \elem{W}{L}{j}{i}} 
	\\                                                                                                                                                                                                                                
	                                                                                                                                                                                                                                    
	\frac{\partial C}{\partial \elem{b}{L}{j}{}} = \frac{\partial C}{\partial \elem{a}{L}{j}{}} \times \frac{\partial \elem{a}{L}{j}{}}{\partial \elem{z}{L}{j}{}} \times \frac{\partial \elem{z}{L}{j}{}}{\partial \elem{b}{L}{j}{}}   
	\\                                                                                                                                                                                                                                
\end{array}
\right.$$
				
On s'aperçoit ici que le terme $\frac{\partial C}{\partial \elem{a}{L}{j}{}}$, exprime la variation de $C(\elem{a}{L}{}{}(x),y)$ en fonction de la sortie du neurone $\elem{a}{L}{j}{}$.
				
On voit aussi que le terme $\frac{\partial \elem{a}{L}{j}{}}{\partial \elem{z}{L}{j}{}}$, traduit la variation de la sortie du neurone $\elem{a}{L}{j}{}$ en fonction de l'agrégat $\elem{z}{L}{j}{}$, dépend de la \emph{fonction d'activation} choisie.
				
Nous reviendrons sur les expressions de $\frac{\partial C}{\partial \elem{a}{L}{j}{}}$ et $\frac{\partial \elem{a}{L}{j}{}}{\partial \elem{z}{L}{j}{}}$, car elles nous permettront de choisir de façon éclairée la fonction d'activation et la fonction coût,car des simplifications peuvent s'opérer.
				
Enfin $\frac{\partial \elem{z}{L}{j}{}}{\partial \elem{W}{L}{j}{i}}=\elem{a}{L-1}{i}{}$ et $\frac{\partial \elem{z}{L}{j}{}}{\partial \elem{b}{L}{j}{i}} = 1$, ce qui est évident à vérifier, car 
$$\elem{z}{L}{j}{} = \sum_{i=1}^{S_{L-1}}{\elem{W}{L}{j}{i} \times \elem{a}{L-1}{i}{}} + \elem{b}{L}{j}{}$$
				
Ces deux expressions traduisent l'influence des poids $\elem{W}{L}{j}{i}$ et du biais $\elem{b}{L}{j}{}$ sur l'agrégat, ou résultat de la fonction d'agrégation, $\elem{z}{L}{j}{}$
				
Pour la suite, nous allons poser $\elem{\delta}{L}{j}{} = \frac{\partial C}{\partial \elem{a}{L}{j}{}} \times \frac{\partial \elem{a}{L}{j}{}}{\partial \elem{z}{L}{j}{}}$, cela interviendra quand nous montrerons le caractère récursif de la rétropropagation.
				
Finalement, nous obtenons,
$$\left\{
\begin{array}{l}
	\frac{\partial C}{\partial \elem{W}{L}{j}{i}} = \elem{\delta}{L}{j}{} \times \frac{\partial \elem{z}{L}{j}{}}{\partial \elem{W}{L}{j}{i}} = \elem{\delta}{L}{j}{} \times \elem{a}{L-1}{i}{} 
	\par                                                                                                                                                                                        
	                                                                                                                                                                                            
	\frac{\partial C}{\partial \elem{b}{L}{j}{}} = \elem{\delta}{L}{j}{} \times \frac{\partial \elem{z}{L}{j}{}}{\partial \elem{b}{L}{j}{}} = \elem{\delta}{L}{j}{}                             
	\par                                                                                                                                                                                        
\end{array}
\right.$$
Avec,
$$\elem{\delta}{L}{j}{} = \frac{\partial C}{\partial \elem{a}{L}{j}{}} \times \frac{\partial \elem{a}{L}{j}{}}{\partial \elem{z}{L}{j}{}}$$
				
\paragraph{Calcul sur l'avant dernière couche}
				
Après avoir explicité les calculs des $\frac{\partial C}{\partial \elem{W}{L}{j}{i}}$ et $\frac{\partial C}{\partial \elem{b}{L}{j}{}}$, passons à présent au calcul sur l'avant dernière couche, soit aux $\frac{\partial C}{\partial \elem{W}{L-1}{j}{i}}$ et $\frac{\partial C}{\partial \elem{b}{L-1}{j}{}}$.

Grâce à la \emph{chain rule}, nous obtenons de la même façon que précédemment,
				
$$\left\{
\begin{array}{l}
	\frac{\partial C}{\partial \elem{W}{L-1}{j}{i}} = \frac{\partial C}{\partial \elem{a}{L-1}{j}{}} \times \frac{\partial \elem{a}{L-1}{j}{}}{\partial \elem{z}{L-1}{j}{}} \times \frac{\partial \elem{z}{L-1}{j}{}}{\partial \elem{W}{L-1}{j}{i}} 
	\\                                                                                                                                                                                                                                            
	\frac{\partial C}{\partial \elem{b}{L-1}{j}{}} = \frac{\partial C}{\partial \elem{a}{L-1}{j}{}} \times \frac{\partial \elem{a}{L-1}{j}{}}{\partial \elem{z}{L-1}{j}{}} \times \frac{\partial \elem{z}{L-1}{j}{}}{\partial \elem{b}{L-1}{j}{}}   
	\\                                                                                                                                                                                                                                            
\end{array}
\right.$$
				
On peut remarquer que l'utilisation de la \emph{Chain rule} permet d'exprimer facilement $\frac{\partial \elem{a}{L-1}{j}{}}{\partial \elem{z}{L-1}{j}{}}$, $\frac{\partial \elem{z}{L-1}{j}{}}{\partial \elem{W}{L-1}{j}{i}}$ et $\frac{\partial \elem{z}{L-1}{j}{}}{\partial \elem{b}{L-1}{j}{}}$.
En effet si la fonction d'activation reste la même pour tout le réseau de neurones, alors le terme $\frac{\partial \elem{a}{L-1}{j}{}}{\partial \elem{z}{L-1}{j}{}}$ est la même que $\frac{\partial \elem{a}{L}{j}{}}{\partial \elem{z}{L}{j}{}}$ calculée plus haut.

De même que précédemment $\frac{\partial \elem{z}{L-1}{j}{}}{\partial \elem{W}{L-1}{j}{i}}=\elem{a}{L-2}{i}{}$ et $\frac{\partial \elem{z}{L-1}{j}{}}{\partial \elem{b}{L-1}{j}{i}} = 1$, car
$$\elem{z}{L-1}{j}{} = \sum_{i=1}^{S_{L-2}}{\elem{W}{L-1}{j}{i} \times \elem{a}{L-2}{i}{}} + \elem{b}{L-1}{j}{}$$
				
La difficulté réside ici, dans le calcul de $\frac{\partial C}{\partial \elem{a}{L-1}{j}{}}$.
Si on trace un réseau de neurones quelconque.

Prenons le $j$-ème neurone de la couche $L-1$, on peut voir qu'il transmet le résultat de son activation $\elem{a}{L-1}{j}{}$ à tous les neurones de la couche $L$.

Cette diffusion d'informations a aussi un impact sur le coût, puisque si erreur il y a alors, les neurones de la couche $L$ en feront les "frais".

Un neurone $\elem{a}{L-1}{i}{}$ propage l'erreur à un neurone $\elem{a}{L}{j}{}$ proportionnellement au poids $\elem{W}{L}{j}{i}$.
				
Nous devons donc décomposer $\frac{\partial C}{\partial \elem{a}{L-1}{j}{}}$, grâce à la \emph{chain rule}.
				
Le résultat est le suivant :	
$$\frac{\partial C}{\partial \elem{a}{L-1}{j}{}} = \sum_{l=1}^{L-1}{\frac{\partial C}{\partial \elem{a}{L}{l}{}} \times \frac{\partial \elem{a}{L}{l}{}}{\partial \elem{z}{L}{l}{}} \times \frac{\partial \elem{z}{L}{l}{}}{\partial \elem{a}{L-1}{l}{}}}$$
En effet, le neurone $\elem{a}{L-1}{i}{}$ transfère son erreur à tous les neurones $\elem{a}{L}{j}{}$ de la couche suivante par le biais des poids, car $\frac{\partial \elem{z}{L}{l}{}}{\partial \elem{a}{L-1}{j}{}} = \elem{W}{L-1}{l}{j}$.

On remarque par ailleurs que 
$$\frac{\partial C}{\partial \elem{a}{L-1}{j}{}} = \sum_{l=1}^{L-1}{\elem{\delta}{L}{l}{} \times \frac{\partial \elem{z}{L}{l}{}}{\partial \elem{a}{L-1}{j}{}}}$$
Car $$\elem{\delta}{L}{j}{} = \frac{\partial C}{\partial \elem{a}{L}{j}{}} \times \frac{\partial \elem{a}{L}{j}{}}{\partial \elem{z}{L}{j}{}}$$
Donc,
$$\elem{\delta}{L-1}{j}{} = \frac{\partial C}{\partial \elem{a}{L-1}{j}{}}  \times \frac{\partial \elem{a}{L-1}{j}{}}{\partial \elem{z}{L-1}{j}{}} = \sum_{l=1}^{L-1}{\elem{\delta}{L}{l}{} \times \frac{\partial \elem{z}{L}{l}{}}{\partial \elem{a}{L-1}{j}{}}} \times \frac{\partial \elem{a}{L-1}{j}{}}{\partial \elem{z}{L-1}{j}{}}$$
				
\paragraph{Récapitulatif}
Récapitulons, afin de voir se dessiner un schéma de récurrence.
Sur la couche $L$,
$$\left\{
\begin{array}{l}
	\frac{\partial C}{\partial \elem{W}{L}{j}{i}} = \elem{\delta}{L}{j}{} \times \frac{\partial \elem{z}{L}{j}{}}{\partial \elem{W}{L}{j}{i}} = \elem{\delta}{L}{j}{} \times \elem{a}{L-1}{i}{} 
	\\                                                                                                                                                                                        
	                                                                                                                                                                                            
	\frac{\partial C}{\partial \elem{b}{L}{j}{}} = \elem{\delta}{L}{j}{} \times \frac{\partial \elem{z}{L}{j}{}}{\partial \elem{b}{L}{j}{}} = \elem{\delta}{L}{j}{}                             
	\\                                                                                                                                                                                        
\end{array}
\right.$$
Avec,
$$\elem{\delta}{L}{j}{} = \frac{\partial C}{\partial \elem{a}{L}{j}{}} \times \frac{\partial \elem{a}{L}{j}{}}{\partial \elem{z}{L-1}{j}{}}$$
Sur la couche $L-1$,
$$\left\{
\begin{array}{l}
	\frac{\partial C}{\partial \elem{W}{L-1}{j}{i}} = \elem{\delta}{L-1}{j}{} \times \frac{\partial \elem{z}{L-1}{j}{}}{\partial \elem{W}{L-1}{j}{i}} = \elem{\delta}{L-1}{j}{} \times \elem{a}{L-2}{i}{} 
	\\                                                                                                                                                                                                  
	\frac{\partial C}{\partial \elem{b}{L-1}{j}{}} = \elem{\delta}{L-1}{j}{} \times \frac{\partial \elem{z}{L-1}{j}{}}{\partial \elem{b}{L-1}{j}{}} = \elem{\delta}{L-1}{j}{}                             
	\\                                                                                                                                                                                                  
\end{array}
\right.$$
Avec,
$$\elem{\delta}{L-1}{j}{} = \sum_{l=1}^{L-1}{\elem{\delta}{L}{l}{} \times \frac{\partial \elem{z}{L}{l}{}}{\partial \elem{a}{L-1}{j}{}}} \times \frac{\partial \elem{a}{L-1}{j}{}}{\partial \elem{z}{L-1}{j}{}}$$
\paragraph{Calcul généralisé}
Essayons à présent d'exprimer une forme récurrente applicable à chaque couche.
On a $\forall k = 1..L$,
$$\left\{
\begin{array}{l}
	\frac{\partial C}{\partial \elem{W}{k}{j}{i}} = \elem{\delta}{k}{j}{} \times \frac{\partial \elem{z}{k}{j}{}}{\partial \elem{W}{k}{j}{i}} = \elem{\delta}{k}{j}{} \times \elem{a}{k-1}{i}{} 
	\\                                                                                                                                                                                        
	\frac{\partial C}{\partial \elem{b}{k}{j}{}} = \elem{\delta}{k}{j}{} \times \frac{\partial \elem{z}{k}{j}{}}{\partial \elem{b}{k}{j}{}} = \elem{\delta}{k}{j}{}                             
	\\                                                                                                                                                                                        
\end{array}
\right.$$
Avec $$\elem{\delta}{k}{j}{} = \left\{
\begin{array}{l}
	\frac{\partial C}{\partial \elem{a}{L-1}{j}{}}, \  si \ k=L                                                                                                                                                  
	\\                                                                                                                                                                                                         
	\sum_{l=1}^{k-1}{\elem{\delta}{k+1}{l}{} \times \frac{\partial \elem{z}{k+1}{l}{}}{\partial \elem{a}{k}{j}{}} \times \frac{\partial \elem{a}{k}{j}{}}{\partial \elem{z}{k}{j}{}}}, \ si \ k \in \{1 .. L-1\}
	\\
\end{array}
\right.$$
				
Ce qui nous permet d'exprimer l'algorithme de rétro-propagation de la façon suivante :
\begin{algorithm}[H]
	\caption{Algorithme de Rétro-propagation}
	\begin{algorithmic}
		\REQUIRE {
			Un réseau de neurones de $L$ couches, défini par $S = (S_1, S_2, ..., S_L)$.
						Un vecteur d'entrée $x \in \mathbb{R}^n = \mathbb{R}^{S_1}$,
						Un vecteur de sortie $y \in \mathbb{R}^m = \mathbb{R}^{S_L}$,
					}
		\STATE
		\COMMENT{Calcul du gradient sur la couche de sortie.}
		\FOR{$j = 1$ \TO $L-1$}
		\STATE $\elem{\delta}{L}{j}{} = \frac{\partial C}{\partial \elem{a}{L-1}{j}{}}$
		\STATE $\frac{\partial C}{\partial \elem{b}{L}{j}{}} = \elem{\delta}{L}{j}{}$
		\FOR{$i =1$ \TO $L$}
		\STATE $\frac{\partial C}{\partial \elem{W}{L}{j}{i}} = \elem{\delta}{L}{j}{} \times \elem{a}{L-1}{i}{}$
		\ENDFOR
		\ENDFOR
						    
		\FOR{$k=L-1$ \TO $1$}
		\STATE
		\COMMENT{Calcul du gradient sur la $k$-ème couche.}
		\FOR{$j = 1$ \TO $k-1$}
		\STATE $\elem{\delta}{k}{j}{} = \sum_{l=1}^{k-1}{\elem{\delta}{k+1}{l}{} \times \frac{\partial \elem{z}{k+1}{l}{}}{\partial \elem{a}{k}{j}{}} \times \frac{\partial \elem{a}{k}{j}{}}{\partial \elem{z}{k}{j}{}}}$
		\STATE $\frac{\partial C}{\partial \elem{b}{k}{j}{}} = \elem{\delta}{k}{j}{}$
		\FOR{$i =1$ \TO $k$}
		\STATE $\frac{\partial C}{\partial \elem{W}{k}{j}{i}} = \elem{\delta}{k}{j}{}  \times \elem{a}{k-1}{i}{}$
		\ENDFOR
		\ENDFOR
		\ENDFOR
						    
	\end{algorithmic}
\end{algorithm}
Cet algorithme nous permet donc de calculer de façon très efficace tous les $\frac{\partial C}{\partial \elem{W}{k}{j}{i}}$ et $\frac{\partial C}{\partial \elem{b}{k}{j}{}}$.
Il existe une version privilégiant le calcul matriciel, permettant un calcul plus rapide, grâce à des librairies de BLAS.

Nous ne redémontrerons pas l'algorithme, mais nous en donneront toutefois la formulation.
\begin{algorithm}[H]
	\caption{Algorithme de Rétro-propagation Matriciel}
	\begin{algorithmic}
		\REQUIRE {
			Un réseau de neurones de $L$ couches, défini par $S = (S_1, S_2, ..., S_L)$.
						Un vecteur d'entrée $x \in \mathbb{R}^n = \mathbb{R}^{S_1}$,
						Un vecteur de sortie $y \in \mathbb{R}^m = \mathbb{R}^{S_L}$,
					}
		\STATE
		\COMMENT{Calcul du gradient sur la couche de sortie.}
		\STATE $\elem{\delta}{L}{}{} = \nabla_{\elem{a}{L-1}{}{}} C$
		\STATE $\nabla_{\elem{b}{L}{}{}} C = \elem{\delta}{L}{}{}$
		\STATE $\nabla_{\elem{W}{L}{}{}} C = \elem{\delta}{L}{}{} \times{\elem{a}{L-1}{}{}}^T $
					    
		\FOR{$k=L-1$ \TO $1$}
		\STATE
		\COMMENT{Calcul du gradient sur la $k$-ème couche.}
		\STATE $\elem{\delta}{k}{}{} = ((\nabla_{\elem{a}{k}{}{}}\elem{z}{k+1}{}{})^T \times \elem{\delta}{k+1}{}{}) \odot \nabla_{\elem{z}{k}{}{}}{\elem{a}{k}{}{}}$
		\STATE $\nabla_{\elem{b}{k}{}{}} C = \elem{\delta}{k}{}{}$
		\STATE $\nabla_{\elem{W}{k}{}{}} C = \elem{\delta}{k}{}{} \times{\elem{a}{k-1}{}{}}^T $
		\ENDFOR
	\end{algorithmic}
\end{algorithm}
Nous implémenterons alors cette méthode, car plus rapide en machine.
Nous disposons à présent des éléments suivants :
\begin{itemize}
	\item Une méthode de descente de gradient.
	\item L'algorithme de rétro-propagation, permettant le calcul du gradient de la fonction de perte de manière efficace.
\end{itemize}
Ainsi, nous disposons alors des éléments permettant de créer un réseau de neurones, ainsi que d'effectuer son apprentissage.

Nous allons maintenant quitter cette partie plutôt calculatoire, pour s'intéresser aux différents moyens existants pour améliorer les capacités de généralisation de nos futurs réseaux de neurones.
\subsection{Théorème d'Approximation Universelle}
Les réseaux de neurones permettent de représenter universellement n'importe quelle fonction, dans le sens où il existe un réseau de neurones, ayant une architecture donnée, des poids et biais donnés, pouvant approximer une fonction en particulier.

Le \emph{Théorème d'Approximation Universelle} nous dit qu'il existe un réseau suffisamment "grand" pour avoir la précision souhaitée sur les résultats.

Toutefois, ce théorème ne dit pas quelle sera la taille de ce réseau, mais en affirme seulement l'existence.
\subsection{Techniques de Régularisation}
Un défi majeur en apprentissage machine est de choisir un algorithme qui aura de bons résultats,non seulement à l'apprentissage, mais aussi sur de nouvelles entrées.
Les stratégies utilisées en apprentissage machine, permettant de réduire l'\emph{erreur de test}, parfois au dépend de l'\emph{erreur d'apprentissage}, sont appelées techniques de régularisation.

Nous avons, dans le premier chapitre, vu les concepts généraux de la \emph{généralisation}, du \emph{sous-apprentissage} et du \emph{sur-apprentissage}.
Nous verrons à présent des méthodes concrètes appliquées aux réseaux de neurones profonds.

Certaines méthodes ajouteront des contraintes d'optimisation sur la fonction de perte, d'autres des restrictions sur les paramètres.
Si les méthodes sont choisies avec soin, elles peuvent améliorer grandement la performance des réseaux de neurones profonds sur l'ensemble des données de test.
\subsubsection{Pénalisation des Paramètres}
La pénalisation des paramètres est une des premières formes de régularisation, utilisée depuis les débuts de l'apprentissage machine.
Cette régularisation limite la capacité de modèles, tels que les réseaux de neurones, les régressions linéaires, polynomiales et logistiques, en ajoutant une composante de pénalisation des paramètres $\Omega(\theta)$ à la fonction de perte $J(x,y,\theta)$, tel que
$$J(x,y,\theta) = J_0(x,y,\theta) + \lambda \Omega(\theta)$$
Avec $\lambda \geq 0$, un hyper-paramètre pondérant la contribution de la composante de pénalisation.
Si $\lambda = 0$, il n'y a pas de régularisation.
Nous ajouterons par ailleurs que cette pénalisation n'affecte que les poids $\elem{W}{k}{j}{i}$ et non les biais $\elem{b}{k}{j}{}$, car les biais requièrent moins de données pour ajuster précisément les données.
\paragraph{Régularisation $L^2$}
Soit $w$, l'ensemble des poids du modèle,
On pose, $$\Omega(\theta) = \Omega(w) = \frac{1}{2} ||w||_2^2 = \frac{1}{2} w^T w$$
La fonction de perte s'écrit donc,
$$\tilde{J}(x,y,\theta) = J(x,y,\theta) + \frac{\lambda}{2} w^T w$$
Par conséquent le gradient s'écrit de la façon suivante,
$$\nabla_\theta \tilde{J}(x,y,\theta) = \nabla_\theta J(x,y,\theta) + \lambda w$$
Ainsi le poids $\elem{W}{k}{j}{i}$ aura tendance à diminuer par rapport à une fraction de lui même.
\subsubsection{Augmentation du Jeu de Données}
Une des meilleures façons d'améliorer la capacité de généralisation d'un modèle, est de l'entraîner sur plus de données.
Malheureusement, la taille des ensembles de données est généralement limitée.
Une façon de contourner le problème est de créer artificiellement des données et de les ajouter à l'ensemble d'apprentissage.

Cette méthode est principalement utilisée pour un domaine : la reconnaissance d'objets.
En effet, il est très facile de transformer les données existantes par des transformations, telles que des rotations, des translations ou des homothéties, paramétrées aléatoirement.
On peut aussi le faire sur d'autres types de données en ajoutant du \emph{bruit blanc} sur une partie des entrées.
\subsubsection{Arrêt Prématuré}
Lors de qu'un modèle avec une capacité suffisante pour sur-apprendre, on observe généralement que tandis ce que l'\emph{erreur d'apprentissage} continue de diminuer, l'\emph{erreur d'entraînement} recommence à augmenter.
Cela signifie que nous avons atteint un \emph{minimum local} sur les données de test, il convient alors d'arrêter l'apprentissage avant que l'\emph{erreur de généralisation} empire.
\subsubsection{Dropout}
La méthode \emph{Dropout} est une méthode assez particulière de régularisation, qui consiste à entraîner tour à tour des sous-réseaux de notre réseaux de neurones.
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.20]{Images/Dropout.png}
		\caption{Exemple d'application de la méthode de \emph{Dropout}}
	\end{center}
\end{figure}
Ainsi les différents sous-modèles se partagent les paramètres $\theta$ du modèle original.
Il en résulte un modèle beaucoup plus robuste, car les différents sous-modèles entraînent une recherche de paramètres pour atteindre des minima différents.

Cela incite donc à une convergence vers un minimum local partagé par les différents sous-modèles.
Ce minimum local est de façon générale un bien meilleur minimum que ceux propres aux sous-modèles.
Cette méthode présente toutefois un inconvénient, elle est difficile à implémenter, mais est présente dans la plupart des librairies d'apprentissage profond.
\section{Réseaux Convolutifs}
Les réseaux de neurones convolutifs sont une famille particulière de réseaux de neurones, qui excelle en terme de performance dans le domaine de la vision par ordinateur.
Ils sont spécialisés dans le traitement de données ayant une structure en forme de grille, c'est à dire que les données sont liées spatialement ou temporellement.

Voici des exemples de données ayant ce genre de structure :
\begin{itemize}
	\item Les séries temporelles pouvant être vue comme une grille de dimension $1$, car assimilables à des signaux, ayant pour unité un intervalle de temps fixe.
	\item Les images, pouvant être considérées comme étant des grilles de dimensions $2$ de pixels.
\end{itemize}
Dans un premier temps, nous définirons rapidement l'opérateur de convolution.
Dans un second temps, nous discuterons de l'intérêt des convolutions dans les réseaux de neurones, ainsi que des différences existantes entre la convolution au sens mathématique et celle employée pour l'apprentissage profond.
Enfin nous parlerons d'une opération très souvent complémentaire à celle de \emph{convolution}, appelée \emph{pooling}.
\subsection{L'Opérateur de Convolution}
L'opérateur de convolution est un opérateur bilinéaire, c'est-à-dire linéaire par rapport à chacune des opérandes, et commutatif, généralement noté $*$.

En traitement du signal, cet opérateur représente l’interaction entre un filtre et un signal.
Elle peut être vue comme une moyenne mobile d'un signal pondérée par une fonction appelée \emph{noyau}.
\subsubsection{Cas Continu}
Le produit de convolution de deux fonctions réelles ou complexes $f$ et $g$ est défini tel que,
$$(f * g)(x) = \int_{-\infty}^{+\infty}{f(x-t)g(t)dt} = \int_{-\infty}^{+\infty}{f(t)g(x-t)dt}$$
\subsubsection{Cas Discret}
Le produit de convolution de deux suites $f$ et $g$ est défini tel que,
$$(f *g)(n) = \sum_{m = -\infty}^{+\infty}{f(n-m)g(m)} = \sum_{m = -\infty}^{+\infty}{f(m)g(n-m)}$$
\subsubsection{Application aux Images}
On rappelle qu'une image $I$ de $M$ lignes et $N$ colonnes est décrite par une fonction discrète $I(i,j)$ à support fini $S \subset \mathbb{Z}^2$ et à valeurs dans $\mathbb{R}$ ou $\mathbb{N}$.
Puisque l'image, décrite par la fonction $I$ est nulle en dehors du support, on peut réécrire le produit de convolution entre des bornes finies.

Le produit de convolution en un point $(i,j)$ de deux images $I$ et $K$, noté $I * K$ est défini tel que,
On choisira d'imiter la notation matricielle pour plus de clarté.
$$(I*K)_{i,j} = \sum_{m}\sum_{n}{I_{m,n}K_{i-m,j-n}} = (K*I)_{i,j} = \sum_{m}\sum_{n}{K_{m,n}I_{i-m,j-n}}$$
L'image $K$ est appelée \emph{noyau}, ou \emph{kernel}, c'est l'équivalent d'un filtre pour les images.
Voici un exemple d'application de la convolution sur une image :
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.25]{Images/Convolution.png}
		\caption{Exemple de convolution entre une image $I$, $(8,3)$ et un noyau $K$, $(2,2)$}
	\end{center}
\end{figure}
Dans cet exemple de convolution entre une image $I$, $(8,3)$ et un noyau $K$, $(2,2)$, on peut remarquer tout d'abord, que la image issue de la convolution est de forme $(6,2)$.

En effet la convolution sans \emph{padding} réduit la taille de la fenêtre.
Si l'image $I$ est de taille $(m,n)$ et le noyau de taille $(k,l)$ alors l'image convolutée sera de taille $(m-k+1,n-l+1)$.
\subsubsection{Convolution et Corrélation Croisée}
Nous avons défini précédemment la convolution entre deux images, ici une \emph{map de features} $I$ et un noyau $K$.

Nous parlerons ici de façon plus générale de convolution entre tenseurs.
\begin{center}
	Un \emph{tenseur} est un \emph{tableau multi-dimensionnel}.
	
	L'\emph{ordre} d'un tenseur est égal à la dimension du tableau.
\end{center}
Par exemple, une image en couleurs (RGB) de $256 \times 256$ pixels peut être décrite par un tenseur d'ordre $3$.
Nous écrirons alors que la dimension de l'image est $3 \times 256 \times 256$, ou bien encore $256 \times 256 \times 3$.

Toutefois, d'un point de vue machine, nous indexons celle variant le plus lentement en premier et celle variant le plus rapidement en dernier. Nous retiendrons ici l'écriture $3 \times 256 \times 256$.

Nous avons défini précédemment la convolution entre deux tenseurs d'ordre $2$, ici une \emph{map de features} $I$ et un noyau $K$, de la façon suivante :
$$(K*I)_{i,j} = \sum_{m}\sum_{n}{K_{m,n}I_{i-m,j-n}}$$
qui est équivalente à 
$$(I*K)_{i,j} = \sum_{m}\sum_{n}{I_{m,n}K_{i-m,j-n}}$$
Mais dans la pratique, le noyau $K$ étant beaucoup plus "\emph{petit}" que $I$, la première formule est préférable, au niveau du calcul des bornes des indices $m$ et $n$.
Par conséquent, même si la propriété de commutativité existe, une seule expression de la convolution nous intéresse.

La corrélation croisée, très proche de la convolution, s'écrit de la façon suivante:
$$(K*I)_{i,j} = \sum_{m}\sum_{n}{K_{m,n}I_{i+m,j+n}}$$
La différence étant par rapport au sens de l'indexation. Cette opération n'est pas commutative contrairement à la convolution, mais étant donnée que seule l'opération $K*I$ nous intéresse, cette propriété ne nous apporte rien.

Il est à noter que dans beaucoup de librairies d'Apprentissage Machine, l'opération de convolution est implémentée en tant que corrélation croisée. Dans la suite, nous appellerons convolution les deux opérations sans distinction.
			
\subsection{Intérêts de la Convolution dans les Réseaux de Neurones}
La convolution s'appuie sur trois idées importantes permettant l'amélioration des performances, l'\emph{interaction partielle}, le \emph{partage des paramètres} et l'\emph{invariance par translation}.
\subsubsection{L'interaction Partielle}
Dans les réseaux de neurones traditionnels, le passage de l'information d'une couche à la suivante se fait en autre par la multiplication matricielle du vecteur d'entrée $\elem{a}{k-1}{}{}$ de dimension $m$, par la matrice $\elem{W}{k}{}{}$ de dimension $m \times n$, la sortie du neurone $\elem{a}{k-1}{}{}$ sera donc de dimension $n$.

Pour rappel :
$$\elem{z}{k}{}{} = (\elem{W}{k}{}{})^T(\elem{a}{k-1}{}{}) + \elem{b}{k}{}{}$$
On voit donc qu'ici l'interaction, ou connectivité, est totale puisque toutes les entrées $\elem{a}{k-1}{j}{}$ sont connectées par les poids $\elem{W}{k}{j}{i}$ aux sorties $\elem{a}{k-1}{i}{}$.
Dans le cas où l'on travaille avec des images, on peut se demander si pour un pixel donné l'information apportée par un pixel situé à l'extrême opposé de l'image est pertinente.

Ainsi, envisager une connectivité partielle entre le vecteur d'entrée $\elem{a}{k-1}{}{}$ et le vecteur de sortie $\elem{a}{k-1}{}{}$ peut sembler intéressante si l'information apportée s'apparente à du bruit.
La convolution nous permet en effet cette interaction partielle, en effet la dimension du noyau $\elem{W}{k}{}{}$, de la forme $k \times n$, et si $k < m$ alors l'interaction sera en effet partielle.

Voici à présent la représentation de l'interaction partielle dans un cas matriciel, plus illustratif qu'un simple cas vectoriel:
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.60]{Images/Convolution_Layer.png}
		\caption{Représentation de l'interaction partielle}
	\end{center}
\end{figure}
			
\subsubsection{Le Partage des Paramètres et Invariance}
Dans un réseau convolutif, chaque paramètre du noyau est utilisé à toutes les positions du vecteur d'entrée, sauf peut-être pour les premiers et derniers éléments du vecteur d'entrée.
Ainsi le partage de paramètres pour la convolution signifie qu'au lieu d'apprendre pour chaque élément du vecteur d'entrée un paramètre associé, un filtre unique, \emph{composé d'un petit nombre de paramètre}, sera appris en rapport au vecteur d'entrée.

Dans le cas de la figure précédente, où la fenêtre est de dimension $5 \times 5$, un seul noyau de dimension $5 \times 5$ sera appris pour cette couche de convolution.
Ce partage de paramètres permet alors à notre couche de convolution d'être invariante par translation.
En effet supposons que le noyau de notre couche soit entraîné à détecter un motif, ou \emph{feature} en particulier sur une image. Le noyau unique, et donc partagé à toutes les sous-régions de l'entrée, pourra détecter le motif peu importe sa position dans l'image.
			
Cette propriété d'invariance par translation rend les couches de convolutions très intéressantes, car elles sont plus robustes au bruit que des couches entièrement connectées.
				
\subsection{La Convolution appliquée aux Réseaux de Neurones}
Le terme \emph{convolution} employé dans le contexte de l'apprentissage profond, diffère quelque peu de la convolution mathématique définie comme ci-dessus.

Tout d'abord, quand on parle d'une convolution dans le contexte des réseaux de neurones, il s'agit en fait de plusieurs convolutions menées en parallèle.

Énumérons à présent les différents noyaux $K$ de convolutions, en fonction de $I$ le tenseur d'entrée et de $S$ le tenseur de sortie souhaité:
\begin{enumerate}
	\item Soient $I$ de dimensions $(H_I,W_I)$ et $S$ de dimensions $(H_S, W_S)$,\\
	Et si $H_I > H_S + 1$ et $W_I > W_S + 1$,\\
	Alors $K$ sera de dimensions :
	$$(H_K, H_K) = (H_I - H_S + 1, W_I - W_S + 1)$$
	Cette convolution nous permet d'extraire seulement une seule \emph{feature} depuis chaque sous-région de $I$.\\
	\item Soient $I$ de dimensions $(H_I,W_I)$ et $S$ de dimensions $(C_S, H_S, W_S)$,\\
	Et si $H_I > H_S + 1$ et $W_I > W_S + 1$,\\
	Alors $K$ sera de dimensions :
	$$(C_K^{out}, H_K, W_K) = (C_S, H_I - H_S + 1, W_I - W_S + 1)$$
	Cette convolution nous permet d'extraire $C_S$ \emph{features} depuis chaque sous-région de $I$.\\
	\item Soient $I$ de dimensions $(C_I, H_I,W_I)$ et $S$ de dimensions $(C_S, H_S, W_S)$,\\
	Et si $H_I > H_S + 1$ et $W_I > W_S + 1$,\\
	Alors $K$ sera de dimensions :
	$$(C_K^{out}, C_K^{in}, H_K, W_K) = (C_S, C_I, H_I - H_S + 1, W_I - W_S + 1)$$
	Cette convolution nous permet d'extraire $C_S$ \emph{features} croisées entre les $C_I$ \emph{canaux} de chaque sous-région de $I$.\\	
\end{enumerate}

Cette dernière expression est l'expression générale de la convolution.
On peut remarquer pour le premier cas, que $(H_I,W_I) = (1, H_I,W_I)$, $(H_S,W_S) = (1, H_S,W_S)$ et $(H_I,W_I) = (1, 1,  H_I,W_I)$

\subsubsection{Convolution tensorielle}
Soient $I$ de dimensions $(C_I, H_I,W_I)$ et $S$ de dimensions $(C_S, H_S, W_S)$,\\
Et si $H_I > H_S + 1$ et $W_I > W_S + 1$,\\
Alors $K$ sera de dimensions :
$$(C_K^{out}, C_K^{in}, H_K, W_K) = (C_S, C_I, H_I - H_S + 1, W_I - W_S + 1)$$

Donc $\forall k \in [0, C_S[, \ \forall i \in [0, H_S[, \ \forall j \in [0, W_S[$,
$$S(k,i,j) = \sum_{l}\sum_{m}\sum_{n}{K_{k,l,m,n} \times I_{l,m + i, n + j}}$$

Avec les indices de sommations suivants,
\begin{itemize}
	\item $l \in [\![0, C_K^{in}[\![$
	\item $m \in [\![0, H_K[\![$ et $(m + i) \in [\![0, H_I[\![$
	\item $n \in [\![0, W_K[\![$ et $(n + j) \in [\![0, W_I[\![$
\end{itemize}
\subsubsection{Padding et Strides}
\paragraph{Padding}
Nous avons pu observer précédemment que la convolution ne préservait pas les dimensions spatiales, la hauteur et la largeur, entre le tenseur d'entrée $I$ et le tenseur de sortie $S$.

Soit $I$ un tenseur de dimensions $(H_I, W_I)$ et $K$ un noyau de dimensions $(H_K, W_K)$, alors $S$ aura les dimensions suivantes :
$$(H_S, W_S) = (H_I - H_K + 1, W_I - W_K + 1)$$
Toutefois il peut être intéressant dans certains cas de préserver ces dimensions.

Le \emph{padding}, signifiant \emph{rembourrage}, permet de remédier à ce problème. Cette méthode consiste à créer un tenseur $I'$, en ajoutant à $I$ des lignes et colonnes de zéros sur ses \emph{bords}.

Ainsi, $$(H_{I'}, W_{I'}) = (H_I + p_H, W_I + p_W)$$
Donc si on applique la convolution à $I'$,
$$(H_S, W_S) = (H_I + p_H - H_K + 1, W_I + p_W - W_K + 1)$$
Donc,
$$(H_S, W_S) = (H_I, W_I) \leftrightarrow (p_H, p_W) = (H_K - 1, W_K - 1) $$

Dans le cas où les dimensions du noyau sont impaires, le \emph{padding} se fera de façon symétrique autour de $I$.
Dans le cas où les dimensions du noyau sont paires, le \emph{padding} est par convention pour les bords \emph{haut} et \emph{gauche} de $I$.

\subparagraph{Exemple}
Dans le cas d'une convolution de noyau $K$ de dimensions $(3, 3)$ appliquée à un tenseur $I$ de dimensions $(3,3)$, si on veut garder $S$ de même dimensions que $I$.

Soit
$$I =
\begin{pmatrix}
a & b & c \\ 
d & e & f \\ 
g & h & i
\end{pmatrix}$$
Alors $(p_H,p_W) = (2, 2)$\\
Donc $$I'=
\begin{pmatrix}
0 & 0 & 0 & 0 & 0\\
0 & a & b & c & 0\\ 
0 & d & e & f & 0\\ 
0 & g & h & i & 0\\
0 & 0 & 0 & 0 & 0
\end{pmatrix}
$$
\paragraph{Strides}
Le terme anglais \emph{stride} peut être traduit en français par le \emph{pas de déplacement}.\\
Augmenter le pas de déplacement dans une convolution à pour effet de diminuer la dimension du tenseur de sortie $S$.

Nous n'allons pas ici expliciter l'impact de ce changement sur les effets de l'apprentissage, un lien sera fait dans la partie dédiée au \emph{Pooling}, mais simplement décrire les modifications sur la sortie.
$$(H_S, W_S) = ((H_I - H_K) / s_H + 1, (W_I - W_K) / s_W + 1)$$
Les divisions sont ici \emph{entières} car les dimensions de sorties sont forcément entières.
\subsubsection{Convolution généralisée}
Soient $I$ de dimensions $(C_I, H_I,W_I)$,

$S$ de dimensions $(C_S, H_S, W_S)$,

$K$ de dimensions $(C_K^{out}, C_K^{in}, H_K, W_K)$, avec $C_K^{out} = C_S$ et $C_K^{in} = C_I$.

Il nous faut alors trouver $(p_H, p_W)$ et $(s_H, s_W)$, tels que :
$$(C_S, H_S, W_S) = (C_S, (H_I + p_H - H_K) / s_H + 1, (W_I + p_W - W_K) / s_W + 1)$$
On pose alors $I'$ le tenseur "\emph{rembourré}" de $I$, avec 
$$(C_{I'}, H_{I'}, W_{I'}) = (C_I, H_I + p_H, W_I + p_W)$$
Donc,
$$(C_S, H_S, W_S) = ((H_{I'} - H_K) / s_H + 1, (W_{I'} - W_K) / s_W + 1)$$
Donc $\forall k \in [0, C_S[, \ \forall i \in [0, H_S[, \ \forall j \in [0, W_S[$,
$$S(k, i, j) = \sum_{l}\sum_{m}\sum_{n}{K_{k, l, m, n} \times {I'}_{l, m + i \times s_H, n + j \times s_W}}$$
Avec,
\begin{itemize}
	\item $l \in [\![0, C_K^{in}[\![$
	\item $m \in [\![0, H_K[\![$ et $(m + i \times s_H) \in [\![0, H_{I'}[\![$
	\item $n \in [\![0, W_K[\![$ et $(n + j \times s_W) \in [\![0, W_{I'}[\![$
\end{itemize}
\subsection{La Réduction de la Dimensionnalité}
La \emph{réduction de la dimensionnalité} est un défi majeur en Statistiques et en Apprentissage Machine.

Prenons un exemple pour illustrer le problème.
Imaginons que nous souhaitons classifier des images issues d'Internet de dimensions $(3,256,256)$, en $1000$ classes distinctes.
Ce problème revient à devoir trouver un \emph{mapping} entre un tenseur d'entrée de dimensions $(3, 256, 256)$ et un tenseur de sortie de dimension $(1000)$.

On remarque qu'on peut transformer le tenseur d'entrée en un tenseur de dimension $(3 \times 256 \times 256) = (196\ 608)$.

On peut alors se poser plusieurs questions,
\begin{itemize}
	\item Quelles sont les variables significatives parmi les $196608$ variables disponibles ?
	\item Comment \emph{transformer}, ou \emph{modeler}, cette quantité d'information pour en extraire l'essentiel, c'est à dire sa classe ?
\end{itemize}

Tout d'abord la première question n'a pas vraiment de sens dans de nombreux domaines, et particulièrement en \emph{vision par ordinateur}, car les pixels d'une image sont liés spatialement. Chaque variable est donc dépendante de ses voisins.
La deuxième est plus beaucoup plus intéressante.

Une approche plutôt naïve pourrait suggérer de transformer l'image de dimensions $(3, 256, 256)$ en niveaux de gris de dimensions $(1, 256, 256)$ puis de la \emph{redimensionner} en $(1, 32, 32)$, ce qui nous permet d'obtenir un tenseur d'entrée de dimension $(1024)$.
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.25]{Images/Lena.jpg}
		\caption{Pré-traitement d'une image}
	\end{center}
\end{figure}
Ici les dimensions d'entrées et de sorties sont comparables, nous pouvons donc "choisir" plus facilement les combinaisons de variables à effectuer pour classifier les images. Toutefois la perte d'information, due aux pré-traitements appliqués aux données, est grande, ce qui aura un impact potentiel sur la performance de notre algorithme apprenant.

Une approche un peu plus réfléchie pourrait suggérer d'une part de ne pas réduire la dimension des données non pas pendant le pré-traitement, mais surtout d'autre part, d'éviter de la réduire d'un seul coup, mais plutôt petit à petit.

\subsubsection{Pooling d'Information}
Le \emph{pooling}, signifiant \emph{mise en commun}, consiste à résumer l'information apportée par les valeurs de sorties proches en une seule valeur.
Il existe deux déclinaisons du \emph{pooling},
\begin{itemize}
	\item Le \emph{max pooling}, qui calcule le maximum des valeurs données en entrée.
	\item L'\emph{average pooling}, qui calcule la moyenne des valeurs données en entrée.
	\item Les convolutions avec une ou plusieurs \emph{strides} $> 1$
\end{itemize}
Nous allons maintenant voir un exemple de calcul d'un \emph{pooling} appliqué sur les composantes spatiales.\\
Soit $I$ un tenseur de dimensions $(C_I, H_I, W_I)$, et une fonction de \emph{pooling} définie par une fenêtre de dimension $(H_P, W_P)$, de \emph{padding} $(p_H, p_W)$ et de \emph{strides} $(s_H, s_W)$,\\
Alors $S$ sera de dimensions :
$$(C_S, H_S, W_S) = (C_I, (H_I + p_H - H_K) / s_H + 1, (W_I + p_W - W_K) / s_W + 1))$$

Ces deux déclinaisons de pooling sont utilisées dans des contextes assez différents.
\paragraph{Max-Pooling}
Le \emph{max pooling} est principalement utilisé pour réduire la dimension des données de façon spatiale, c'est une méthode robuste aux bruits ambients, car elle ne transmet que l'information ayant le plus d'intensité.
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.6]{Images/Pooling_Layer.png}
		\caption{\emph{Max-pooling} sur une fenêtre $(2,2)$}
	\end{center}
\end{figure}
\paragraph{Average Pooling}
L'\emph{average pooling} est principalement utilisé pour réduire la dimension des données au niveau des canaux, car elle permet de prendre en compte les valeurs des différentes \emph{features} et de les agréger.
\paragraph{Pooling par Convolution}
Les convolutions à strides $>1$ sont à l'heure actuelle \emph{à la mode}. Elles font le travail à la fois de couches de convolution, mais aussi de couches de \emph{pooling}, permettant ainsi d'une part de simplifier le modèle, ce qui réduit le nombre de \emph{floating-point operations}, mais aussi d'avoir une opération de \emph{pooling} plus "maléable", car la fonction calculée n'est pas statique, mais sera amenée à évoluer lors de la rétro-propagation.

De plus, elles sont souvent suivies de fonctions d'activation, rendant la sortie plus robuste aux bruits stochastiques.
Elle est utilisée dans plusieurs modèles très performants, justifiant ainsi sa popularité montante.
\section{Applications à la Vision par Ordinateur}
Les applications basées sur les réseaux de neurones occupent une place de plus en plus importante dans la société, le champ d'application est très large, on les retrouve notamment dans des outils de reconnaissance vocale, par exemple : Siri, Cortana; dans des outils de vision par ordinateur, utilisés par exemple dans les voitures autonomes; ou bien encore dans la création d'intelligences artificielles, liés à des jeux de réflexion, comme Deep Mind au jeu de Go, ou encore des agents conversationnels.
Pour ces applications, les performances des réseaux de neurones sont comparables voire supérieures à celles d'un humain.

Nous allons dans cette partie présenter quelques tâches liées à la vision par ordinateur, domaine dans lequel l'influence des réseaux de neurones est grande.
\subsection{Classification}
La classification est sans doute le problème le plus simple en matière de vision, il s'agit de prédire l'appartenance d'une image à une classe, généralement liée aux objets liés dans l'image.
\subsubsection{Datasets}
Un des premiers \emph{datasets} d'images pour la classification est le MNIST, composé de $70000$ images noir et blanc de $28 \times 28$ pixels, chacune contenant un chiffre manuscrit.
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.3]{Images/MNIST_Digits.png}
		\caption{Données issues de MNIST}
	\end{center}
\end{figure}
Même si la l'intérêt à reconnaître les chiffres est limité, ce \emph{dataset} a longtemps servi au niveau académique de \emph{benchmark} pour comparer les différents modèles.

On citera aussi les \emph{datasets} CIFAR-10, CIFAR-100, et ImageNet.
CIFAR-10 et CIFAR-100 sont composés chacun de $60000$ images RGB de $32 \times 32$ pixels, réparties en $10$ classes pour le premier et $100$ classes pour le second.
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.3]{Images/CIFAR-10.png}
		\caption{Données issues de CIFAR-10}
	\end{center}
\end{figure}
ImageNet contient une base de classification d'images contenant plus de $10$ millions d'URLs d'images de taille variable réparties en $1000$ classes. Les images sont majoritairement issues de sites comme Flickr.
Ce \emph{dataset}, créé en $2009$, fait l'objet d'une compétition depuis $2010$, qui a permis de réaliser des progrès impressionnants en traitement d'images.
\subsubsection{Architectures de Modèles}
En $2011$, l'erreur de classification était de $25\%$. En $2012$, le réseau de neurones convolutifs AlexNet, composé de $8$ couches, atteignait alors $16\%$ d'erreur. En $2014$, GoogLeNet ($22$ couches), suivi de près par VGG-16 ($16$ couches), remportait la compétition avec une erreur de $6.7\%$ (respectivement $7.3\%$). En $2015$, ResNet, un réseau de $152$ couches, atteignait alors $3.6\%$. En moyenne, un humain non-entraîné réalise environ $10\%$ d'erreur et un humain entraîné $5\%$.
\subsection{Détection d'Objets}
La détection d'objets consiste à prédire la classe et l'emplacement d'un ou plusieurs objets dans une image. L'emplacement d'un objet est généralement défini par une \emph{bounding box}, ou région d'intérêt, représentée par un rectangle entourant l'objet.
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.3]{Images/Pascal_VOC_Detection.jpg}
		\caption{Image et \emph{bounding boxes} issues de Pascal VOC}
	\end{center}
\end{figure}

\subsubsection{Datasets}
Le \emph{dataset} Pascal VOC est composé de $11530$ images contenant au total $27450$ régions d'intérêt décrivant $20$ classes.

ImageNet possède aussi une base de détection d'objets contenant environ $450000$ images contenant $475000$ objets référencés répartis en $200$ classes.
\subsubsection{Architectures de Modèles}
Deux architectures remarquables sont les réseaux de type R-CNN et YOLO, l'une par ses performances exceptionnelles, l'autre par le compromis réalisé entre performances et vitesse d'éxécution.

Les architectures de type R-CNN se caractérisent par un schéma de fonctionnement divisé en deux parties, la première étant un réseau de neurones assurant la localisation potentielle d'objets, la seconde étant un autre réseau de neurones dédié à la classification de chacune des zones potentielles.

Les architectures de type YOLO ont à l'inverse la particularité d'effectuer en parallèle la localisation et la classification des objets, proposant ainsi une grande vitesse d'exécution.
\subsection{Segmentation d'Images}
Comme pour la détection d'objets, la segmentation vise à identifier les objets appartenant à une classe et à les localiser sur l'image.
La différence apparaît sur la sortie produite, dans le cas de la segmentation, cela consiste à prédire, pour chaque pixel de l'image, sa classe.
La segmentation répond à des besoins de précision plus élevés que la détection d'objets, du fait de la prédiction d'un masque de la taille de l'image d'entrée.
\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.2]{Images/Pascal_VOC_Segmentation.png}
		\caption{Image et masque de classes issus de Pascal VOC}
	\end{center}
\end{figure}
Un des avantages de la segmentation d'images par rapport à la détection d'objets, outre le gain potentiel de précision, est qu'il est possible à partir d'un masque de segmentation de produire des \emph{bounding boxes} en utilisant la polygonisation des masques. L'opération inverse n'est pas vraiment intéressante puisque les polygones sont des rectangles.
\subsubsection{Datasets}
Pascal VOC possède aussi une base de segmentation d'images contenant $2913$ images décrivant $20$ classes.
Microsoft COCO (Common Objects in Context) contient $328000$ images décrivant $91$ classes.

Ces deux \emph{datasets} possèdent la particularité de segmenter les images d'une part selon la classe mais aussi en fonction de l'instance, permettant ainsi de différencier deux objets de même nature au sein d'une image.
\subsubsection{Architectures de Modèles}
Deux architectures remarquables sont les réseaux de type FCN et DeconvNet, elles utilisent toutes les deux le principe de décomposer l'image en \emph{features} par convolutions successives, puis de reconstituer l'image en image segmentée en appliquant plusieurs couches de déconvolutions.

Les architectures de type FCN reconstituent l'image en combinant les \emph{features} dé-convolutées avec les \emph{features} après \emph{pooling}.

Les architectures de type DeconvNet reconstituent l'image en utilisant des couches d'\emph{unpooling}, inversant l'effet des couches de \emph{pooling}. Nous reviendront en détail leur fonctionnement dans la suite.
\chapter{L'Apprentissage Profond appliqué à l'Imagerie Satellite}
\section{Présentation des données}
\subsection{Données SpaceNet}
\subsection{Données Pléiades}
\section{Cartographie Automatisée par Segmentation de Classes}
\subsection{Protocole expérimental}
\subsection{Résultats}
\subsection{Comparaisons entre modèles}
\section{Recherche de Similarités entre Images}
\subsection{Protocole expérimental}
\subsection{Résultats}
\subsection{Comparaisons entre modèles}
\chapter{Conclusion}
\end{document}
